{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secret-episode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-1.5433],\n",
      "        [-4.0281],\n",
      "        [-3.3238],\n",
      "        [12.3252],\n",
      "        [-5.0082],\n",
      "        [-0.6949],\n",
      "        [-3.2405],\n",
      "        [-2.8939],\n",
      "        [ 6.3242],\n",
      "        [ 3.5306],\n",
      "        [-3.7562],\n",
      "        [ 2.4269],\n",
      "        [ 9.7136],\n",
      "        [ 8.9549],\n",
      "        [-9.2630],\n",
      "        [-1.1120],\n",
      "        [-3.7876],\n",
      "        [-6.0466],\n",
      "        [ 5.4963],\n",
      "        [-2.5591]]), tensor([[-12.6343],\n",
      "        [ -3.8836],\n",
      "        [  4.2603],\n",
      "        [ -4.5930],\n",
      "        [  6.5098],\n",
      "        [  4.5102],\n",
      "        [  0.7874],\n",
      "        [ -4.3000],\n",
      "        [  5.0318],\n",
      "        [  4.6434],\n",
      "        [  1.3784],\n",
      "        [  0.3712],\n",
      "        [ -4.5079],\n",
      "        [ -9.5469],\n",
      "        [  5.1770],\n",
      "        [  1.8466],\n",
      "        [  5.3064],\n",
      "        [ -2.2349],\n",
      "        [ -2.7901],\n",
      "        [-12.3457]]), tensor([[ -1.0877],\n",
      "        [ -1.4009],\n",
      "        [  7.0690],\n",
      "        [  9.1229],\n",
      "        [ -2.8953],\n",
      "        [  1.3095],\n",
      "        [ -1.1315],\n",
      "        [ -2.3207],\n",
      "        [ -3.0884],\n",
      "        [-13.1212],\n",
      "        [ -0.4644],\n",
      "        [  2.8015],\n",
      "        [  0.4383],\n",
      "        [  4.7571],\n",
      "        [  4.7026],\n",
      "        [  0.4818],\n",
      "        [ -3.9406],\n",
      "        [  8.2154],\n",
      "        [ -1.8650],\n",
      "        [  0.5125]]), tensor([[  5.2281],\n",
      "        [ -6.7236],\n",
      "        [ -4.2205],\n",
      "        [ -2.1512],\n",
      "        [ -1.8865],\n",
      "        [ -4.1049],\n",
      "        [-10.0421],\n",
      "        [ -3.2037],\n",
      "        [ -6.3644],\n",
      "        [  1.1590],\n",
      "        [  0.0456],\n",
      "        [  2.6072],\n",
      "        [  9.9453],\n",
      "        [  4.4833],\n",
      "        [  9.2891],\n",
      "        [ -6.2668],\n",
      "        [ -3.2766],\n",
      "        [  2.4117],\n",
      "        [  5.3371],\n",
      "        [ -4.5345]]), tensor([[ 7.1972],\n",
      "        [-2.8209],\n",
      "        [ 7.4644],\n",
      "        [ 2.3332],\n",
      "        [-1.0342],\n",
      "        [ 5.8699],\n",
      "        [ 1.7986],\n",
      "        [-2.9610],\n",
      "        [ 5.2298],\n",
      "        [-9.3056],\n",
      "        [-7.1965],\n",
      "        [-3.5618],\n",
      "        [ 0.3589],\n",
      "        [ 2.5761],\n",
      "        [-0.4381],\n",
      "        [12.0000],\n",
      "        [-0.4217],\n",
      "        [ 5.2944],\n",
      "        [-1.1757],\n",
      "        [ 2.5362]])]\n",
      "hid_orderings [0, 0, 0, 0, 0, 0, 0, 0] size 8\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0] size 1\n",
      "expanded_output_ordering [0, 0] size 2\n",
      "hid_orderings [2, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 2, 0, 0, 2] size 16\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1] size 2\n",
      "expanded_output_ordering [2, 2, 1, 1] size 4\n",
      "hid_orderings [0, 6, 4, 1, 5, 5, 2, 5, 1, 4, 3, 5, 2, 2, 5, 3, 4, 4, 4, 6, 3, 4, 2, 0, 5, 1, 5, 6, 4, 1, 2, 2] size 32\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1, 2] size 3\n",
      "expanded_output_ordering [4, 4, 0, 0, 1, 1] size 6\n",
      "hid_orderings [2, 14, 17, 10, 5, 2, 19, 0, 10, 7, 16, 22, 28, 19, 30, 29, 19, 7, 14, 5, 30, 13, 23, 1, 4, 5, 7, 10, 8, 13, 13, 3, 1, 11, 2, 13, 0, 16, 2, 21, 12, 30, 8, 14, 23, 10, 10, 19, 30, 27, 12, 22, 21, 11, 7, 2, 27, 1, 16, 16, 4, 20, 28, 24, 12, 3, 30, 16, 19, 24, 11, 1, 4, 20, 10, 27, 22, 30, 20, 9, 24, 0, 16, 27, 15, 4, 15, 16, 11, 27, 10, 8, 15, 6, 9, 12, 29, 2, 6, 6, 30, 27, 6, 17, 2, 9, 10, 16, 28, 25, 16, 24, 15, 22, 24, 7, 25, 17, 15, 12, 6, 15, 3, 19, 27, 24, 18, 15] size 128\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1, 2, 3, 4] size 5\n",
      "expanded_output_ordering [1, 1, 8, 8, 4, 4, 12, 12] size 8\n",
      "hid_orderings [21, 3, 1, 26, 11, 20, 13, 11, 23, 10, 23, 25, 5, 30, 1, 12, 15, 25, 5, 17, 11, 28, 3, 8, 25, 9, 29, 1, 12, 3, 17, 29, 10, 20, 8, 13, 17, 7, 21, 15, 28, 8, 29, 5, 0, 20, 22, 14, 1, 30, 4, 26, 27, 6, 26, 14, 27, 27, 24, 8, 17, 30, 9, 11, 21, 1, 7, 5, 12, 13, 18, 15, 5, 1, 16, 23, 28, 26, 9, 26, 14, 8, 2, 13, 16, 8, 6, 29, 2, 29, 12, 24, 3, 17, 23, 13, 11, 15, 6, 6, 7, 1, 28, 2, 28, 0, 20, 16, 1, 29, 22, 27, 13, 9, 5, 3, 20, 25, 6, 0, 11, 4, 6, 6, 20, 13, 17, 12] size 128\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1, 2, 3, 4] size 5\n",
      "expanded_output_ordering [7, 7, 1, 1, 13, 13] size 6\n",
      "hid_orderings [2, 1, 0, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 0, 2, 0] size 16\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1] size 2\n",
      "expanded_output_ordering [2, 2] size 2\n",
      "number of levels: 6\n",
      "input_levels [['r'], ['r', 'z2'], ['y4', 'z1', 'z2'], ['z1', 'y3', 'y4', 'x8', 'y2'], ['x6', 'y1', 'x4', 'y3', 'y2'], ['x2', 'y1']]\n",
      "out_levels [['z2'], ['z1', 'y4'], ['y3', 'x8', 'y2'], ['x6', 'y1', 'x4', 'x7'], ['x5', 'x2', 'x3'], ['x1']]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-da5a0edb9935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m             \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m         \u001b[0mimme_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msvi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[0mloss_track\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimme_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\infer\\svi.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# get loss and compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# grab a trace from the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\infer\\elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[1;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[1;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m---> 52\u001b[1;33m         model_trace, guide_trace = get_importance_trace(\n\u001b[0m\u001b[0;32m     53\u001b[0m             \"flat\", self.max_plate_nesting, model, guide, args, kwargs)\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\infer\\enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[1;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mmodel_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprune_subsample_sites\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mmodel_trace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mguide_trace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_score_parts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_struct.py\u001b[0m in \u001b[0;36mcompute_log_prob\u001b[1;34m(self, site_filter)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"log_prob\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                         \u001b[0mlog_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msite\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fn\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"args\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"kwargs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\distributions\\normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mlog_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlog_scale\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from made import MADE\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal, AutoNormal, AutoMultivariateNormal\n",
    "from gmade import GMADE\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# NN used for p(x | y)\n",
    "class simpleNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=32, out_size=1, t=\"normal\", out_non_linear=None):\n",
    "        super().__init__()\n",
    "        self.t = t\n",
    "        self.out_non_linear = out_non_linear\n",
    "        self.hiddeen_layer = nn.Linear(input_size, hidden)\n",
    "        if t == \"normal\":\n",
    "            self.loc_layer = nn.Linear(hidden, out_size)\n",
    "            self.std_layer = nn.Linear(hidden, out_size)\n",
    "            self.softplus = nn.Softplus()\n",
    "        elif t == \"bern\":\n",
    "            self.prob_layer = nn.Linear(hidden, out_size)\n",
    "        elif t == \"mlp\":\n",
    "            self.out_layer = nn.Linear(hidden, out_size)\n",
    "        \n",
    "    def forward(self, x_list):\n",
    "        for i in range(len(x_list)):\n",
    "            if x_list[i].dim() == 0:\n",
    "                x_list[i] = torch.unsqueeze(x_list[i], dim=0)\n",
    "        input_x = torch.cat(x_list)\n",
    "        hid = F.relu(self.hiddeen_layer(input_x))\n",
    "        # return loc, std\n",
    "        if self.t == \"normal\":\n",
    "            return self.loc_layer(hid), self.softplus(self.std_layer(hid))\n",
    "        elif self.t == \"bern\":\n",
    "            return torch.sigmoid(self.prob_layer(hid))\n",
    "        else:\n",
    "            if self.out_non_linear == \"tanh\":\n",
    "                return torch.tanh(self.out_layer(hid))\n",
    "            else:\n",
    "                return self.out_layer(hid)\n",
    "\n",
    "class Experiment(nn.Module):\n",
    "    def __init__(self, USE_CUDA):\n",
    "        super().__init__()\n",
    "        \n",
    "        # guide 1\n",
    "        \n",
    "        self.x1_net_1 = simpleNN()\n",
    "        self.x2_net_1 = simpleNN()\n",
    "        self.x3_net_1 = simpleNN()\n",
    "        self.x4_net_1 = simpleNN()\n",
    "        self.x5_net_1 = simpleNN()\n",
    "        self.x6_net_1 = simpleNN()\n",
    "        self.x7_net_1 = simpleNN()\n",
    "        self.x8_net_1 = simpleNN()\n",
    "        self.y1_net_1 = simpleNN()\n",
    "        self.y2_net_1 = simpleNN()\n",
    "        self.y3_net_1 = simpleNN()\n",
    "        self.y4_net_1 = simpleNN()\n",
    "        self.z1_net_1 = simpleNN()\n",
    "        self.z2_net_1 = simpleNN()\n",
    "        \n",
    "        # guide 2\n",
    "        self.x1_net_2 = simpleNN(2)\n",
    "        self.x2_net_2 = simpleNN(2)\n",
    "        self.x3_net_2 = simpleNN(2)\n",
    "        self.x4_net_2 = simpleNN(2)\n",
    "        self.x5_net_2 = simpleNN(2)\n",
    "        self.x6_net_2 = simpleNN(2)\n",
    "        self.x7_net_2 = simpleNN(2)\n",
    "        self.x8_net_2 = simpleNN(2)\n",
    "        self.y1_net_2 = simpleNN(2)\n",
    "        self.y2_net_2 = simpleNN(2)\n",
    "        self.y3_net_2 = simpleNN(2)\n",
    "        self.y4_net_2 = simpleNN(2)\n",
    "        self.z1_net_2 = simpleNN()\n",
    "        self.z2_net_2 = simpleNN()\n",
    "        \n",
    "        # guide 3\n",
    "        self.x1_net_3 = simpleNN(7)\n",
    "        self.x2_net_3 = simpleNN(7)\n",
    "        self.x3_net_3 = simpleNN(7)\n",
    "        self.x4_net_3 = simpleNN(7)\n",
    "        self.x5_net_3 = simpleNN(7)\n",
    "        self.x6_net_3 = simpleNN(7)\n",
    "        self.x7_net_3 = simpleNN(7)\n",
    "        self.x8_net_3 = simpleNN(7)\n",
    "        self.y1_net_3 = simpleNN(3)\n",
    "        self.y2_net_3 = simpleNN(3)\n",
    "        self.y3_net_3 = simpleNN(3)\n",
    "        self.y4_net_3 = simpleNN(3)\n",
    "        self.z1_net_3 = simpleNN()\n",
    "        self.z2_net_3 = simpleNN()\n",
    "\n",
    "        # guide 4\n",
    "        self.x1_net_4 = simpleNN(2)\n",
    "        self.x2_net_4 = simpleNN()\n",
    "        self.x3_net_4 = simpleNN(2)\n",
    "        self.x4_net_4 = simpleNN()\n",
    "        self.x5_net_4 = simpleNN(2)\n",
    "        self.x6_net_4 = simpleNN()\n",
    "        self.x7_net_4 = simpleNN(2)\n",
    "        self.x8_net_4 = simpleNN()\n",
    "        self.y1_net_4 = simpleNN(2)\n",
    "        self.y2_net_4 = simpleNN()\n",
    "        self.y3_net_4 = simpleNN(2)\n",
    "        self.y4_net_4 = simpleNN()\n",
    "        self.z1_net_4 = simpleNN(2)\n",
    "        self.z2_net_4 = simpleNN()\n",
    "        \n",
    "        # guide 5\n",
    "        self.x1_net_5 = simpleNN(14)\n",
    "        self.x2_net_5 = simpleNN(13)\n",
    "        self.x3_net_5 = simpleNN(12)\n",
    "        self.x4_net_5 = simpleNN(11)\n",
    "        self.x5_net_5 = simpleNN(10)\n",
    "        self.x6_net_5 = simpleNN(9)\n",
    "        self.x7_net_5 = simpleNN(8)\n",
    "        self.x8_net_5 = simpleNN(7)\n",
    "        self.y1_net_5 = simpleNN(6)\n",
    "        self.y2_net_5 = simpleNN(5)\n",
    "        self.y3_net_5 = simpleNN(4)\n",
    "        self.y4_net_5 = simpleNN(3)\n",
    "        self.z1_net_5 = simpleNN(2)\n",
    "        self.z2_net_5 = simpleNN()\n",
    "        \n",
    "        # guide 6\n",
    "        self.x1_net_6 = simpleNN()\n",
    "        self.x2_net_6 = simpleNN()\n",
    "        self.x3_net_6 = simpleNN()\n",
    "        self.x4_net_6 = simpleNN()\n",
    "        self.x5_net_6 = simpleNN()\n",
    "        self.x6_net_6 = simpleNN()\n",
    "        self.x7_net_6 = simpleNN()\n",
    "        self.x8_net_6 = simpleNN()\n",
    "        self.y1_net_6 = simpleNN(2)\n",
    "        self.y2_net_6 = simpleNN(2)\n",
    "        self.y3_net_6 = simpleNN(2)\n",
    "        self.y4_net_6 = simpleNN(2)\n",
    "        self.z1_net_6 = simpleNN(2)\n",
    "        self.z2_net_6 = simpleNN(2)\n",
    "        \n",
    "        # guide 7\n",
    "        self.x1_net_7 = simpleNN()\n",
    "        self.x2_net_7 = simpleNN(2)\n",
    "        self.x3_net_7 = simpleNN()\n",
    "        self.x4_net_7 = simpleNN(2)\n",
    "        self.x5_net_7 = simpleNN()\n",
    "        self.x6_net_7 = simpleNN(2)\n",
    "        self.x7_net_7 = simpleNN()\n",
    "        self.x8_net_7 = simpleNN(2)\n",
    "        self.y1_net_7 = simpleNN(2)\n",
    "        self.y2_net_7 = simpleNN(3)\n",
    "        self.y3_net_7 = simpleNN(2)\n",
    "        self.y4_net_7 = simpleNN(3)\n",
    "        self.z1_net_7 = simpleNN(2)\n",
    "        self.z2_net_7 = simpleNN(3)\n",
    "        \n",
    "        \n",
    "        # guide full_made\n",
    "        input_dim_dict = {\n",
    "            \"r\" : 1\n",
    "        }\n",
    "        var_dim_dict = {\n",
    "            \"x1\" : 1,\n",
    "            \"x2\" : 1,\n",
    "            \"x3\" : 1,\n",
    "            \"x4\" : 1,\n",
    "            \"x5\" : 1,\n",
    "            \"x6\" : 1,\n",
    "            \"x7\" : 1,\n",
    "            \"x8\" : 1,\n",
    "            \"y1\" : 1,\n",
    "            \"y2\" : 1,\n",
    "            \"y3\" : 1,\n",
    "            \"y4\" : 1,\n",
    "            \"z1\" : 1,\n",
    "            \"z2\" : 1\n",
    "        }\n",
    "        dependency_dict = {\n",
    "            \"z2\" : [\"r\"],\n",
    "            \"z1\" : [\"r\", \"z2\"],\n",
    "            \"y4\" : [\"z2\"],\n",
    "            \"y3\" : [\"z2\", \"y4\"],\n",
    "            \"y2\" : [\"z1\"],\n",
    "            \"y1\" : [\"z1\", \"y2\"],\n",
    "            \"x8\" : [\"y4\"],\n",
    "            \"x7\" : [\"y4\", \"x8\"],\n",
    "            \"x6\" : [\"y3\"],\n",
    "            \"x5\" : [\"y3\", \"x6\"],\n",
    "            \"x4\" : [\"y2\"],\n",
    "            \"x3\" : [\"y2\", \"x4\"],\n",
    "            \"x2\" : [\"y1\"],\n",
    "            \"x1\" : [\"y1\", \"x2\"]\n",
    "        }\n",
    "        self.full_made = GMADE(input_dim_dict, dependency_dict, var_dim_dict)\n",
    "        if USE_CUDA:\n",
    "            self.cuda()\n",
    "    \n",
    "    # a tree model\n",
    "    def model(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(0, 1.0))\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(0, 1.0))\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(0, 1.0))\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(0, 1.0))\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(0, 1.0))\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(0, 1.0))\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(0, 1.0))\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(0, 1.0))\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(x1+x2, 1.0))\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(x3+x4, 1.0))\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(x5+x6, 1.0))\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(x7+x8, 1.0))\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(y1+y2, 1.0))\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(y3+y4, 1.0))\n",
    "        pyro.sample(\"obs\", dist.Normal(z1+z2, 1.0), obs=obs)\n",
    "        \n",
    "    # guide 1 basically inverse the arrows in the model\n",
    "    def guide_1(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_1([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_1([obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_1([z2])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_1([z2])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_1([z1])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_1([z1])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_1([y4])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_1([y4])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_1([y3])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_1([y3])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_1([y2])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_1([y2])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_1([y1])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_1([y1])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "    \n",
    "    # guide 2 inverse the arrows in the model and add obs as dependency for each RV \n",
    "    def guide_2(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_2([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_2([obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_2([z2, obs])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_2([z2, obs])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_2([z1, obs])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_2([z1, obs])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_2([y4, obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_2([y4, obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_2([y3, obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_2([y3, obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_2([y2, obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_2([y2, obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_2([y1, obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_2([y1, obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "    \n",
    "    # guide 3 inverse the arrows and each RV depends on all RVs in previous levels\n",
    "    # i.e. x depends on all y + z + obs\n",
    "    def guide_3(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_3([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_3([obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_3([z1, z2, obs])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_3([z1, z2, obs])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_3([z1, z2, obs])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_3([z1, z2, obs])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "    \n",
    "    # guide 4 inverse the arrows and each RV depends on its previously sampled sibling (if any) at the same level\n",
    "    # i.e. x1 depends on y1 and x2, y1 depends on z1 and y2, y3 depends on z2 and y4\n",
    "    # this should be minimum failthful\n",
    "    def guide_4(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_4([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_4([z2, obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_4([z2])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_4([y4, z2])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_4([z1])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_4([y2, z1])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_4([y4])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_4([x8, y4])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_4([y3])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_4([x6, y3])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_4([y2])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_4([x4, y2])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_4([y1])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_4([x2, y1])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "    \n",
    "    # guide 5 inverse the arrows and each RV depends on all previously sampled RV\n",
    "    # fully-connected\n",
    "    def guide_5(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_5([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_5([z2, obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_5([z1, z2, obs])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_5([y4, z1, z2, obs])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_5([y3, y4, z1, z2, obs])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_5([y2, y3, y4, z1, z2, obs])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_5([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_5([x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_5([x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_5([x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_5([x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_5([x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_5([x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_5([x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "        \n",
    "    # guide 6 the order to sample RV is the same as the model but given obs as dependency for xs\n",
    "    def guide_6(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "\n",
    "        x1_mean, x1_std = self.x1_net_6([obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "        x2_mean, x2_std = self.x2_net_6([obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x3_mean, x3_std = self.x3_net_6([obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x4_mean, x4_std = self.x4_net_6([obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))        \n",
    "        x5_mean, x5_std = self.x5_net_6([obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x6_mean, x6_std = self.x6_net_6([obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))        \n",
    "        x7_mean, x7_std = self.x7_net_6([obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x8_mean, x8_std = self.x8_net_6([obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        y1_mean, y1_std = self.y1_net_6([x1, x2])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))        \n",
    "        y2_mean, y2_std = self.y2_net_6([x3, x4])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))        \n",
    "        y3_mean, y3_std = self.y3_net_6([x5, x6])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))        \n",
    "        y4_mean, y4_std = self.y4_net_6([x7, x8])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))        \n",
    "        z1_mean, z1_std = self.z1_net_6([y1, y2])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))        \n",
    "        z2_mean, z2_std = self.z2_net_6([y3, y4])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "    \n",
    "    # guide 7 is similar to guide 6 but each RV dependent on its subling\n",
    "    # the inverse of guide 4\n",
    "    def guide_7(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "\n",
    "        x1_mean, x1_std = self.x1_net_7([obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "        x2_mean, x2_std = self.x2_net_7([x1, obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x3_mean, x3_std = self.x3_net_7([obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x4_mean, x4_std = self.x4_net_7([x3, obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))        \n",
    "        x5_mean, x5_std = self.x5_net_7([obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x6_mean, x6_std = self.x6_net_7([x5, obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))        \n",
    "        x7_mean, x7_std = self.x7_net_7([obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x8_mean, x8_std = self.x8_net_7([x7, obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        y1_mean, y1_std = self.y1_net_7([x1, x2])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))        \n",
    "        y2_mean, y2_std = self.y2_net_7([x3, x4, y1])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))        \n",
    "        y3_mean, y3_std = self.y3_net_7([x5, x6])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))        \n",
    "        y4_mean, y4_std = self.y4_net_7([x7, x8, y3])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))        \n",
    "        z1_mean, z1_std = self.z1_net_7([y1, y2])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))        \n",
    "        z2_mean, z2_std = self.z2_net_7([y3, y4, z1])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "    \n",
    "    def guide_full_made(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        input_made = {\n",
    "                \"r\" : torch.unsqueeze(obs, dim=0)\n",
    "        }\n",
    "        output_dict = self.full_made(input_made, suffix=\"\")\n",
    "        \n",
    "def generate_data():\n",
    "    x_len = 8\n",
    "    xs = torch.randn(x_len)\n",
    "    ys = []\n",
    "    i = 0\n",
    "    while i < len(xs):\n",
    "        y = dist.Normal(xs[i] + xs[i+1], 2).sample()\n",
    "        ys.append(y)\n",
    "        i +=2\n",
    "        \n",
    "    zs = []\n",
    "    i = 0\n",
    "    while i < len(ys):\n",
    "        z = dist.Normal(ys[i] + ys[i+1], 1.5).sample()\n",
    "        zs.append(z)\n",
    "        i +=2\n",
    "        \n",
    "        \n",
    "    obs = dist.Normal(zs[0] + zs[1], 1).sample()\n",
    "    return obs\n",
    "    \n",
    "USE_CUDA = True\n",
    "data = []\n",
    "num_data = 100\n",
    "for _ in range(num_data):\n",
    "    data.append(generate_data().unsqueeze(0))\n",
    "data = torch.stack(data)\n",
    "batches = []\n",
    "for i in range(5):\n",
    "    batches.append(data[int(i * num_data / 5): int((i + 1) * num_data / 5)])\n",
    "print(batches)\n",
    "experiment = Experiment(USE_CUDA)\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.95, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "guide = experiment.guide_full_made # guide_1\n",
    "\n",
    "# pyro auto guide\n",
    "#guide = AutoNormal(experiment.model)\n",
    "#guide = AutoMultivariateNormal(experiment.model)\n",
    "#guide = AutoDiagonalNormal(experiment.model)\n",
    "\n",
    "svi = SVI(experiment.model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "\n",
    "n_steps = 200\n",
    "log_interval = 10\n",
    "# do gradient steps\n",
    "loss = 0\n",
    "loss_track = []\n",
    "for step in range(1, n_steps + 1):\n",
    "    imme_loss = 0\n",
    "    \n",
    "    for obs in data:\n",
    "        if USE_CUDA:\n",
    "            obs = obs.cuda()\n",
    "        imme_loss += svi.step(obs) / num_data\n",
    "        \n",
    "    loss_track.append(imme_loss)\n",
    "    loss += imme_loss / log_interval\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print(\"[Step {}/{}] Immediate Loss: {} Accumlated Loss: {}\".format(step, n_steps, imme_loss, loss))\n",
    "        loss = 0\n",
    "    \n",
    "plt.plot(loss_track)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 1\n",
    "[Step 10/100] Immediate Loss: 5.6792811819911035 Accumlated Loss: 8.161501753419639\n",
    "[Step 20/100] Immediate Loss: 5.6724499085545546 Accumlated Loss: 5.7964787363111965\n",
    "[Step 30/100] Immediate Loss: 5.761731808781624 Accumlated Loss: 5.581517954558135\n",
    "[Step 40/100] Immediate Loss: 6.112146431803706 Accumlated Loss: 5.703019751578569\n",
    "[Step 50/100] Immediate Loss: 5.990561635196209 Accumlated Loss: 5.61033443725109\n",
    "[Step 60/100] Immediate Loss: 5.79047949910164 Accumlated Loss: 5.709876654744148\n",
    "[Step 70/100] Immediate Loss: 5.865784194469453 Accumlated Loss: 5.6813742448389535\n",
    "[Step 80/100] Immediate Loss: 5.5839250811934455 Accumlated Loss: 5.665409379035234\n",
    "[Step 90/100] Immediate Loss: 5.802031826376916 Accumlated Loss: 5.689023856550455\n",
    "[Step 100/100] Immediate Loss: 5.711089228987696 Accumlated Loss: 5.733322246074676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 2\n",
    "[Step 10/100] Immediate Loss: 6.268227699697018 Accumlated Loss: 9.823156678080556\n",
    "[Step 20/100] Immediate Loss: 6.012787947654725 Accumlated Loss: 6.139076143831014\n",
    "[Step 30/100] Immediate Loss: 6.102070910632606 Accumlated Loss: 5.927030056893825\n",
    "[Step 40/100] Immediate Loss: 6.45776209264994 Accumlated Loss: 5.981230340063572\n",
    "[Step 50/100] Immediate Loss: 6.256524928808213 Accumlated Loss: 5.893774724751712\n",
    "[Step 60/100] Immediate Loss: 6.069752818644045 Accumlated Loss: 5.9795956534147265\n",
    "[Step 70/100] Immediate Loss: 6.092835750877859 Accumlated Loss: 5.928910363674163\n",
    "[Step 80/100] Immediate Loss: 5.949914609193803 Accumlated Loss: 5.921238815844059\n",
    "[Step 90/100] Immediate Loss: 6.110138435661791 Accumlated Loss: 5.9243319559395315\n",
    "[Step 100/100] Immediate Loss: 5.967664820253849 Accumlated Loss: 5.956207058787346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 3\n",
    "[Step 10/100] Immediate Loss: 6.570058162808415 Accumlated Loss: 9.397841033637526\n",
    "[Step 20/100] Immediate Loss: 6.147684178054332 Accumlated Loss: 6.235418024212122\n",
    "[Step 30/100] Immediate Loss: 6.111919716298578 Accumlated Loss: 5.938203674733639\n",
    "[Step 40/100] Immediate Loss: 6.531079505085945 Accumlated Loss: 5.937320747315884\n",
    "[Step 50/100] Immediate Loss: 6.133750829696654 Accumlated Loss: 5.836949352592229\n",
    "[Step 60/100] Immediate Loss: 5.995875943303109 Accumlated Loss: 5.909800890862941\n",
    "[Step 70/100] Immediate Loss: 6.01717264592648 Accumlated Loss: 5.870649518340828\n",
    "[Step 80/100] Immediate Loss: 5.837504681944848 Accumlated Loss: 5.835405748039484\n",
    "[Step 90/100] Immediate Loss: 6.031392835974693 Accumlated Loss: 5.827427438616752\n",
    "[Step 100/100] Immediate Loss: 5.949472520351413 Accumlated Loss: 5.865983818709852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "### guide 4 ### best\n",
    "[Step 10/100] Immediate Loss: 4.377868088781835 Accumlated Loss: 6.545501601159573\n",
    "[Step 20/100] Immediate Loss: 3.575750644803046 Accumlated Loss: 4.03719574072957\n",
    "[Step 30/100] Immediate Loss: 3.5968227416276943 Accumlated Loss: 3.657659743905067\n",
    "[Step 40/100] Immediate Loss: 3.5601295506954207 Accumlated Loss: 3.6178785299956795\n",
    "[Step 50/100] Immediate Loss: 3.4762910395860662 Accumlated Loss: 3.543176322728395\n",
    "[Step 60/100] Immediate Loss: 3.52601896584034 Accumlated Loss: 3.533123803049326\n",
    "[Step 70/100] Immediate Loss: 3.449901377856731 Accumlated Loss: 3.498376666098833\n",
    "[Step 80/100] Immediate Loss: 3.472165140509606 Accumlated Loss: 3.527985264599323\n",
    "[Step 90/100] Immediate Loss: 3.535960964262485 Accumlated Loss: 3.4987394436597814\n",
    "[Step 100/100] Immediate Loss: 3.4975102710723887 Accumlated Loss: 3.5023412067890174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "### gmade ###\n",
    "[Step 10/100] Immediate Loss: 6.091697503328321 Accumlated Loss: 11.86150044506788\n",
    "[Step 20/100] Immediate Loss: 4.033280954957009 Accumlated Loss: 4.759111630380153\n",
    "[Step 30/100] Immediate Loss: 3.729229698777201 Accumlated Loss: 3.9092313872575764\n",
    "[Step 40/100] Immediate Loss: 3.6316562518477444 Accumlated Loss: 3.7232759437263008\n",
    "[Step 50/100] Immediate Loss: 3.5912016203999513 Accumlated Loss: 3.5814507492780683\n",
    "[Step 60/100] Immediate Loss: 3.409006274640559 Accumlated Loss: 3.4948545873165124\n",
    "[Step 70/100] Immediate Loss: 3.545635481178759 Accumlated Loss: 3.461448216050863\n",
    "[Step 80/100] Immediate Loss: 3.5296939200162885 Accumlated Loss: 3.425615511506796\n",
    "[Step 90/100] Immediate Loss: 3.399731188714504 Accumlated Loss: 3.419999708920717\n",
    "[Step 100/100] Immediate Loss: 3.2696896982193002 Accumlated Loss: 3.3859521727561956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 5\n",
    "[Step 10/100] Immediate Loss: 5.436824112832545 Accumlated Loss: 7.459522048622368\n",
    "[Step 20/100] Immediate Loss: 4.522601895034313 Accumlated Loss: 4.697016129463912\n",
    "[Step 30/100] Immediate Loss: 4.035572609305381 Accumlated Loss: 4.087585103064775\n",
    "[Step 40/100] Immediate Loss: 3.9674540817737576 Accumlated Loss: 3.922967136412859\n",
    "[Step 50/100] Immediate Loss: 3.819277352690697 Accumlated Loss: 3.8670592607259744\n",
    "[Step 60/100] Immediate Loss: 3.8970872554183003 Accumlated Loss: 3.8228334636390207\n",
    "[Step 70/100] Immediate Loss: 3.6495595994591716 Accumlated Loss: 3.728844232827424\n",
    "[Step 80/100] Immediate Loss: 3.6761886674165725 Accumlated Loss: 3.7416907757222653\n",
    "[Step 90/100] Immediate Loss: 3.6880584159493455 Accumlated Loss: 3.6743881301581856\n",
    "[Step 100/100] Immediate Loss: 3.7141958668828003 Accumlated Loss: 3.684455200225115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 6\n",
    "[Step 10/100] Immediate Loss: 8.01269422084093 Accumlated Loss: 15.49425634944439\n",
    "[Step 20/100] Immediate Loss: 6.9067663696408275 Accumlated Loss: 7.9501663804352285\n",
    "[Step 30/100] Immediate Loss: 8.029220328330993 Accumlated Loss: 8.010903750896453\n",
    "[Step 40/100] Immediate Loss: 8.31351687759161 Accumlated Loss: 8.1114898557961\n",
    "[Step 50/100] Immediate Loss: 8.786913882493973 Accumlated Loss: 7.755306751757858\n",
    "[Step 60/100] Immediate Loss: 7.783528136909008 Accumlated Loss: 7.7925652467012405\n",
    "[Step 70/100] Immediate Loss: 8.006914387047292 Accumlated Loss: 7.681327867358923\n",
    "[Step 80/100] Immediate Loss: 8.374721429347991 Accumlated Loss: 7.807788733184337\n",
    "[Step 90/100] Immediate Loss: 7.715019945800301 Accumlated Loss: 7.808754653304815\n",
    "[Step 100/100] Immediate Loss: 8.256794970929624 Accumlated Loss: 7.728429790437221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 7\n",
    "[Step 10/100] Immediate Loss: 7.946083300113675 Accumlated Loss: 15.880016953587534\n",
    "[Step 20/100] Immediate Loss: 6.707426010072232 Accumlated Loss: 7.429752558678389\n",
    "[Step 30/100] Immediate Loss: 6.904689866006373 Accumlated Loss: 7.198620594471693\n",
    "[Step 40/100] Immediate Loss: 7.047841712534428 Accumlated Loss: 7.0875664424300195\n",
    "[Step 50/100] Immediate Loss: 7.573134193122387 Accumlated Loss: 6.855033908337354\n",
    "[Step 60/100] Immediate Loss: 7.103918403685091 Accumlated Loss: 6.874631712168455\n",
    "[Step 70/100] Immediate Loss: 6.944367031455041 Accumlated Loss: 6.938687078088522\n",
    "[Step 80/100] Immediate Loss: 7.446044615507124 Accumlated Loss: 7.044109266996383\n",
    "[Step 90/100] Immediate Loss: 6.661473557949067 Accumlated Loss: 6.902258327007294\n",
    "[Step 100/100] Immediate Loss: 7.03185636729002 Accumlated Loss: 6.8993669908344755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoNormal \n",
    "[Step 10/100] Immediate Loss: 29.661400873661044 Accumlated Loss: 34.381083221018315\n",
    "[Step 20/100] Immediate Loss: 21.721210796236996 Accumlated Loss: 24.125531654298307\n",
    "[Step 30/100] Immediate Loss: 20.717992586493505 Accumlated Loss: 20.629015110522506\n",
    "[Step 40/100] Immediate Loss: 20.31778262376786 Accumlated Loss: 20.401564517676828\n",
    "[Step 50/100] Immediate Loss: 21.517062507569797 Accumlated Loss: 20.607605726897724\n",
    "[Step 60/100] Immediate Loss: 20.558893247246754 Accumlated Loss: 20.390989627033466\n",
    "[Step 70/100] Immediate Loss: 20.57022605895995 Accumlated Loss: 20.47847183179855\n",
    "[Step 80/100] Immediate Loss: 19.823867598176 Accumlated Loss: 20.282766120791436\n",
    "[Step 90/100] Immediate Loss: 20.220103700757026 Accumlated Loss: 20.263966775059696\n",
    "[Step 100/100] Immediate Loss: 20.07956038057804 Accumlated Loss: 20.539366428911684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoMultivariateNormal\n",
    "[Step 10/100] Immediate Loss: 29.280232212543496 Accumlated Loss: 34.96955828201771\n",
    "[Step 20/100] Immediate Loss: 20.823702557683003 Accumlated Loss: 23.777785731434825\n",
    "[Step 30/100] Immediate Loss: 17.56564211547375 Accumlated Loss: 18.975887567698955\n",
    "[Step 40/100] Immediate Loss: 18.09688677370549 Accumlated Loss: 18.158192227423196\n",
    "[Step 50/100] Immediate Loss: 17.358041861653323 Accumlated Loss: 17.932833659708496\n",
    "[Step 60/100] Immediate Loss: 17.660284592509267 Accumlated Loss: 17.789189765751363\n",
    "[Step 70/100] Immediate Loss: 16.889609196186065 Accumlated Loss: 17.35965327256918\n",
    "[Step 80/100] Immediate Loss: 18.56209426760674 Accumlated Loss: 17.78802405971289\n",
    "[Step 90/100] Immediate Loss: 17.714577720761305 Accumlated Loss: 17.483879809975623\n",
    "[Step 100/100] Immediate Loss: 16.55987268984317 Accumlated Loss: 17.230655351817603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoDiagonalNormal\n",
    "[Step 10/100] Immediate Loss: 29.594689139127723 Accumlated Loss: 35.09126758885384\n",
    "[Step 20/100] Immediate Loss: 22.305745403170594 Accumlated Loss: 24.653422838687895\n",
    "[Step 30/100] Immediate Loss: 19.765058637857443 Accumlated Loss: 20.882928909182546\n",
    "[Step 40/100] Immediate Loss: 20.646754955649378 Accumlated Loss: 20.50682894957065\n",
    "[Step 50/100] Immediate Loss: 20.2246539914608 Accumlated Loss: 20.506671326756482\n",
    "[Step 60/100] Immediate Loss: 21.094068167805677 Accumlated Loss: 20.755982849299905\n",
    "[Step 70/100] Immediate Loss: 20.336222262978545 Accumlated Loss: 20.427405071496963\n",
    "[Step 80/100] Immediate Loss: 21.357484986782072 Accumlated Loss: 20.727729279518126\n",
    "[Step 90/100] Immediate Loss: 21.060880010724066 Accumlated Loss: 20.713297606468206\n",
    "[Step 100/100] Immediate Loss: 20.076601029038425 Accumlated Loss: 20.360575951337818"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
