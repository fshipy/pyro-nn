{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "standard-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hid_orderings [1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 2, 1, 2, 0, 0, 0] size 16\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 0, 0, 0, 0, 0, 0, 0, 1] size 9\n",
      "expanded_output_ordering [2, 2] size 2\n",
      "hid_orderings [1, 2, 1, 3, 2, 0, 0, 2, 0, 3, 0, 3, 0, 4, 2, 6, 1, 3, 5, 2, 2, 4, 6, 6, 2, 5, 4, 2, 1, 0, 6, 0] size 32\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1, 1, 1, 1, 1, 1, 1, 1, 2] size 10\n",
      "expanded_output_ordering [3, 3, 6, 6] size 4\n",
      "hid_orderings [7, 8, 2, 9, 13, 11, 5, 1, 14, 7, 9, 12, 5, 0, 2, 10, 5, 13, 11, 14, 10, 4, 11, 0, 7, 13, 7, 2, 7, 8, 5, 13, 5, 4, 7, 3, 4, 5, 14, 1, 2, 2, 14, 13, 2, 8, 1, 4, 5, 8, 13, 12, 8, 11, 7, 10, 11, 3, 12, 8, 7, 5, 3, 7] size 64\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3] size 11\n",
      "expanded_output_ordering [12, 12, 8, 8, 9, 9] size 6\n",
      "hid_orderings [7, 39, 56, 49, 38, 31, 43, 7, 3, 54, 22, 42, 26, 22, 48, 21, 47, 51, 11, 61, 3, 26, 31, 52, 11, 35, 23, 58, 7, 16, 51, 20, 59, 3, 24, 6, 36, 60, 20, 40, 16, 27, 36, 15, 43, 31, 57, 17, 60, 11, 1, 41, 46, 30, 2, 62, 8, 54, 56, 13, 54, 29, 56, 55, 48, 18, 36, 61, 20, 24, 43, 3, 15, 10, 26, 26, 38, 31, 10, 2, 33, 48, 58, 52, 19, 54, 29, 17, 5, 27, 34, 17, 12, 59, 4, 59, 25, 49, 6, 35, 47, 27, 22, 31, 12, 13, 15, 2, 57, 4, 58, 0, 41, 34, 2, 59, 46, 55, 27, 18, 11, 7, 42, 51, 13, 1, 22, 9, 14, 13, 41, 27, 35, 24, 61, 31, 2, 8, 46, 57, 7, 28, 54, 34, 1, 32, 18, 13, 59, 6, 52, 47, 37, 20, 5, 42, 60, 11, 7, 29, 53, 0, 49, 5, 2, 9, 28, 59, 41, 3, 9, 29, 5, 42, 22, 60, 51, 51, 14, 27, 42, 5, 0, 20, 25, 49, 51, 3, 4, 58, 18, 7, 49, 49, 38, 48, 54, 53, 16, 26, 62, 23, 39, 53, 55, 37, 22, 43, 0, 22, 47, 40, 5, 45, 38, 28, 6, 37, 46, 12, 39, 4, 12, 22, 49, 17, 56, 61, 10, 1, 45, 48, 56, 42, 49, 23, 6, 62, 38, 17, 56, 4, 3, 16, 8, 25, 39, 32, 34, 7, 33, 61, 20, 50, 40, 48] size 256\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5] size 13\n",
      "expanded_output_ordering [7, 7, 33, 33, 15, 15, 37, 37] size 8\n",
      "hid_orderings [41, 27, 14, 5, 7, 6, 48, 52, 51, 55, 22, 42, 51, 8, 0, 13, 57, 50, 8, 53, 11, 16, 10, 55, 52, 4, 1, 49, 24, 35, 40, 34, 11, 19, 37, 49, 21, 1, 9, 17, 60, 26, 31, 26, 54, 50, 9, 41, 34, 56, 3, 36, 11, 35, 51, 27, 33, 23, 59, 54, 5, 2, 33, 19, 1, 42, 9, 40, 6, 44, 52, 50, 55, 38, 21, 11, 41, 61, 41, 6, 2, 9, 50, 8, 44, 36, 22, 26, 16, 25, 11, 33, 41, 34, 62, 58, 56, 38, 9, 47, 59, 37, 28, 41, 39, 52, 30, 23, 50, 29, 40, 17, 33, 35, 36, 49, 21, 10, 23, 36, 30, 23, 26, 11, 6, 41, 4, 36, 61, 31, 44, 48, 30, 33, 14, 39, 33, 21, 59, 39, 26, 56, 48, 61, 21, 30, 14, 45, 52, 43, 44, 9, 58, 8, 50, 10, 43, 46, 11, 35, 15, 60, 11, 61, 31, 0, 9, 22, 42, 40, 14, 26, 53, 29, 20, 40, 54, 43, 61, 27, 0, 2, 61, 23, 49, 61, 34, 42, 35, 45, 51, 43, 41, 2, 7, 28, 51, 52, 26, 52, 21, 40, 7, 60, 22, 19, 4, 12, 2, 35, 61, 0, 30, 26, 44, 4, 11, 21, 20, 26, 30, 24, 22, 59, 6, 16, 43, 23, 11, 54, 26, 40, 58, 58, 27, 28, 2, 3, 58, 59, 24, 52, 46, 23, 3, 38, 7, 27, 31, 2, 12, 18, 44, 9, 38, 22] size 256\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5] size 13\n",
      "expanded_output_ordering [21, 21, 17, 17, 37, 37] size 6\n",
      "hid_orderings [3, 6, 4, 5, 1, 1, 3, 1, 2, 5, 1, 3, 2, 4, 3, 6, 3, 6, 0, 2, 3, 0, 6, 5, 2, 3, 3, 1, 0, 4, 5, 3] size 32\n",
      "num hid layers: 1\n",
      "expanded_input_ordering [0, 1, 2, 2, 2, 2, 2, 2, 2, 2] size 10\n",
      "expanded_output_ordering [6, 6] size 2\n",
      "number of levels: 6\n",
      "input_levels [['h', 'r'], ['z2', 'h', 'r'], ['z2', 'z1', 'y4', 'h'], ['y3', 'y4', 'h', 'y2', 'z1', 'x8'], ['x6', 'y3', 'h', 'x4', 'y2', 'y1'], ['x2', 'y1', 'h']]\n",
      "out_levels [['z2'], ['y4', 'z1'], ['y3', 'y2', 'x8'], ['x6', 'x7', 'x4', 'y1'], ['x5', 'x2', 'x3'], ['x1']]\n",
      "[Step 10/100] Immediate Loss: 22.587351982593542 Accumlated Loss: 33.70665139359235\n",
      "[Step 20/100] Immediate Loss: 20.323317878842342 Accumlated Loss: 20.64148927158117\n",
      "[Step 30/100] Immediate Loss: 19.377580498456965 Accumlated Loss: 19.61169250741601\n",
      "[Step 40/100] Immediate Loss: 19.286448630988595 Accumlated Loss: 19.423534301012754\n",
      "[Step 50/100] Immediate Loss: 19.379515575468538 Accumlated Loss: 19.38483266532421\n",
      "[Step 60/100] Immediate Loss: 19.431174555718894 Accumlated Loss: 19.333751212775706\n",
      "[Step 70/100] Immediate Loss: 19.20345581322908 Accumlated Loss: 19.347703420668843\n",
      "[Step 80/100] Immediate Loss: 19.257125191986567 Accumlated Loss: 19.241439772397282\n",
      "[Step 90/100] Immediate Loss: 19.305208963453765 Accumlated Loss: 19.25091784054041\n",
      "[Step 100/100] Immediate Loss: 19.30832313328981 Accumlated Loss: 19.307121041238307\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfHklEQVR4nO3deZCcd33n8fe37+me+9BopJE0ki102LIteyxsMEkW4wCxwSZZWBOTdSUQV21lCWSpIk7IsSQhkM0mC5UFEscJKxaC7SKAXY4DGIExh9f22JYPWbJ1n3NLcx890/3dP7pnrFujY9R6+vm8qqZ6nqev72965tO/+fXze37m7oiISPBESl2AiIicGwW4iEhAKcBFRAJKAS4iElAKcBGRgFKAi4gElAJcRCSgFOBSlsxsj5m9o9R1iMwnBbiISEApwCU0zCxpZp83s0PFr8+bWbJ4XaOZPWpmA2Z22Mx+YmaR4nW/b2YHzWzYzF4zs5tL2xKRglipCxC5iD4F3ABcAzjwMPBHwB8DnwAOAE3F294AuJmtAv4rcL27HzKzNiB6ccsWOTn1wCVM7gL+zN173L0X+DTwG8XrpoAWYJm7T7n7T7xwoqAckATWmlnc3fe4+86SVC9yHAW4hMkiYO9R23uL+wD+GtgBfN/MdpnZvQDuvgP4OPDfgR4ze8DMFiFyCVCAS5gcApYdtb20uA93H3b3T7j7CuA9wH+bGet2939x95uK93Xgry5u2SInpwCXchY3s9TMF/AN4I/MrMnMGoE/Ab4GYGa3mdnlZmbAEIWhk5yZrTKztxc/7JwAxovXiZScAlzK2WMUAnfmKwV0AC8BLwPPA39RvO1K4AfACPAU8CV3f4LC+PfngD6gC1gA/OFFa4HIaZgWdBARCSb1wEVEAkoBLiISUApwEZGAUoCLiATURZ1K39jY6G1tbRfzKUVEAu+5557rc/em4/df1ABva2ujo6PjYj6liEjgmdnek+3XEIqISEApwEVEAkoBLiISUApwEZGAUoCLiASUAlxEJKAU4CIiARWIAN+0tZsvPbGj1GWIiFxSAhHgP93Rxxd/qAAXETlaIAJ8YXWK0WyOkcnpUpciInLJCESAN1enAOganChxJSIil45ABXj3kAJcRGRGIAJ8YY164CIixwtEgDdXJwHoHlaAi4jMCESApxMxqlIxutUDFxGZNacAN7NaM/ummW0zs61mdqOZ1ZvZ42a2vXhZN5+FLqxO0aUxcBGRWXPtgX8B+K67rwauBrYC9wKb3H0lsKm4PW8W1qToHpqcz6cQEQmUMwa4mVUDvwD8E4C7Z919ALgd2Fi82UbgjvkpsWBBVUpHoYiIHGUuPfAVQC/wFTN7wczuN7MM0OzunQDFywUnu7OZ3WNmHWbW0dvbe86FLqxJ0jM8SS7v5/wYIiLlZC4BHgOuBb7s7uuBUc5iuMTd73P3dndvb2o6YU3OOVtYnSKXd/pHNIwiIgJzC/ADwAF3f7q4/U0Kgd5tZi0Axcue+Smx4I3JPApwERGYQ4C7exew38xWFXfdDLwKPALcXdx3N/DwvFRYNDudXuPgIiJAYXhkLj4KfN3MEsAu4DcphP9DZvZhYB/w/vkpsWB2NqYCXEQEmGOAu/tmoP0kV918Qas5jcbKJBGDHgW4iAgQkJmYANGI0VSV1PlQRESKAhPgoNmYIiJHC1SAN1drMo+IyIxABbim04uIvCFQAd5cnWJwfIqJqVypSxERKbnABThoYQcREQhYgC/U0moiIrMCFeAzK/PoSBQRkaAFeI164CIiMwIV4FXJGOlElK5BHYkiIhKoADczFlantLixiAgBC3CABdVJLW4sIkIAA1zT6UVECgIX4M01KXqGJnHX0moiEm6BC/DqVJxsLk82ly91KSIiJRW4AM8kogCMTWo6vYiEW+ACPJ0srEExmp0ucSUiIqUVuADPJAoBPpZVD1xEwi1wAZ4uDqGMTqoHLiLhFtgAVw9cRMIucAGemRkDVw9cREIucAE+0wMf16IOIhJygQvwN3rgCnARCbfABfgbY+AaQhGRcAtggKsHLiICAQzwaMRIxiLqgYtI6AUuwKEwDq6ZmCISdoEM8HQiqnOhiEjoBTLAM4mYJvKISOgFMsDTyaiGUEQk9AIZ4OqBi4gENMArElFNpReR0AtkgGcSUfXARST0Ahng6WRMx4GLSOgFMsAziahmYopI6AUywNOJGONTOfJ5rUwvIuEVyADPJHVKWRGR2FxuZGZ7gGEgB0y7e7uZ1QMPAm3AHuAD7n5kfso8VkXijYWNZ04vKyISNmfTA/8P7n6Nu7cXt+8FNrn7SmBTcfuiyMycUlbj4CISYuczhHI7sLH4/UbgjvOuZo7SR/XARUTCaq4B7sD3zew5M7unuK/Z3TsBipcLTnZHM7vHzDrMrKO3t/f8K+aNMXAdCy4iYTbXAeS3uvshM1sAPG5m2+b6BO5+H3AfQHt7+wU5bOSNRR3UAxeR8JpTD9zdDxUve4BvAxuAbjNrAShe9sxXkcebPQpFPXARCbEzBriZZcysauZ74JeBV4BHgLuLN7sbeHi+ijxeZnYMXAEuIuE1lyGUZuDbZjZz+39x9++a2bPAQ2b2YWAf8P75K/NYFVrYWETkzAHu7ruAq0+yvx+4eT6KOpOMFjYWEQnmTMxUPIKZeuAiEm6BDHAzI5OIqQcuIqEWyACH4sLG6oGLSIgFNsAzSS2rJiLhFtgAr4irBy4i4RbYAM8ktaiDiIRbYAM8ndCyaiISboEN8EwyqpmYIhJqgQ3wdCLGmE5mJSIhFtgAzyTUAxeRcAtsgKeTMZ2NUERCLbgBHo+SzeXJTudLXYqISEkEN8CLixmrFy4iYRXYAJ9Z2FjrYopIWAU2wGd64DoWXETCKrABPtsD12xMEQmpwAb47MLG6oGLSEgFOMC1sLGIhFtgA3xmZXpN5hGRsApsgM8MoWg6vYiEVWADfHZhY/XARSSkAhvgFcUxcPXARSSsAhvgiViERDSiHriIhFZgAxwgndSyaiISXsEO8HhUCxuLSGgFO8CTWlZNRMIr0AGeSWhhYxEJr0AHuBY2FpEwC3SAZ5LqgYtIeAU6wNUDF5EwC3iAa2FjEQmvgAe4FjYWkfAKdIBnklFGs9O4e6lLERG56AId4OlEDHeYmNLK9CISPoEO8MpU4YyEwxNTJa5EROTiC3SA11TEARgcV4CLSPjMOcDNLGpmL5jZo8XtejN73My2Fy/r5q/Mk1OAi0iYnU0P/GPA1qO27wU2uftKYFNx+6JSgItImM0pwM2sFbgVuP+o3bcDG4vfbwTuuKCVzUFtMcAHxhTgIhI+c+2Bfx74JHD04R7N7t4JULxccGFLOzP1wEUkzM4Y4GZ2G9Dj7s+dyxOY2T1m1mFmHb29vefyEKdUrQAXkRCbSw/8rcB7zWwP8ADwdjP7GtBtZi0Axcuek93Z3e9z93Z3b29qarpAZRdEI0ZVMqYAF5FQOmOAu/sfuHuru7cBdwI/dPcPAY8Adxdvdjfw8LxVeRo16bgCXERC6XyOA/8ccIuZbQduKW5fdDUVCnARCafY2dzY3Z8Anih+3w/cfOFLOjsKcBEJq0DPxAQFuIiEV+ADvDYd13HgIhJKgQ/w6oo4Q+NTOqWsiIRO4AO8piJONpfXKWVFJHTKIsBBk3lEJHwCH+C1FQlAAS4i4RP4AK+ZPaFVtsSViIhcXGUT4OqBi0jYKMBFRAIq+AGeVoCLSDgFPsCrkjHMFOAiEj6BD/BIxKhOaTq9iIRP4AMcdD4UEQmnsgjwWp0TXERCqCwCvKZCJ7QSkfApiwCfOaGViEiYlEWAawxcRMKoLAK8thjgOqWsiIRJWQR4TUWc6bwzms2VuhQRkYumbAIcNJlHRMKlvAJcR6KISIiUR4DrfCgiEkLlEeAaQhGRECqzANeiDiISHmUW4OqBi0h4lEWAVyZjRCOmABeRUCmLADczzcYUkdApiwAHndBKRMKnbAK8Wj1wEQmZsgnwWp2RUERCpmwCXGPgIhI2ZRXgAwpwEQmRsgrwofEp8nmdUlZEwqFsArw2HSfvMJKdLnUpIiIXRdkE+MxszIFRDaOISDiUTYC3NWYA2NE7XOJKREQujrIJ8NULqwB49dBQiSsREbk4zhjgZpYys2fM7EUz22Jmny7urzezx81se/Gybv7LPbWqVJxlDWle7VSAi0g4zKUHPgm83d2vBq4B3mVmNwD3ApvcfSWwqbhdUmtbqtUDF5HQOGOAe8FIcTNe/HLgdmBjcf9G4I75KPBsrG2pZk//GCOTOhJFRMrfnMbAzSxqZpuBHuBxd38aaHb3ToDi5YJ5q3KO1i6qBmCbhlFEJATmFODunnP3a4BWYIOZXTnXJzCze8ysw8w6ent7z7HMuVnTUghwjYOLSBic1VEo7j4APAG8C+g2sxaA4mXPKe5zn7u3u3t7U1PT+VV7Bi01KWrTcY2Di0gozOUolCYzqy1+XwG8A9gGPALcXbzZ3cDD81TjnJlZ4YNM9cBFJATm0gNvAX5kZi8Bz1IYA38U+Bxwi5ltB24pbpfc2pZqtnUNM53Ll7oUEZF5FTvTDdz9JWD9Sfb3AzfPR1HnY+2iarLTeXb1jfKm5qpSlyMiMm/KZibmjJkjUTQOLiLlruwC/LKmShLRiMbBRaTslV2Ax6MR3rSwUj1wESl7ZRfgUPggc2vnEO5a3EFEylfZBnj/aJbuoclSlyIiMm/KMsCvW1YPwA+3nXRukYhIWSjLAL9ycTWrmqt48Nl9pS5FRGTelGWAmxn/6folvHhgkK06GkVEylRZBjjA+9YvJhGN8OCz+0tdiojIvCjbAK/LJPjlK5r5zuaDTEzlSl2OiMgFV7YBDnDn9UsZGJvi+692l7oUEZELrqwD/C2XNdBaV8FDGkYRkTJU1gEeiRgfaF/CT3f0sa9/rNTliIhcUGUd4ADvb28lFjE2PrWn1KWIiFxQZR/gLTUV3HZVCw8+u5+hialSlyMicsGUfYADfORtKxiZnOaBZzSxR0TKRygC/MrFNdy4ooGv/GwPU1qpR0TKRCgCHOCeX1hB5+AE//ZSZ6lLERG5IEIT4L/4piYuX1DJfU/u0mlmRaQshCbAIxHjIzct59XOIZ7c3lfqckREzltoAhzgjvWLWVqf5tOPbGFyWtPrRSTYQhXgqXiUP7/jSnb1jfLlJ3aWuhwRkfMSqgCHwlj4e65exJd+tJNdvSOlLkdE5JyFLsAB/vi2NSTjEf7oO6/oA00RCaxQBviCqhSffNdqfr6zn3/8ya5SlyMick5ipS6gVO7asJSf7+jjLx/bxlg2x8duXomZlbosEZE5C2UPHAqHFf7dB9fzH69r5fM/2M6fPfoq+byGU0QkOELbAweIRSP8j1+7iupUnH/+2W6+v6Wbt61s5C2XN3LLmmYqEtFSlygickqhDnAo9MT/+LY1rGut5ruvdPFvL3fywLP7efPyer7+kTcTi4b2nxQRucSFPsChsIr9+9a38r71rUzn8jzYsZ9PffsV/ubx1/n9d60udXkiIiel7uVxYtEId715GR/csIQvP7GTTVu1nqaIXJoU4Kfwp++5gisWVfN7D27m2T2H2dc/Rt/IpD7oFJFLhoZQTiEVj/Klu67ltr/7Ke//+6dm929oq2fjb23QB5wiUnIK8NNY1pDhsd99G68cHGQ0m+PgkXG+sOl1PvqNF/j7D12rDzhFpKQU4GewpD7Nkvr07HZdJs6fPLyFP31kC39xx5VsOTTEQx37yeWdP3nPWpIx9cxF5OJQgJ+l/3xjG4cGJvj7H+/kye297D88TiIWITud59DAOF/+0HWk4gpxEZl/GgM4B5985yruevNSGjJJ/vyOK3n2D9/BX75vHT96rZff/moHE1M617iIzL8z9sDNbAnwVWAhkAfuc/cvmFk98CDQBuwBPuDuR+av1EtHJGJ85n3rjtn3629eSixq/P6/vsRvfuVZ7r+7nUxS/+CIyPyZSw98GviEu68BbgB+x8zWAvcCm9x9JbCpuB1qH2hfwv/6wDU8s+cwd93/NANj2WOu7x2e5Gc7+vjKz3bzhR9s58josde/fGCQO+97ioc69us0tyJyRna2QWFmDwP/u/j1S+7eaWYtwBPuvup0921vb/eOjo5zLjYovreli4/+ywssb8zwxbuu5end/TzUcYAX9w8cc7vFtRV88a5ruWZJLd/b0sXHH9hMLu9kc3l+8U1NfPZX17GotuKUz9M5OM5nH9tGa10Fv3vzSo29i5QpM3vO3dtP2H82AW5mbcCTwJXAPnevPeq6I+5ed5L73APcA7B06dLr9u7de9bFB9HPdvTx21/tYCxbGA9f1VzFHesXc1VrDSubK+kanOC/fO15eoYnuHVdCw+/eIirWmv5x9+4jn9/pYvP/fs2ohHj3nev5tc3LCUSeeNUt+7ON57Zz2cf28pkLk92Os9lTRn++v1Xc+3SE14CEQm48w5wM6sEfgx8xt2/ZWYDcwnwo4WlBz7jxf0DPPZyJ7de1cK6xTUnnG98YCzLJx56kU3berh1XQt/84GrZ3vR+/rHuPdbL/Hznf1c31bHZ391HclYlB9s7ebhzYfYvH+AG1c08LlfW8e+w2Pc+68v0zk4zttXL2BFUyXLGtJkEjEGxrIMjE9Rn0nw3qsXUZtOzD6/u5PL+2mPZ3d3OgcnGJ2cZnI6Ty7vNFQmWFCVIhGLnHDbbV3DbNraTV0mwVsua6StIX1W51kfy04zls3RWJmc832ON53Ls6d/jH2HR7l2ad0xbQ4id2diKs/w5BS1FYkTfu5S/s4rwM0sDjwKfM/d/7a47zU0hHLe8nnn1c4h1rZUH9PLhsIf7jefO8BnHtvK0PgUM7P4Vy6o5LduWs6d1y+ZDcfhiSn+5vuv87Mdfew9PEZ2On/CcyVjEW5d18LVS2p5ft8Rntl9mJ7hSVY0Zli1sIpVzVUsbUjTWldBPBrh8Ve7+beXOtnVN3rCY5lBY2WSlpoULTUp6jNJnt7dz67eY2/bUpNiUW0FBkTMWFxXwfVt9VzfVseS+jTTeWc6l2fz/gEe3nyI723pYiybY/XCKn5p1QJuvKyBpfVpWmpSRCPG9u4RthwapGtwgisX13DtsjqqUzFe7Rzie1u6+fFrPWzrGmay2P5ELMK7r1zIr13byujkNJv3D/DywUGiEaOpKklTZZK2xgxrWqpZ1VxFNGJ0D01waKBweOiKxkpq0vFj2jQxlePF/QN07D1C/0iWNS1VXLm4hobKBFs7h3nl4CC7ekdn34zy7rQ1ZLh8QSWLays4cGSMHb0jHBqY4E3NVdywop72tnoyiSjTeWdsMsfTu/v50Wu9/GR7L12DE0wXX/xkLMI1S2rZsLyepfVpUvEoFfEozhtvfmPZHBNTOcazOSIRY1FNisV1FbTWpVlSVzH7hr2jZ5hHNh9ia9cw71u/mHdesZBo5MQ3W3dncHyKmor4Kd+MJ6Zy9A5P0liZPGGW8lh2mpHJaapTcZKxCGPZHK93D7Ota5iIwS1rF1KfOfFNdiqXZ2fvCD1Dk6xpqaap6tRv6l2DExwaHKdveJKBsSkaqxIsrc+wpL4CdxieKNRQEY/SUJkgfpJOyysHB/mHJ3dxaGCcZQ1pltVnqE3HCz/LqRxG8XemKkl9JkEqHiEVj1KditNYmZj92Yxnczy5vZfn9x6hsTLJkvrCz/6ypspznsF9zgFuhao2Aofd/eNH7f9roN/dP2dm9wL17v7J0z2WAvzc9I1Mcv9PdtOQSfCOtc0sb8yc9vb5vNM5NMF4NkddOk5NRZzXuof5xjP7+M4LhxiZnGZBVZINy+tprUuzo2eE17qH2H94/JjHiRjceFkDt6xppqEySSIWIWpG38gknYMTs380nYMT9AxNsK61hl9Z18I7r1jI0PgUP9/Zz1O7+hkYy+IOubyzs3eUvpHJk9ZdnYpx61UtLKlP8+TrvXTsOTIbXACxiB2zDYU3kvp0gv7RLGZw3dI61i+tZfXCalpqUnx3SxfffuEgwxPTACSiEVa3VGFA30iW3uFJsrn8bHsdOP5Poj6ToC4dZypXeLPpHZlkKle4USoeYWLqxDfLhdUpqlIx0sU/2F19o7M1AFSlYiyqqWBX38jsYx2vMhnjrZc3cFlTJVWpOJXJKLv7xujYe5gth4bIneG8PCdrTzxqtDVkiJjxWnchQOszSfpGJmlrSPPBDUsxK/xsuocm2N03yq7eUUYmp2msTHB9Wz3XLq1jeHKanb0j7O4dpXNwnCNjU7Ov0brWGja01TM+leO5vUfY2jk02/mIRwuv4dE1xSLGTSsbub6tnt7hSbqHJth3eIzt3SOzrw3AkvoK1i+p4y2XNfDWyxtZWJPi8Ve7+epTe/h/uw6f9mdxvNp0nKX1ad7UXMXlCyp5amc/P369l6pUjDUt1ew/PEbn4MScH686FWNlcxWVyRhP7+5nYipPNGLHvEb/dHc7N69pPqs6Z5xPgN8E/AR4mcJhhAB/CDwNPAQsBfYB73f30/4UFeClN5ad5vBolsW1FSf0psazOQ4OjLH/8DhDE1O89fLG8xrKOBl3Z0//GM/uOUzv8CTxqBGLRGitq+AXVzUdM5N1eGKKLYeGODQwPjuMs2phobfbXJ3ipWIveFfvCDesaOAda5tPWu/EVI6fbu+jsSrJmpaqY54jn3f2Hxlja+cQWzuHAVhUm6KlpoLJ6Ty7+0bY1TvK0MQU8WiEeDRCQ2WC65fVc92yOqor4uzpH+WVg4P0j2RZ3VLFFS01J/Ta3Z2e4UkODozTWltBU1USM2MsO83zewd4fl/hzSoRNeLRCOtaa2hfVn/K4ZKx7DT9I1kmpnKzbyDpZJR0Iko6HqMiEZ0Ny8J/FBPs7R9lZ+8oO3tHGJ2c5pa1zdx6VQsNmSTf29LFP/x4Jy8eGAQKPf2mqiTLGzNc1lTJotoU27qGeWb3YQ4cGSdihVnKKxoztNalaa5O0liZZO/hMZ7ZfZiXDgwQjxb+W2hfVkdTVZKhiWmGJ6ZJJ6KsXljFmpZqhiameOTFQzz6YicHB8bJJKI016RYXFvB2kXVrC32vLccHGLz/gGe3VP4rxEgnYgyls3RWlfBBzcsZW1LNQ2VCWorEvSOTLC3v/C7HIsaVakYlckY41M5+oaz9I5MsKdvjNe6h+kdnqQhk+DDb1vOh25YRnUqPvt7MzJZqDcVi5Jzp29kkt7hSQ6PZpmYyjMxlePIWJYdPSNs7xnh8GiWmy5v5JfXNnP98nrGJnPsPzLG/sNjXL+8/pz/ni7Ih5jnSwEuculyd7qGJqhMFsLuVMMlfSOTVCZjpz3qaXI6R9RszucLyued8ancGedOuDs7e0f46fY+tnUNc/OaZt6+esFJh37m6sholnQyekmfBuNUAa6ZJiICFBY2aak59WGrM+bSizzbMIxEbE4T38yMyxdUcfmCqrN6/NOpO8n4e1Do42wRkYBSgIuIBJQCXEQkoBTgIiIBpQAXEQkoBbiISEApwEVEAkoBLiISUBd1JqaZ9QLnej7ZRqDvApYTFGFsdxjbDOFsdxjbDGff7mXu3nT8zosa4OfDzDpONpW03IWx3WFsM4Sz3WFsM1y4dmsIRUQkoBTgIiIBFaQAv6/UBZRIGNsdxjZDONsdxjbDBWp3YMbARUTkWEHqgYuIyFEU4CIiARWIADezd5nZa2a2o7j+ZtkxsyVm9iMz22pmW8zsY8X99Wb2uJltL17WlbrWC83Momb2gpk9WtwOQ5trzeybZrat+JrfWO7tNrPfK/5uv2Jm3zCzVDm22cz+2cx6zOyVo/adsp1m9gfFbHvNzN55Ns91yQe4mUWBLwLvBtYCHzSztaWtal5MA59w9zXADcDvFNt5L7DJ3VcCm4rb5eZjwNajtsPQ5i8A33X31cDVFNpftu02s8XA7wLt7n4lEAXupDzb/H+Adx2376TtLP6N3wlcUbzPl4qZNyeXfIADG4Ad7r7L3bPAA8DtJa7pgnP3Tnd/vvj9MIU/6MUU2rqxeLONwB0lKXCemFkrcCtw/1G7y73N1cAvAP8E4O5Zdx+gzNtNYQnHCjOLAWngEGXYZnd/Ejh+gfdTtfN24AF3n3T33cAOCpk3J0EI8MXA/qO2DxT3lS0zawPWA08Dze7eCYWQBxaUsLT58Hngk0D+qH3l3uYVQC/wleLQ0f1mlqGM2+3uB4H/CewDOoFBd/8+Zdzm45yqneeVb0EI8JMtN122xz6aWSXwr8DH3X2o1PXMJzO7Dehx9+dKXctFFgOuBb7s7uuBUcpj6OCUimO+twPLgUVAxsw+VNqqLgnnlW9BCPADwJKjtlsp/OtVdswsTiG8v+7u3yru7jazluL1LUBPqeqbB28F3mtmeygMjb3dzL5GebcZCr/TB9z96eL2NykEejm3+x3Abnfvdfcp4FvAWyjvNh/tVO08r3wLQoA/C6w0s+VmlqAw4P9IiWu64MzMKIyJbnX3vz3qqkeAu4vf3w08fLFrmy/u/gfu3urubRRe1x+6+4co4zYDuHsXsN/MVhV33Qy8Snm3ex9wg5mli7/rN1P4nKec23y0U7XzEeBOM0ua2XJgJfDMnB/V3S/5L+BXgNeBncCnSl3PPLXxJgr/Or0EbC5+/QrQQOFT6+3Fy/pS1zpP7f8l4NHi92XfZuAaoKP4en8HqCv3dgOfBrYBrwD/F0iWY5uBb1AY55+i0MP+8OnaCXyqmG2vAe8+m+fSVHoRkYAKwhCKiIichAJcRCSgFOAiIgGlABcRCSgFuIhIQCnARUQCSgEuIhJQ/x9NcdHqDwntAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from made import MADE\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal, AutoNormal, AutoMultivariateNormal\n",
    "from gmade import GMADE\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# NN used for p(x | y)\n",
    "class simpleNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=32, out_size=1, t=\"normal\", out_non_linear=None):\n",
    "        super().__init__()\n",
    "        self.t = t\n",
    "        self.out_non_linear = out_non_linear\n",
    "        self.hiddeen_layer = nn.Linear(input_size, hidden)\n",
    "        if t == \"normal\":\n",
    "            self.loc_layer = nn.Linear(hidden, out_size)\n",
    "            self.std_layer = nn.Linear(hidden, out_size)\n",
    "            self.softplus = nn.Softplus()\n",
    "        elif t == \"bern\":\n",
    "            self.prob_layer = nn.Linear(hidden, out_size)\n",
    "        elif t == \"mlp\":\n",
    "            self.out_layer = nn.Linear(hidden, out_size)\n",
    "        \n",
    "    def forward(self, x_list):\n",
    "        for i in range(len(x_list)):\n",
    "            if x_list[i].dim() == 0:\n",
    "                x_list[i] = torch.unsqueeze(x_list[i], dim=0)\n",
    "        input_x = torch.cat(x_list)\n",
    "        hid = F.relu(self.hiddeen_layer(input_x))\n",
    "        # return loc, std\n",
    "        if self.t == \"normal\":\n",
    "            return self.loc_layer(hid), self.softplus(self.std_layer(hid))\n",
    "        elif self.t == \"bern\":\n",
    "            return torch.sigmoid(self.prob_layer(hid))\n",
    "        else:\n",
    "            if self.out_non_linear == \"tanh\":\n",
    "                return torch.tanh(self.out_layer(hid))\n",
    "            else:\n",
    "                return self.out_layer(hid)\n",
    "\n",
    "class Experiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # guide 1\n",
    "        self.hidden_size_1 = 8\n",
    "        self.x1_net_1 = simpleNN()\n",
    "        self.x2_net_1 = simpleNN()\n",
    "        self.x3_net_1 = simpleNN()\n",
    "        self.x4_net_1 = simpleNN()\n",
    "        self.x5_net_1 = simpleNN()\n",
    "        self.x6_net_1 = simpleNN()\n",
    "        self.x7_net_1 = simpleNN()\n",
    "        self.x8_net_1 = simpleNN()\n",
    "        self.y1_net_1 = simpleNN()\n",
    "        self.y2_net_1 = simpleNN()\n",
    "        self.y3_net_1 = simpleNN()\n",
    "        self.y4_net_1 = simpleNN()\n",
    "        self.z1_net_1 = simpleNN(self.hidden_size_1 + 1)\n",
    "        self.z2_net_1 = simpleNN(self.hidden_size_1 + 1)\n",
    "        \n",
    "        self.h0_1 = nn.Parameter(torch.zeros(self.hidden_size_1))\n",
    "        self.hid_net_1 = simpleNN(self.hidden_size_1 + 8, out_size = self.hidden_size_1, t = \"mlp\")\n",
    "        \n",
    "        # guide 2\n",
    "        self.hidden_size_2 = 8\n",
    "        self.x1_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x2_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x3_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x4_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x5_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x6_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x7_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x8_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y1_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y2_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y3_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y4_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.z1_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.z2_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.h0_2 = nn.Parameter(torch.zeros(self.hidden_size_2))\n",
    "        self.hid_net_2 = simpleNN(self.hidden_size_2 + 8, out_size = self.hidden_size_2, t = \"mlp\")\n",
    "        \n",
    "        # guide 3\n",
    "        self.hidden_size_3 = 8\n",
    "        self.x1_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x2_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.x3_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x4_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.x5_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x6_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.x7_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x8_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.y1_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.y2_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.y3_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.y4_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.z1_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.z2_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.h0_3 = nn.Parameter(torch.zeros(self.hidden_size_3))\n",
    "        self.hid_net_3 = simpleNN(self.hidden_size_3 + 8, out_size = self.hidden_size_3, t = \"mlp\")\n",
    "\n",
    "        # guide 4\n",
    "        self.hidden_size_4 = 8\n",
    "        self.x1_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x2_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.x3_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x4_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.x5_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x6_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.x7_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x8_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.y1_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.y2_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.y3_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.y4_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.z1_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.z2_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.h0_4 = nn.Parameter(torch.zeros(self.hidden_size_4))\n",
    "        self.hid_net_4 = simpleNN(self.hidden_size_4 + 8 + 4 + 2, out_size = self.hidden_size_4, t = \"mlp\")\n",
    "        \n",
    "        # guide 5\n",
    "        self.hidden_size_5 = 16\n",
    "        self.x1_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x2_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.x3_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x4_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.x5_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x6_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.x7_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x8_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.y1_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.y2_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.y3_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.y4_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.z1_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.z2_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.h0_5 = nn.Parameter(torch.zeros(self.hidden_size_5))\n",
    "        self.hid_net_5 = simpleNN(self.hidden_size_5 + 8 + 4 + 2, out_size = self.hidden_size_5, t = \"mlp\")\n",
    "        \n",
    "        # guide 6\n",
    "        self.hidden_size_6 = 8\n",
    "        self.x1_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x2_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.x3_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x4_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.x5_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x6_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.x7_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x8_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.y1_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.y2_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.y3_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.y4_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.z1_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.z2_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.h0_6 = nn.Parameter(torch.zeros(self.hidden_size_6))\n",
    "        self.hid_net_6 = simpleNN(self.hidden_size_6 + 8 + 4 + 2 + 1, out_size = self.hidden_size_6, t = \"mlp\")\n",
    "    \n",
    "        # guide 7\n",
    "        self.hidden_size_7 = 8\n",
    "        self.x1_net_7 = simpleNN(self.hidden_size_7+ 2)\n",
    "        self.x2_net_7 = simpleNN(self.hidden_size_7+ 1)\n",
    "        self.x3_net_7 = simpleNN(self.hidden_size_7+ 2)\n",
    "        self.x4_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.x5_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.x6_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.x7_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.x8_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.y1_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.y2_net_7= simpleNN(self.hidden_size_7 + 1)\n",
    "        self.y3_net_7= simpleNN(self.hidden_size_7 + 2)\n",
    "        self.y4_net_7= simpleNN(self.hidden_size_7 + 1)\n",
    "        self.z1_net_7= simpleNN(self.hidden_size_7 + 2)\n",
    "        self.z2_net_7= simpleNN(self.hidden_size_7 + 1)\n",
    "        self.h0_7= nn.Parameter(torch.zeros(self.hidden_size_7))\n",
    "        self.hid_net_7 = simpleNN(self.hidden_size_7 + 1, out_size = self.hidden_size_7, t = \"mlp\")\n",
    "        \n",
    "        # guide 7 made\n",
    "        \n",
    "        self.hidden_size_7_made = 6\n",
    "        self.input_size = self.hidden_size_7_made + 1\n",
    "        self.out_size = 14 * 2\n",
    "        \n",
    "                                \n",
    "        # guide 8\n",
    "        self.hidden_size_8 = 8\n",
    "        self.x1_net_8 = simpleNN(self.hidden_size_8+ 2)\n",
    "        self.x2_net_8 = simpleNN(self.hidden_size_8+ 1)\n",
    "        self.x3_net_8 = simpleNN(self.hidden_size_8+ 2)\n",
    "        self.x4_net_8 = simpleNN(self.hidden_size_8 + 1)\n",
    "        self.x5_net_8 = simpleNN(self.hidden_size_8 + 2)\n",
    "        self.x6_net_8 = simpleNN(self.hidden_size_8 + 1)\n",
    "        self.x7_net_8 = simpleNN(self.hidden_size_8 + 2)\n",
    "        self.x8_net_8 = simpleNN(self.hidden_size_8 + 1)\n",
    "        self.y1_net_8 = simpleNN(self.hidden_size_8 + 2)\n",
    "        self.y2_net_8 = simpleNN(self.hidden_size_8 + 1)\n",
    "        self.y3_net_8 = simpleNN(self.hidden_size_8 + 2)\n",
    "        self.y4_net_8 = simpleNN(self.hidden_size_8 + 1)\n",
    "        self.z1_net_8 = simpleNN(self.hidden_size_8 + 2)\n",
    "        self.z2_net_8 = simpleNN(self.hidden_size_8 + 1)\n",
    "        self.h0_8= nn.Parameter(torch.zeros(self.hidden_size_8))\n",
    "        self.hid_net_8 = simpleNN(self.hidden_size_8 + 2, out_size = self.hidden_size_8, t = \"mlp\")\n",
    "                                \n",
    "        # guide 9\n",
    "        self.hidden_size_9 = 8\n",
    "        self.x1_net_9 = simpleNN(self.hidden_size_9+ 2)\n",
    "        self.x2_net_9 = simpleNN(self.hidden_size_9+ 1)\n",
    "        self.x3_net_9 = simpleNN(self.hidden_size_9+ 2)\n",
    "        self.x4_net_9 = simpleNN(self.hidden_size_9 + 1)\n",
    "        self.x5_net_9 = simpleNN(self.hidden_size_9 + 2)\n",
    "        self.x6_net_9 = simpleNN(self.hidden_size_9 + 1)\n",
    "        self.x7_net_9 = simpleNN(self.hidden_size_9 + 2)\n",
    "        self.x8_net_9 = simpleNN(self.hidden_size_9 + 1)\n",
    "        self.y1_net_9 = simpleNN(self.hidden_size_9 + 2)\n",
    "        self.y2_net_9 = simpleNN(self.hidden_size_9 + 1)\n",
    "        self.y3_net_9 = simpleNN(self.hidden_size_9 + 2)\n",
    "        self.y4_net_9 = simpleNN(self.hidden_size_9 + 1)\n",
    "        self.z1_net_9 = simpleNN(self.hidden_size_9 + 2)\n",
    "        self.z2_net_9 = simpleNN(self.hidden_size_9 + 1)\n",
    "        self.h0_9 = nn.Parameter(torch.zeros(self.hidden_size_9))\n",
    "        self.hid_net_9 = simpleNN(self.hidden_size_9 + 4, out_size = self.hidden_size_9, t = \"mlp\")\n",
    "        \n",
    "        # guide full_made\n",
    "        self.hidden_size_full_made = 8\n",
    "        input_dim_dict = {\n",
    "            \"h\" : self.hidden_size_full_made,\n",
    "            \"r\" : 1\n",
    "        }\n",
    "        var_dim_dict = {\n",
    "            \"x1\" : 1,\n",
    "            \"x2\" : 1,\n",
    "            \"x3\" : 1,\n",
    "            \"x4\" : 1,\n",
    "            \"x5\" : 1,\n",
    "            \"x6\" : 1,\n",
    "            \"x7\" : 1,\n",
    "            \"x8\" : 1,\n",
    "            \"y1\" : 1,\n",
    "            \"y2\" : 1,\n",
    "            \"y3\" : 1,\n",
    "            \"y4\" : 1,\n",
    "            \"z1\" : 1,\n",
    "            \"z2\" : 1\n",
    "        }\n",
    "        dependency_dict = {\n",
    "            \"z2\" : [\"h\", \"r\"],\n",
    "            \"z1\" : [\"h\", \"r\", \"z2\"],\n",
    "            \"y4\" : [\"h\", \"z2\"],\n",
    "            \"y3\" : [\"h\", \"z2\", \"y4\"],\n",
    "            \"y2\" : [\"h\", \"z1\"],\n",
    "            \"y1\" : [\"h\", \"z1\", \"y2\"],\n",
    "            \"x8\" : [\"h\", \"y4\"],\n",
    "            \"x7\" : [\"h\", \"y4\", \"x8\"],\n",
    "            \"x6\" : [\"h\", \"y3\"],\n",
    "            \"x5\" : [\"h\", \"y3\", \"x6\"],\n",
    "            \"x4\" : [\"h\", \"y2\"],\n",
    "            \"x3\" : [\"h\", \"y2\", \"x4\"],\n",
    "            \"x2\" : [\"h\", \"y1\"],\n",
    "            \"x1\" : [\"h\", \"y1\", \"x2\"]\n",
    "        }\n",
    "        self.full_made = GMADE(input_dim_dict, dependency_dict, var_dim_dict)\n",
    "        self.h0_full_made = nn.Parameter(torch.zeros(self.hidden_size_full_made))\n",
    "        self.hid_net_full_made = simpleNN(self.hidden_size_full_made + 1, out_size = self.hidden_size_full_made, t = \"mlp\")\n",
    "        \n",
    "    def model(self, n, obses):\n",
    "        def tree_model(i, mu):\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(mu, 1.0))\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(mu, 1.0))\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(mu, 1.0))\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(mu, 1.0))\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(mu, 1.0))\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(mu, 1.0))\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(mu, 1.0))\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(mu, 1.0))\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(x1+x2, 1.0))\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(x3+x4, 1.0))\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(x5+x6, 1.0))\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(x7+x8, 1.0))\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(y1+y2, 1.0))\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(y3+y4, 1.0))\n",
    "            return pyro.sample(f\"obs{i}\", dist.Normal(z1+z2, 1.0), obs=obses[i])\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        mu = 0\n",
    "        for i in range(n):\n",
    "            mu = tree_model(i, mu)\n",
    "    \n",
    "    # guide 1 basically inverse the arrows in the model, add hidden states that z2 depends on\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    def guide_1(self, n, obses):\n",
    "        \n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_1([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_1([obses[i], hid])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_1([z2])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_1([z2])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_1([z1])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_1([z1])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_1([y4])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_1([y4])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_1([y3])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_1([y3])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_1([y2])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_1([y2])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_1([y1])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_1([y1])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_1([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_1\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide_1_1 basically inverse the arrows in the model, add hidden states that z2 depends on\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # different from guide_1 by sample from i = n-1, n-2, ..., 0\n",
    "    def guide_1_1(self, n, obses):\n",
    "        \n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_1([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_1([obses[i], hid])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_1([z2])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_1([z2])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_1([z1])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_1([z1])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_1([y4])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_1([y4])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_1([y3])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_1([y3])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_1([y2])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_1([y2])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_1([y1])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_1([y1])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_1([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_1\n",
    "        for i in range(n-1, -1, -1):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 2 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    def guide_2(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_2([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_2([obses[i], hid])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_2([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_2([z2, hid])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_2([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_2([z1, hid])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_2([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_2([y4, hid])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_2([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_2([y3, hid])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_2([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_2([y2, hid])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_2([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_2([y1, hid])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_2([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_2\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 3 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    \n",
    "    def guide_3(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_3([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_3([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_3([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_3([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_3([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_3([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_3([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_3([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_3([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_3([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_3([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_3([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_3([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_3([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_3([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_3\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 3_1 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = n-1, n-2, ..., 1, 0\n",
    "    \n",
    "    def guide_3_1(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_3([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_3([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_3([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_3([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_3([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_3([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_3([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_3([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_3([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_3([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_3([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_3([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_3([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_3([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_3([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_3\n",
    "        for i in range(n-1, -1, -1):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 4 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled RVs in current iteration (x1,x2...x8, y1,...y4, z1,z2)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    \n",
    "    def guide_4(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_4([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_4([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_4([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_4([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_4([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_4([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_4([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_4([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_4([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_4([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_4([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_4([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_4([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_4([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_4([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_4\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 5 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled RVs in current iteration (x1,x2...x8, y1,...y4, z1,z2)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    # increases hidden state dim from 8 to 16\n",
    "    def guide_5(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_5([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_5([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_5([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_5([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_5([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_5([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_5([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_5([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_5([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_5([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_5([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_5([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_5([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_5([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_5([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_5\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 6 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled RVs in current iteration (x1,x2...x8, y1,...y4, z1,z2, obs)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    # different from guide_4 by adding obses[i] as an extra dependecy when updating hid\n",
    "\n",
    "    def guide_6(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_6([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_6([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_6([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_6([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_6([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_6([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_6([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_6([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_6([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_6([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_6([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_6([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_6([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_6([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_6([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obses[i]])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_6\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 7 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and obs\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    # different from guide_4 by adding obses[i] as an extra dependecy when updating hid\n",
    "\n",
    "    def guide_7(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_7([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_7([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_7([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_7([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_7([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_7([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_7([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_7([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_7([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_7([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_7([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_7([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_7([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_7([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_7([hid, obses[i]])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_7\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "                                 \n",
    "    # guide 8 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and z1, z2\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    # different from guide_4 by adding obses[i] as an extra dependecy when updating hid\n",
    "\n",
    "    def guide_8(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_8([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_8([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_8([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_8([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_8([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_8([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_8([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_8([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_8([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_8([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_8([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_8([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_8([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_8([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_8([hid, z1, z2])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_8\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "                                 \n",
    "    \n",
    "    # guide 9 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and y1, y2, y3. y4\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    # different from guide_4 by adding obses[i] as an extra dependecy when updating hid\n",
    "    \n",
    "    def guide_9(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_9([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_9([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_9([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_9([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_9([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_9([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_9([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_9([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_9([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_9([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_9([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_9([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_9([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_9([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_9([hid, y1, y2, y3, y4])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_9\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    def guide_full_made(self, n, obses):\n",
    "        def tree_guide(i, hid):\n",
    "            input_made = {\n",
    "                \"h\" : hid,\n",
    "                \"r\" : torch.unsqueeze(obses[i], dim=0)\n",
    "            }\n",
    "            \n",
    "            output_dict = self.full_made(input_made, suffix=str(i))\n",
    "            \n",
    "            hid = self.hid_net_full_made([hid, obses[i]])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_full_made\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "\n",
    "def generate_data():\n",
    "    \n",
    "    n_min = 2\n",
    "    n_max = 4\n",
    "    n = random.randint(n_min, n_max)\n",
    "    obses = []\n",
    "    mu = 0\n",
    "    x_len = 8\n",
    "    for i in range(n):\n",
    "        x_noise = torch.randn(x_len) / 4\n",
    "        x_mean = torch.zeros(x_len) + mu\n",
    "        xs = torch.normal(x_mean, 1) + x_noise\n",
    "        ys = []\n",
    "        j = 0\n",
    "        while j < len(xs):\n",
    "            y = dist.Normal(xs[j] + xs[j+1], 2).sample()\n",
    "            ys.append(y)\n",
    "            j +=2\n",
    "        \n",
    "        zs = []\n",
    "        j = 0\n",
    "        while j < len(ys):\n",
    "            z = dist.Normal(ys[j] + ys[j+1], 1.5).sample()\n",
    "            zs.append(z)\n",
    "            j +=2\n",
    "        \n",
    "        \n",
    "        obs = dist.Normal(zs[0] + zs[1], 1).sample() / 5\n",
    "        obses.append(obs)\n",
    "        mu = obs\n",
    "        \n",
    "    return n, obses\n",
    "    \n",
    "data = []\n",
    "num_data = 100\n",
    "for _ in range(num_data):\n",
    "    data.append(generate_data())\n",
    "\n",
    "#print(data)\n",
    "experiment = Experiment()\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.95, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "guide = experiment.guide_full_made # guide_1\n",
    "\n",
    "#guide = AutoNormal(experiment.model)\n",
    "#guide = AutoMultivariateNormal(experiment.model)\n",
    "#guide = AutoDiagonalNormal(experiment.model)\n",
    "\n",
    "svi = SVI(experiment.model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "\n",
    "n_steps = 100\n",
    "log_interval = 10\n",
    "# do gradient steps\n",
    "loss = 0\n",
    "loss_track = []\n",
    "for step in range(1, n_steps + 1):\n",
    "    imme_loss = 0\n",
    "    \n",
    "    for n, obses in data:\n",
    "        imme_loss += svi.step(n, obses) / num_data\n",
    "        \n",
    "    loss_track.append(imme_loss)\n",
    "    loss += imme_loss / log_interval\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print(\"[Step {}/{}] Immediate Loss: {} Accumlated Loss: {}\".format(step, n_steps, imme_loss, loss))\n",
    "        loss = 0\n",
    "    \n",
    "plt.plot(loss_track)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expired-cooler",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-ca9d77f22370>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-ca9d77f22370>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    [Step 10/100] Immediate Loss: 32.056255335211766 Accumlated Loss: 39.810146228253835\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# guide 1\n",
    "[Step 10/100] Immediate Loss: 32.056255335211766 Accumlated Loss: 39.810146228253835\n",
    "[Step 20/100] Immediate Loss: 30.77456396490336 Accumlated Loss: 30.907070715844633\n",
    "[Step 30/100] Immediate Loss: 30.832169231176383 Accumlated Loss: 30.868072110861544\n",
    "[Step 40/100] Immediate Loss: 30.20635374277832 Accumlated Loss: 30.786874743551017\n",
    "[Step 50/100] Immediate Loss: 31.064358202517017 Accumlated Loss: 30.73660790809988\n",
    "[Step 60/100] Immediate Loss: 30.461085685789595 Accumlated Loss: 30.735810206323862\n",
    "[Step 70/100] Immediate Loss: 30.69941374212503 Accumlated Loss: 30.568582807511092\n",
    "[Step 80/100] Immediate Loss: 31.283807360827932 Accumlated Loss: 30.603012248307465\n",
    "[Step 90/100] Immediate Loss: 30.556891204416758 Accumlated Loss: 30.497190983921286\n",
    "[Step 100/100] Immediate Loss: 30.619736705124378 Accumlated Loss: 30.699366100519896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide_1_1\n",
    "[Step 10/100] Immediate Loss: 33.08285777300596 Accumlated Loss: 42.140617132395505\n",
    "[Step 20/100] Immediate Loss: 30.552316099703305 Accumlated Loss: 31.146604584604507\n",
    "[Step 30/100] Immediate Loss: 30.533921941220754 Accumlated Loss: 30.85680748859048\n",
    "[Step 40/100] Immediate Loss: 30.76778864353895 Accumlated Loss: 30.536550723701716\n",
    "[Step 50/100] Immediate Loss: 30.1870471033454 Accumlated Loss: 30.73809576103092\n",
    "[Step 60/100] Immediate Loss: 31.023994455933572 Accumlated Loss: 30.653320709526536\n",
    "[Step 70/100] Immediate Loss: 31.379466826319703 Accumlated Loss: 30.791925778031345\n",
    "[Step 80/100] Immediate Loss: 31.064741338491448 Accumlated Loss: 30.297557548731568\n",
    "[Step 90/100] Immediate Loss: 30.665508285760872 Accumlated Loss: 30.577219336509703\n",
    "[Step 100/100] Immediate Loss: 30.387796130776415 Accumlated Loss: 30.447961003541952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 2\n",
    "[Step 10/100] Immediate Loss: 31.160341137945643 Accumlated Loss: 40.11236542010307\n",
    "[Step 20/100] Immediate Loss: 29.47647261351348 Accumlated Loss: 29.61162685546279\n",
    "[Step 30/100] Immediate Loss: 29.94969665110111 Accumlated Loss: 29.67519397190213\n",
    "[Step 40/100] Immediate Loss: 29.2828398269415 Accumlated Loss: 29.308840560138226\n",
    "[Step 50/100] Immediate Loss: 29.36908874571323 Accumlated Loss: 29.168527402102946\n",
    "[Step 60/100] Immediate Loss: 29.091700927019115 Accumlated Loss: 28.999451614946132\n",
    "[Step 70/100] Immediate Loss: 29.1920207542181 Accumlated Loss: 28.950033961921935\n",
    "[Step 80/100] Immediate Loss: 30.127138351202017 Accumlated Loss: 28.875505193889143\n",
    "[Step 90/100] Immediate Loss: 28.85039758533239 Accumlated Loss: 28.882422005444763\n",
    "[Step 100/100] Immediate Loss: 28.979458193778992 Accumlated Loss: 28.880654528141022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 3\n",
    "[Step 10/100] Immediate Loss: 26.031784344017506 Accumlated Loss: 36.08618940055371\n",
    "[Step 20/100] Immediate Loss: 23.71810558915138 Accumlated Loss: 24.834602235227827\n",
    "[Step 30/100] Immediate Loss: 24.366164560318005 Accumlated Loss: 24.285493285149336\n",
    "[Step 40/100] Immediate Loss: 23.4816444569826 Accumlated Loss: 23.823054573804136\n",
    "[Step 50/100] Immediate Loss: 23.566059122681615 Accumlated Loss: 24.03096249982715\n",
    "[Step 60/100] Immediate Loss: 24.22875029921531 Accumlated Loss: 23.79123932659626\n",
    "[Step 70/100] Immediate Loss: 24.362703014910227 Accumlated Loss: 23.839444131016734\n",
    "[Step 80/100] Immediate Loss: 24.524240311384194 Accumlated Loss: 23.454850003451114\n",
    "[Step 90/100] Immediate Loss: 23.35828918129206 Accumlated Loss: 23.429724233001476\n",
    "[Step 100/100] Immediate Loss: 23.05758892029523 Accumlated Loss: 23.247113545954228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 3_1\n",
    "[Step 10/100] Immediate Loss: 29.64976183772088 Accumlated Loss: 38.22538236251472\n",
    "[Step 20/100] Immediate Loss: 25.34471814244986 Accumlated Loss: 26.440933385401955\n",
    "[Step 30/100] Immediate Loss: 25.35544960319997 Accumlated Loss: 25.267824931949374\n",
    "[Step 40/100] Immediate Loss: 24.37403639018536 Accumlated Loss: 24.840208679139614\n",
    "[Step 50/100] Immediate Loss: 24.247421675920478 Accumlated Loss: 24.383337319314474\n",
    "[Step 60/100] Immediate Loss: 25.045929816961284 Accumlated Loss: 24.55331683513522\n",
    "[Step 70/100] Immediate Loss: 24.163105537891386 Accumlated Loss: 24.277232891410588\n",
    "[Step 80/100] Immediate Loss: 23.972828967869276 Accumlated Loss: 24.21140722477435\n",
    "[Step 90/100] Immediate Loss: 24.01401171565055 Accumlated Loss: 24.00979202204943\n",
    "[Step 100/100] Immediate Loss: 24.33066892236472 Accumlated Loss: 24.13794069096446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 4\n",
    "[Step 10/100] Immediate Loss: 24.68699115812778 Accumlated Loss: 37.01468467932939\n",
    "[Step 20/100] Immediate Loss: 21.6624699795246 Accumlated Loss: 22.73940928918123\n",
    "[Step 30/100] Immediate Loss: 21.166393940448767 Accumlated Loss: 21.316948004901416\n",
    "[Step 40/100] Immediate Loss: 21.36728857249021 Accumlated Loss: 21.098873917281626\n",
    "[Step 50/100] Immediate Loss: 20.981309909522533 Accumlated Loss: 20.997873998492956\n",
    "[Step 60/100] Immediate Loss: 21.08762986898422 Accumlated Loss: 20.824197031199933\n",
    "[Step 70/100] Immediate Loss: 20.935759621858594 Accumlated Loss: 20.822197566896673\n",
    "[Step 80/100] Immediate Loss: 20.30705537825823 Accumlated Loss: 20.72653667473793\n",
    "[Step 90/100] Immediate Loss: 20.73721558332443 Accumlated Loss: 20.64209464859963\n",
    "[Step 100/100] Immediate Loss: 20.87153839617968 Accumlated Loss: 20.65713318750262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 5\n",
    "[Step 10/100] Immediate Loss: 23.1993371462822 Accumlated Loss: 33.514440439701076\n",
    "[Step 20/100] Immediate Loss: 21.155377793312088 Accumlated Loss: 21.891660819441086\n",
    "[Step 30/100] Immediate Loss: 21.215811479985703 Accumlated Loss: 21.078007463216775\n",
    "[Step 40/100] Immediate Loss: 21.20999110490082 Accumlated Loss: 21.014692111611367\n",
    "[Step 50/100] Immediate Loss: 20.966142849922193 Accumlated Loss: 20.979130407631395\n",
    "[Step 60/100] Immediate Loss: 20.94501889407635 Accumlated Loss: 20.84996331000328\n",
    "[Step 70/100] Immediate Loss: 21.04487294763326 Accumlated Loss: 20.896094068676238\n",
    "[Step 80/100] Immediate Loss: 20.460133520364757 Accumlated Loss: 20.75659060847759\n",
    "[Step 90/100] Immediate Loss: 20.84229312330485 Accumlated Loss: 20.710244399458173\n",
    "[Step 100/100] Immediate Loss: 20.769813348650935 Accumlated Loss: 20.68340155428648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 6\n",
    "[Step 10/100] Immediate Loss: 20.42654618114233 Accumlated Loss: 28.889365255206823\n",
    "[Step 20/100] Immediate Loss: 19.857153085172172 Accumlated Loss: 19.937184128135442\n",
    "[Step 30/100] Immediate Loss: 19.520539140999315 Accumlated Loss: 19.629199158638713\n",
    "[Step 40/100] Immediate Loss: 19.165769968926895 Accumlated Loss: 19.488673482775685\n",
    "[Step 50/100] Immediate Loss: 19.41767822444439 Accumlated Loss: 19.426740706920622\n",
    "[Step 60/100] Immediate Loss: 19.431891245543948 Accumlated Loss: 19.40624176305532\n",
    "[Step 70/100] Immediate Loss: 19.494637635350234 Accumlated Loss: 19.350892909973858\n",
    "[Step 80/100] Immediate Loss: 19.229742932021615 Accumlated Loss: 19.365910012155773\n",
    "[Step 90/100] Immediate Loss: 19.331023247241966 Accumlated Loss: 19.303414241611957\n",
    "[Step 100/100] Immediate Loss: 19.552925373315805 Accumlated Loss: 19.321839558482168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "### guide 7 ### best\n",
    "[Step 10/100] Immediate Loss: 20.2772622281313 Accumlated Loss: 28.76096033588051\n",
    "[Step 20/100] Immediate Loss: 19.679782972037792 Accumlated Loss: 19.731237277120353\n",
    "[Step 30/100] Immediate Loss: 19.403315845429905 Accumlated Loss: 19.522962967753415\n",
    "[Step 40/100] Immediate Loss: 19.093879950344558 Accumlated Loss: 19.36297418275476\n",
    "[Step 50/100] Immediate Loss: 19.2976006630063 Accumlated Loss: 19.353287386298177\n",
    "[Step 60/100] Immediate Loss: 19.316642963588237 Accumlated Loss: 19.31276805520058\n",
    "[Step 70/100] Immediate Loss: 19.310542556643476 Accumlated Loss: 19.264885908722878\n",
    "[Step 80/100] Immediate Loss: 19.276807580590248 Accumlated Loss: 19.28338193294406\n",
    "[Step 90/100] Immediate Loss: 19.19589645862579 Accumlated Loss: 19.198544875502588\n",
    "[Step 100/100] Immediate Loss: 19.4472383236885 Accumlated Loss: 19.247250556439162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### gmade ###\n",
    "[Step 10/100] Immediate Loss: 22.680389780998233 Accumlated Loss: 35.19650405162573\n",
    "[Step 20/100] Immediate Loss: 20.381133034527302 Accumlated Loss: 21.011727388679983\n",
    "[Step 30/100] Immediate Loss: 19.57214338630438 Accumlated Loss: 19.62186603462696\n",
    "[Step 40/100] Immediate Loss: 19.315119618177416 Accumlated Loss: 19.436573924750093\n",
    "[Step 50/100] Immediate Loss: 19.29497722923756 Accumlated Loss: 19.36097045993805\n",
    "[Step 60/100] Immediate Loss: 19.204773218631747 Accumlated Loss: 19.309482787221672\n",
    "[Step 70/100] Immediate Loss: 19.29591664344073 Accumlated Loss: 19.284042857289315\n",
    "[Step 80/100] Immediate Loss: 19.228719753324977 Accumlated Loss: 19.211760253548626\n",
    "[Step 90/100] Immediate Loss: 19.120977384448054 Accumlated Loss: 19.248472143501047\n",
    "[Step 100/100] Immediate Loss: 19.145323577821248 Accumlated Loss: 19.25928099399805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 8\n",
    "[Step 10/100] Immediate Loss: 22.467771414220337 Accumlated Loss: 34.07140950384736\n",
    "[Step 20/100] Immediate Loss: 21.763280723392967 Accumlated Loss: 21.793595794767143\n",
    "[Step 30/100] Immediate Loss: 21.077882419526578 Accumlated Loss: 21.09933529755473\n",
    "[Step 40/100] Immediate Loss: 20.581267143785947 Accumlated Loss: 20.841164585858582\n",
    "[Step 50/100] Immediate Loss: 21.248149825930597 Accumlated Loss: 20.92562254476547\n",
    "[Step 60/100] Immediate Loss: 20.944569247066973 Accumlated Loss: 20.890202902674677\n",
    "[Step 70/100] Immediate Loss: 20.514412646591662 Accumlated Loss: 20.68528026425838\n",
    "[Step 80/100] Immediate Loss: 20.368839347958563 Accumlated Loss: 20.65337956503033\n",
    "[Step 90/100] Immediate Loss: 20.631799390316022 Accumlated Loss: 20.61819331428409\n",
    "[Step 100/100] Immediate Loss: 20.91762545168399 Accumlated Loss: 20.63467643406987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 9\n",
    "[Step 10/100] Immediate Loss: 24.727704225182535 Accumlated Loss: 35.97320130950212\n",
    "[Step 20/100] Immediate Loss: 23.37845941632986 Accumlated Loss: 23.7587587428689\n",
    "[Step 30/100] Immediate Loss: 22.28792653501035 Accumlated Loss: 22.80557987380028\n",
    "[Step 40/100] Immediate Loss: 21.437094094157214 Accumlated Loss: 22.30265956261754\n",
    "[Step 50/100] Immediate Loss: 22.73526936858893 Accumlated Loss: 22.48900521808863\n",
    "[Step 60/100] Immediate Loss: 23.203256192803387 Accumlated Loss: 22.573640926212075\n",
    "[Step 70/100] Immediate Loss: 21.949498886764047 Accumlated Loss: 22.333624592006206\n",
    "[Step 80/100] Immediate Loss: 21.99221489280463 Accumlated Loss: 22.276512214809657\n",
    "[Step 90/100] Immediate Loss: 22.006299128532408 Accumlated Loss: 22.028557543367143\n",
    "[Step 100/100] Immediate Loss: 22.434146136939518 Accumlated Loss: 22.160525921404357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoNormal\n",
    "[Step 10/100] Immediate Loss: 1233.5509329861402 Accumlated Loss: 1227.3371018108132\n",
    "[Step 20/100] Immediate Loss: 1223.710170497894 Accumlated Loss: 1198.8953249975439\n",
    "[Step 30/100] Immediate Loss: 1214.6601654508706 Accumlated Loss: 1199.9680957393944\n",
    "[Step 40/100] Immediate Loss: 1164.4792316886785 Accumlated Loss: 1196.4807624239027\n",
    "[Step 50/100] Immediate Loss: 1185.8603583538534 Accumlated Loss: 1201.2587032988667\n",
    "[Step 60/100] Immediate Loss: 1168.790014993846 Accumlated Loss: 1197.5709460456371\n",
    "[Step 70/100] Immediate Loss: 1175.152639506459 Accumlated Loss: 1194.480629557699\n",
    "[Step 80/100] Immediate Loss: 1200.5110745263096 Accumlated Loss: 1204.2938371902703\n",
    "[Step 90/100] Immediate Loss: 1210.800975180566 Accumlated Loss: 1195.3925600020586\n",
    "[Step 100/100] Immediate Loss: 1179.5571283224222 Accumlated Loss: 1201.02371161443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoMultivariateNormal\n",
    "[Step 10/100] Immediate Loss: 1235.3812578570842 Accumlated Loss: 1236.1352865802646\n",
    "[Step 20/100] Immediate Loss: 1210.2978770101067 Accumlated Loss: 1216.1027867695093\n",
    "[Step 30/100] Immediate Loss: 1229.688204897046 Accumlated Loss: 1205.0053660194872\n",
    "[Step 40/100] Immediate Loss: 1200.555576323867 Accumlated Loss: 1192.0478162692784\n",
    "[Step 50/100] Immediate Loss: 1191.1188332122565 Accumlated Loss: 1196.5321274908779\n",
    "[Step 60/100] Immediate Loss: 1191.3697812026737 Accumlated Loss: 1206.1590484446883\n",
    "[Step 70/100] Immediate Loss: 1189.0993092578653 Accumlated Loss: 1185.5664499574898\n",
    "[Step 80/100] Immediate Loss: 1184.2317881757021 Accumlated Loss: 1193.5602444505096\n",
    "[Step 90/100] Immediate Loss: 1213.3458593541382 Accumlated Loss: 1189.3086517564059\n",
    "[Step 100/100] Immediate Loss: 1194.0520617479087 Accumlated Loss: 1196.8081811218856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoDiagonalNormal\n",
    "[Step 10/100] Immediate Loss: 1235.8018628519776 Accumlated Loss: 1236.249700816393\n",
    "[Step 20/100] Immediate Loss: 1212.7352848732473 Accumlated Loss: 1217.2863890322446\n",
    "[Step 30/100] Immediate Loss: 1233.1168017601972 Accumlated Loss: 1208.195502301395\n",
    "[Step 40/100] Immediate Loss: 1205.5053979098793 Accumlated Loss: 1196.19749720788\n",
    "[Step 50/100] Immediate Loss: 1196.6777249866725 Accumlated Loss: 1201.5737289296987\n",
    "[Step 60/100] Immediate Loss: 1195.7460924953223 Accumlated Loss: 1211.1477473101022\n",
    "[Step 70/100] Immediate Loss: 1194.371914086938 Accumlated Loss: 1191.4428508981468\n",
    "[Step 80/100] Immediate Loss: 1189.6923706567293 Accumlated Loss: 1199.3408790806534\n",
    "[Step 90/100] Immediate Loss: 1220.8790620434281 Accumlated Loss: 1195.186482142985\n",
    "[Step 100/100] Immediate Loss: 1201.1263765621195 Accumlated Loss: 1203.2602218962313"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
