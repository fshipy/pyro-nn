{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "banner-smith",
   "metadata": {
    "id": "banner-smith"
   },
   "source": [
    "uncomment if executing in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "center-syria",
   "metadata": {
    "id": "center-syria"
   },
   "outputs": [],
   "source": [
    "# ! pip uninstall pyro-ppl\n",
    "# ! pip install pyro-ppl==1.5.1\n",
    "# ! unzip fonts.zip \n",
    "# ! unzip claptchagen.zip\n",
    "# ! unzip csis\n",
    "# ! cp csis.py /usr/local/lib/python3.7/dist-packages/pyro/infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intimate-postage",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "intimate-postage",
    "outputId": "f18a10f4-cecc-4172-a7f6-1e4fe2fa1bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n",
      "number of samples in group 0\n",
      "number of samples in group 676\n",
      "text 01 captcha shape (32, 100) noise 0.5317091456182311\n",
      "text 70 captcha shape (32, 100) noise 0.3916747982250164\n",
      "text 04 captcha shape (32, 100) noise 0.851765483126142\n",
      "text 67 captcha shape (32, 100) noise 0.2977274117772327\n",
      "text 60 captcha shape (32, 100) noise 0.8082621257270096\n",
      "text 82 captcha shape (32, 100) noise 0.6677921309562015\n",
      "text 40 captcha shape (32, 100) noise 0.8255491121415252\n",
      "text 86 captcha shape (32, 100) noise 0.5783670890135378\n",
      "text 65 captcha shape (32, 100) noise 0.3588539766854798\n",
      "text 18 captcha shape (32, 100) noise 0.28867005207225027\n",
      "text 94 captcha shape (32, 100) noise 0.12294211033564126\n",
      "number of samples in group 656\n",
      "text 718 captcha shape (32, 100) noise 0.050219258631867665\n",
      "text 078 captcha shape (32, 100) noise 0.8567344501002044\n",
      "text 371 captcha shape (32, 100) noise 0.06467416735045343\n",
      "text 671 captcha shape (32, 100) noise 0.7880504633172919\n",
      "text 313 captcha shape (32, 100) noise 0.7730105133742611\n",
      "text 514 captcha shape (32, 100) noise 0.7361867369511322\n",
      "text 637 captcha shape (32, 100) noise 0.06393212234360444\n",
      "text 725 captcha shape (32, 100) noise 0.6327198418069877\n",
      "text 321 captcha shape (32, 100) noise 0.9131158288027452\n",
      "text 138 captcha shape (32, 100) noise 0.15823187005960007\n",
      "text 133 captcha shape (32, 100) noise 0.7341326729624481\n",
      "number of samples in group 668\n",
      "text 5669 captcha shape (32, 100) noise 0.3967302012370857\n",
      "text 7474 captcha shape (32, 100) noise 0.669756013878727\n",
      "text 7785 captcha shape (32, 100) noise 0.17239549935566176\n",
      "text 1236 captcha shape (32, 100) noise 0.10858911665510254\n",
      "text 9698 captcha shape (32, 100) noise 0.5200466638724084\n",
      "text 2915 captcha shape (32, 100) noise 0.7583476986524887\n",
      "text 4875 captcha shape (32, 100) noise 0.4995171955883015\n",
      "text 1534 captcha shape (32, 100) noise 0.4138648043515131\n",
      "text 9098 captcha shape (32, 100) noise 0.34823356904067393\n",
      "text 4478 captcha shape (32, 100) noise 0.547606627387649\n",
      "text 8851 captcha shape (32, 100) noise 0.9804961774760472\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import numpy as np\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
    "from PIL import Image\n",
    "from claptchagen.claptcha import Claptcha\n",
    "from torch.distributions import constraints\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from gmade import GMADE\n",
    "import matplotlib.pyplot as plt\n",
    "print(pyro.__version__)\n",
    "\n",
    "captcha_folder = 'generated_captchas'\n",
    "captchaHeight = 32\n",
    "captchaWidth = 100\n",
    "captchaMarginX = 4\n",
    "captchaMarginY = 4\n",
    "batch_size = 10\n",
    "\n",
    "char_dict = string.digits\n",
    "USE_CUDA = True\n",
    "MAX_N = 4 # maximum number of letters in a captcha \n",
    "MIN_N = 2 # minimum number of letters in a captcha\n",
    "MIN_NOISE = 0.01 # minimum noise\n",
    "MAX_NOISE = 0.99 # maximum noise\n",
    "smoke_test = False\n",
    "num_steps = 400 if not smoke_test else 10\n",
    "TrainingSample = 2000 if not smoke_test else 100 # number of captchas generated for training \n",
    "hidden_state_dim = 32\n",
    "\n",
    "def randomString():\n",
    "    \"\"\"\n",
    "    return a string with <num_char> random letters\n",
    "    \"\"\"\n",
    "    k = random.randint(MIN_N, MAX_N) # sample number of characters\n",
    "    \n",
    "    rndLetters = (random.choice(char_dict) for _ in range(k))\n",
    "    \n",
    "    pad_spaces = MAX_N - k # pad the string so the captcha is close to center\n",
    "    space = \" \" * (pad_spaces // 2)\n",
    "    \n",
    "    return space + \"\".join(rndLetters) + space\n",
    "\n",
    "def ramdomNoise():\n",
    "    \"\"\"\n",
    "    return a float between MIN_NOISE, MAX_NOISE\n",
    "    \"\"\"\n",
    "    return random.uniform(MIN_NOISE, MAX_NOISE)\n",
    "\n",
    "def generate_random_captcha(n, save=False):\n",
    "    \"\"\"\n",
    "    generate n random captchas,\n",
    "    return a list of texts on the captchas\n",
    "    \"\"\"\n",
    "    # Initialize Claptcha object with random text, FreeMono as font, of size\n",
    "    # 100x30px, using bicubic resampling filter and adding a bit of white noise\n",
    "    c = Claptcha(randomString, \"fonts/FreeSans.ttf\", (captchaWidth, captchaHeight), (captchaMarginX, captchaMarginY),\n",
    "             resample=Image.BILINEAR, noise=0)\n",
    "    captcha_generated = [ [] for i in range(MAX_N)]\n",
    "    for i in range(n):\n",
    "        c.noise = ramdomNoise()\n",
    "        if save:\n",
    "            text, _ = c.write(os.path.join(captcha_folder, 'captcha{}.png'.format(i)))\n",
    "            os.rename(os.path.join(captcha_folder, 'captcha{}.png'.format(i)),os.path.join(captcha_folder, '{}.png'.format(text + \"_\" + str(i))))\n",
    "        text, image = c.image\n",
    "        text = text.strip()\n",
    "        image = np.array(image)[:, :, 0] # the generator is gray scale, only keep one channel is enough\n",
    "        captcha_generated[len(text) - 1].append((text, image, c.noise))\n",
    "    return captcha_generated\n",
    "    \n",
    "captcha_generated = generate_random_captcha(TrainingSample, save=False)\n",
    "for lst in captcha_generated:\n",
    "    print(\"number of samples in group\", len(lst))\n",
    "    # print some sample captcha information generated\n",
    "    for i, t in enumerate(lst):\n",
    "        print(\"text\", t[0], \"captcha shape\", t[1].shape, \"noise\", t[2])\n",
    "        if i >= 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7da7f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAACMCAYAAABlPvLpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmRklEQVR4nO2dbaxe1XXn/8u+doJNCBBe4hgntrGNMYZgYkFTklHVtCozRSWqFLWRGjGjRHxpZ5JRRgPTL1U/VOJDVc1IrSqRJhlGUxUhEglUKU0RbdI2SoCENwMG2zixucHBJIQEghMw3v1wn3v823/fve/jF67zcNdfsrzPc/bZZ++1X+5Z/73W2lFKUSKRSCQmD0tOdwUSiUQicWLIBTyRSCQmFLmAJxKJxIQiF/BEIpGYUOQCnkgkEhOKXMATiURiQnFSC3hEXBcRT0fEnoi45VRVKpFIJBLzI07UDjwilkraJek3JU1LelDSx0spT5666iUSiUSihamTePZqSXtKKXslKSLukHSDpOYCPjU1VZYvXy5JWrKk/vif/V2Sli5dOqTfeOONKt/hw4fnvHfkyJEqX0QM6WXLls1ZttfD69R6l4PvYtrBOv7iF78Y0q+99lqVj7J4+9vf3iyPZbBsbwevx5WZl0G5sX49mb3++utDemqqHmosryc/fmD0PjZa/djrD9bv0KFD1T3K6W1ve1t1j+3v9SPrO+64YL4zzjijysd6sH4+NlkP9ofLj33AOcL2+T0fM7xu9b2D7WDZXkemWbZUt5H97X3FcdcbP2xHK+3X3qd8V2vOed3HHd+HDh36YSnlfP/9ZBbw1ZKexfW0pGs8U0TcJOkmaaazNm/eLElasWJFlW/VqlVD+uyzzx7SL730UpXvRz/60ZB++eWXh/Srr75a5eMgfPe73z1n2VLd4V6nH//4x816tMpgJ3rHcbLv2rVrSD/77LNVvosuumhIb926dUj7IP7ud787pF955ZUhfeaZZ1b52K6f/vSnQ5ryk2qZ+eLxrne9a0ivXr26me+HP/zhkH7++eeH9HnnnVfle+c73znne31SUIa9P6grV64c0u94xzua5RGs32OPPVbd+8lPfjKkN27cWN1j/3zve98b0uwPqZ7sbKPX/ec///mQ5oK2ZcuWKt+GDRuGNPuRdZWk6enpIf2DH/xgSPuieu655w7pCy64YEi/733vq/JdeOGFc9ZVqufdiy++OKQPHDhQ5WObL7744iHNeS+1+5jzXpL2798/pClbli3V45YLpC/MP/vZz4Y02+h/2Dln/I8F38XxSLlItWzYJ/4BwPbv2LFjn+bAyVAoH5P0W6WUT42uPyHp6lLKf209MzU1Vc466yxJx34JcyHgIKZgpVqAXJhmy8W7hjQ7wb8Y169fP6TXrFlT3eMgeeaZZ4Y0FwipHvCs+549e6p87Di23+vETuWi739guChyMva+dltfZ14eB6NUT9SHH354SPsfH4JjyyfWpk2bhjT/qLrGwcn09NNPD+nnnnuuyjf7YSBJ69atG9LeRsqTZfsHAOH9zTryDzsXS6mtFfGPl1QvnlwU+AdGkvbtOzqHuWj7x0Xri9Tb8d73vndIs7/5MSDVfyx80eKYbI0zqf5Dyrnq/c3+Ytr/SFE27FNfVwiuJb4wc/zwD6Uvvg8++OCQ5seK1Nb0/Q8nxx3nSE/LL6V8p5Sy3X8/mU3MaUlc8S6S9FwjbyKRSCROMU5mAX9Q0saIWBcRyyX9vqR7Tk21EolEIjEfTpgDL6Ucjog/kvRVSUslfaGU8sQpq1kikUgkujhhDvxEcN5555Xrr79e0rHc9uOPPz6kyT2vXbu2yscNJfJizomSd+Kmnm+6MZ9zVa0Nv94OO3ksz0dOtLXpJtV8pG/+EZQh3+Xl8V2E88PkM52bZLsod+eOW+PJ+ULytqy7by6x7txMY1pqW4P4vgH7n1yxW16wPN+QI9dNbtf51/PPP2o0wM06H/vc0D548GCzTuRYyZtzU1mqOebWXpBUb7qyP3xjkXtDzgm/8MILQ5p95xvpLX64t//DtG9i0sCgJReplgXl7hv4nHNM+1zi+PH58/3vf39Ic4z0NidZJx8XbP/hw4dPOQeeSCQSidOIXMATiURiQrGgFMrSpUvLrGruKhapEdImrqbwuud8QPqDKqqbXF1yySVD2k3dWs4SPdM05vM6UV2kOsu6SrWJFKkHfy/VY1IeblJJGoKqp5tm9ezAvS2zcDtrUhZUP53G4TXL6I3HnqNRywTL69dyEvPnWQ83nWMZNC996qmnqnzvec97hjTN1Fy2Lfqn58jDZ5waIeVDOtLHPtvIuUQ7d6meF04LkkJr+QD4u3umfmwzx7TLgmOcY84pM84Rzh/Kz+tEOXO+SDVl5HInhUTZens5JlmGUyjmJJUUSiKRSLyVkAt4IpFITChOxpX+uLFixQpdddVVko5VK6gS9VymqcK14mnMvmsW9Dhzqw5aM7j6RRXGd5IJetbRi43UjVSrs1RZ3XOSqhRV1HPOOafKR48xWjy4esjrnsch20EPVQetF5z+YZ9Q7aUXoVSrpnzG6R/2a29ctFRgd/2mykprA/fCpSy8f0gnUe7+LraFlI+rynTHpzxJ70m1xy/Ho9MafO8VV1wxpD3uCMc77zm1RvrDrYTYLs4lt4xhP/asQfgu3nO6gtYwpFp8jpDGY3nubUraluOCHs5S3cZe3Xveq63xw7Q/98UvflFzIb/AE4lEYkKRC3gikUhMKHIBTyQSiQnFgnLgETFwlc4LtUwCaaYl1bwyva4uvfTSKh/Lb5nAOZxLbEUjdC6RvFgvnCx5VfJ2Lgvyz3zG+Wt6e9ELzLn8VvxqB8t3z9ZWZDjnfVv7EgzpK9WhUpnPZdbah/D30myNaeeb+Rx5VPcUJffp3ni83rt375B2mdGMkLyq88jkYylbN2FjGW5SSrTCG/szNDckn+v7Gqyfj1Xuc5B/9v7mnOnF56fMWHYvwibrx/6Q6v2antc1zf7Y/p5ZYm8fhs+5LNiPbKObSvbMLWeRX+CJRCIxocgFPJFIJCYUC0qhHDlypGmO1wrA44F1Wl57Hkyf6ggPDHAPUKrY7j1GtZJqr6s6LJN1d7qi5S3oMqGKSarFvRmpylPt83bwmu1wFY3v6p1cRJWwp8oTbh7Id7l6TLS8FJ1OagUYc8/OVtAv9z7smQfSpI3mh+7Jy3HBvvNxQdqAqrebxBGka3jQhVTLlqaHbmpL80VSN25Cum3btiHtsuD86Z1+xOdYd3o2SvVhHByDPs4Y3Iplu8xoNkw60sdj77SecfO1DqPoefKSJmN/SP0DHmaRX+CJRCIxocgFPJFIJCYUuYAnEonEhGJBOfA33nhj4HycF2qZPjnvS/di8kzOzZGPY9nOK5E791PFycH1+EiaGLYivEk1d05uzs3U6JL75JNPDmk37yIP3IqI6Nd8l7+XbtEeQL/l+u/cJDlNmun5AQwMb0Cu2McF38X6unkXZeMmgQT5YXKR7hZNWTi3yzr2DsFojWl3426ZQLpsObb4Lne5b+2b+F4DeX7uL/ihDY8++uiQdpM4XtNc1fceKF+OWx9n7BNyzD6/KUOOfZ9zbDPHhcuiFdHQzVDZP77vwjJ7c4TXvQibPS5+eGbeHIlEIpH4pUQu4IlEIjGhWPBohFdeeaWkY9UKqir0EOuZ0pDi6Jm9UU1xtYfUiEdhawWN7wX/Z/muzrXq4bLgc71zIAmqnq4e8rpn6kW4OkcVlqqoHxJAGTLt0enoRcs6Ob1A1Z50gNePYHud+uJ7OUZ6Zmo+LlhH0j9umsYx4/eIFq3l0eloBkfawD2NaeZISsvztTyDfXyT8nj22Were+z/FmUktQ/I8DNv6QHLdC9CIqlJjyrp0QRbYP04Hp26YZ/62CeNx/7xvuc18/nY7529O4v8Ak8kEokJRS7giUQiMaFYUArl0KFDg1WFq/JUg6hiuQpMlZXqB2kXqfZwomrj6iGtIT7wgQ9U9w4ePDhn+W6xQDWfqig97KR6x5718GD1lAXVXLfIoTrHfK42MngO87kVCoN37dy5s7pHSoHtcBWTVjNUAd37cHp6ekiTDnEPS6rizOcWHy2rI7eGYPmkFHr0h6vvHE+Uocud5bN+TmWQ/uM9p+B474Mf/OCQvvrqq6t8u3fvHtJf+cpXhvSePXuqfBwLvfNl2QfuNUyrDObzMjimW+emSvV4ah10IdV0A+XXmyOsq1uctc5i9QNgOKe5dkj1GCcl1zvnlWuMBy9LCiWRSCTewsgFPJFIJCYU8y7gEfGFiDgYEY/jt3Mj4t6I2D36v+3lkkgkEok3BeNw4P9X0l9K+n/47RZJ95VSbo2IW0bXN89X0JEjRwb+2CPhke8hl+bRysgtkVfrBd33ey14FD9yqZs3bx7S7p1FzzXecy8zen2S2/f6URbkxz0fo9/RG4/cplTzgpSfc2w8FOOyyy6r7vE5ttGjQLYOoPD+5j4COUw3AyM3S88038ugbMhburlhK0i+c7bkxF2ejM7H+vm7GOHQIxUS5HppmuamlyyP/Ku/txUVz/cXOLda3qVSfTCyy4/cPvcKfN62zEu9H2kqyzb6vhP54p4HaGt/yqNPsk7sA/fq5Xz0fRPOaefiidYBJu55yf0A7k8R836Bl1L+RdKL9vMNkm4fpW+X9NH5ykkkEonEqcWJWqFcWEo5IEmllAMRcUErY0TcJOkmqR/3OZFIJBLHhzd9RS2l3CbpNklauXJlmVUz3KyMagtNhNwbjWY8zOceYqRXGCSeJnVSrWK6iRQpEJ456Wpfy0TKzQOJXvApUgpUbd10jrKhGukB/hlAv+fBSLXP6Rqq8zxko0d5sO5u5sn+Yrv8wI2WB6zTP+MG02e7KAunBlrnG3qZrb6XpA0bNgzprVu3DmlvI80A2cZecKweqNqTknCTT76rZ+rGex7oitQGaQ2na/iulpmsVM9ves26SSWpDZoY+jhjn7BOTsnw45L942sC3+tUKucg2+hrHfuBz/hc4vh84IEHNBdO1Arl+YhYJUmj/w/Okz+RSCQSpxgnuoDfI+nGUfpGSXefmuokEolEYlzMS6FExN9J+jVJ50XEtKQ/kXSrpDsj4pOS9kv62DgvW7Zs2aDSuVpBlZW7tM6bkzbpqcosn16FrubyzED3nKTqyPKcGmkFiPKzM1vnZboqtmnTpiF9+eWXz5mW6kBArKtb01D94rtczW0FEpJqCoAUj6vApKgoT3qcSTUlRXl6P5ImIhXm9XMV+3jhwayo5nrdWV/WyS0b6Pm4a9euIe3efbT+oeWF01gtL+Sexx4pAKdQWB5Vefc8JW3glALlxr53OqBVnlMZbr3Sem+LWuvVj8+4hQ+pIdK5vl6wv32s8t379u0b0h6kipQP6+Hjxym0uTDvAl5K+Xjj1kfmLT2RSCQSbxrSEzORSCQmFLmAJxKJxITitEUjdP6IEe7oteZmS+TPeudPkhckp+URv2g659wkQS7MOW/Wg7yy1925sBYoG5qiefQzmou1zseUar6Z7XdZ9KLJkRclN0evRKk2feI9N/NseVX6uHAOchbeRnL7HrmO8DbPVQe/7gXaZz7nmCkz9oHv67BfN27cOKSvu+66Kh/NDVvjW6rbyLHqc4Tjlvytj2/OEfcw5N5Vz+SV/UWzVjf7Y98xYqWb/3K96M1NyolycQ9i1tdNlwnOM+fbuWfBvaGexybL27FjR5XP92XmQn6BJxKJxIQiF/BEIpGYUCy4b/usyumBW6iOUO1xlbp1LmRPdaIK42oJy3dVlHmp9vr5m1S/qBK5Sk1VnGqUt2n9+vVzpl31ZhCkp556akg/8sgjVT4G+KfpGNVQqaYhnP7hQQ1sv8uTFAA9NmkaKUkf+tCHhjRNx7y81vmETqFQJabZX08NpZpLrz+pHhdu5klqhH3iNEzrvEP3emT5fIYB1KTajJSUjB++QVmQNnFqgLJpHUbg9fN5RqqN9IfTWJwXLMNN5/gcKQ/3lOWcZh1awcqkPtVCOXE+986QdZqRz/Gem3nymvXtnZvaQn6BJxKJxIQiF/BEIpGYUOQCnkgkEhOKBeXAzzjjDF155ZWSjnVHJ29HkzN3R29xX84PjxtprRVZTmpHq3P+vhXhz93M+RxdaN2Fn/fYXn9PywzMo93RTM152hac3yOHSbdwlwXbTP7e+Vdes4zegdFsr/O0HE8so3fQB/cenAMn3OSM9WCfuMkjr9knPlbZx9w3cJM97gEw3eObe272rEevD3gAsJsitty9/b0sn3PJZUGZ8V0+N1tj38dtixP3NaEV3ZD9IdVmvd4/3Edg/3h4AJpHMiSEv6tlQkvkF3gikUhMKHIBTyQSiQnFglIor7/++qCOuhcT1Raqw56P5lhUv3rekVS3XQWkh5ffo9rXO4+xZarmnp1UlVl3V1mpsjOyoKuRbDMpCTfNogx52APNC6VaHfZof1TnWJ7XnSosTSW9TqRXKHc3XyQdwD516oaRGSlnV3Od1pqFm3xSHXaKi7Jm/fwMVNaD8nQzVI4TyonnnEq12Sff5eOvZYrXO2CEfeqUEc1rnaLguzl+fKySqiSt4RQH5c46ORXGsUV6qhfBj2OVZphSLZveWa6ts1el9rmiPgY59yk/p8J6/TWL/AJPJBKJCUUu4IlEIjGhWHAKhTuwRCswlXvcUb3pnWnIMqjCuArNfL5zThWG9fA6se5Uj1x1olpJbz5Xvfle0iROG1C1ZYAgP9CB91hX98SkWuo74pQ1aQ6XBdVAqqyu2m7ZsmVIU1X2oFf0NqX67nQX77XOTZVqCwDSJj3LIrcG4LvZj25tQNmQTnHvYlIqlLtbxjiNMAuXGfubsnWVnOOu1W9STRk6fUgZts5DlWqqknPQ81GGpHI8X8uqx71m2Wbe8/WCc5Vj1ecwKQ9fL1pWcZxXUn2IDN/l46znVTqL/AJPJBKJCUUu4IlEIjGhyAU8kUgkJhQLyoEvWbJk4K6cSyM3y3TvYGByUG4GNk7ZXr5HAyMXSC7WTRt7PBbBe70oZDRTo1emy2zv3r1Dmry3c+r0MiOX6BwruUlvB7m/VoRAqQ7Qv3///rHq1Ds0l9fM1zugl2k3zSJnTc6yZzbpZbAt7BM3DyQnzLHk3Cn7hHyp5yOHy/b3ouIRXh7nEsdjb3/BeVnuFXBu+bvY/p55HPundzCHc9Oz8H0IlsH2+l5Yi9t2WfLaZdE6mN09qFmP1mEw4yK/wBOJRGJCkQt4IpFITCgWlEI5cuTIoD652kcPNJq3uYcl1Q+aabla1joj0mkIPtdT86m+et2pOlM183xUTXumVKRNqMq7isVrmhS66kn1lW10mbXOJZXaqmPPVJLtd8+3hx56aEhTti4LeljyoAb32CQNxbRTQaRX+C73qmM7nFLgmGQfUP2XanWepn1OC9KkkqaC3j+kyZjumbWyri5btplyck/MnkckqSfOLR+DlEXPE5Pzu0WXSrU5aO9cUpbRCyBHc1OOLaf06Nnq5patcee0Dscx+9jrPk7gufwCTyQSiQnFvAt4RKyJiH+OiJ0R8UREfHr0+7kRcW9E7B79f858ZSUSiUTi1GEcCuWwpM+WUh6KiHdI+k5E3CvpP0u6r5Rya0TcIukWSTf3Clq+fPmgurjlBVUa9xAkqBK2dtGl2rOut9NLSwmeK+mg6ujUCNGLv9xSvV0FpmpGNcpjJzPON9VeV+1aFga+O876uQrsquRc5Um1mk45+fNUU1vqtZdBdd1V4FasbO+PlprvHnx8L70IpXrs9qyYaNlACsW9Q1ux670PeM0Y3U5PEay705Etj1r3HGQb3WO1FSiOdIW/uzf2SXGRhnA6if3VOrtWqvuR+bw8jlvOK6fF9u3bN6RJp3he1sPHPsdkK7b8uJj3iVLKgVLKQ6P0y5J2Slot6QZJt4+y3S7po8f99kQikUicMI5rEzMi1kraJul+SReWUg5IM4t8RMx5pElE3CTpJqn/5ZpIJBKJ48PY3+wRcaakL0n6TCmlbWFvKKXcVkrZXkrZ7up2IpFIJE4cY32BR8QyzSzef1tK+fLo5+cjYtXo63uVpIPtEkYvm5oa+G1fzFvcn/OKNL9jGV4euVTyWx78nuU5r0rTPPJbfuYkPSdpbufvIt/X41/JkfK9Pb55zZo1Q9rNj1hf8uPOsZKDcw80nh956aWXDmk/qIH1/cY3vjGk6aEp1eaH7CuXGblTanDOxZL3dhNDovUR4Vw5y+M4kGo50Zu1d64m+XtGo5NqU0mOJZqxSjXX3RsXrDvHlnOslCff6+ORnLXz7awj6+GerTRZZNpNKrlX8MwzzwxpN1/keORY7Xlktw5Ukeq5Sdk6z03u3Mcq5yPTvvfA8c79Bj83lvK84447NBfGsUIJSZ+XtLOU8he4dY+kG0fpGyXdPV9ZiUQikTh1GOcL/FpJn5C0IyIeGf32x5JulXRnRHxS0n5JH3tTaphIJBKJOTHvAl5K+TdJ0bj9keN52SuvvKKvfe1rko41F2udp+cmTfR67AWQpwkSaRIPYkO1d+PGjdU9ei0y7SoR38V7PXM+0jWuHl5zzTVDmiZNjpZHm8uCsuWZmDRFk9pnOEo1RbNt27Yh7R6MX//614c0KRQ/ZIKUCvvR+5t0EM0NXbatPvZxxv5hvzkNQfXYPelI0VC2Lnde86AGly3pJLbXTV45Bmma5nQA75ECcJW/RSc53cX2+zOUISkZp2v4bs5vn489z1GCcmodTCHVVBvl5IHHmK9l8ijV7e+d18vnOHekY6nak0F6YiYSicSEIhfwRCKRmFDkAp5IJBITigWNRlhKOcb8axatgOrO25H74j13eaW5D9POzdGkyw/yJadFLrF3cKrXlyAfS+7YOdGWmZHzduTOx90PIN/qIQtYJ49GyHezDxiKQKrbT+7Peb/LL798SJPD5MEZfo8cq9edvCrb6OaB5C3JdXpURfaB86Dsf9bPef6Wm73vPdx1111Dmv3tZonsH84jdwsnD9xzW2c/tublfHViv7K9vvfAd3Fe+YHMBMf0uAcruBkh28yxSZd4r3vLxFWq2+GRLjds2DCkOae9jffff/+Q5nj0taPXJ7PIL/BEIpGYUOQCnkgkEhOKBaVQpqamBtXCqYwWBeAmUlRhqN64ORLVzZ55E83R9uzZU92jlxlVZffEpKkfVWU/f7NVd1dtqWIy7eoc1UVSSPRgk+qzM6keunkTVUD3FmQ9qAKybKmWxYc//OE56yrVaj8D3LuKTgqENI73AWkD9qmbaJIO4DNOBbFOLne+m9H+nOJqed66+RlpDrZ3586dVT6Ox97ZkazH+vXrh7RTa2wzZebjgtc+Hykbeqz6uKApIueF0wStgzScMmuZXrrXLKnPFp0i1ZQHvTzdXNWvCfZJ6/xbqV4j2He9c4JbyC/wRCKRmFDkAp5IJBITigW3QplVH1213bx585CmCuM7+1TNWqqnVKt6rSDxUq0SeaB9Bmqi1YSHxW0dHuEem7xH1c7P4qRaxXa5CkxVmRY0bvFx1VVXDWnKzK1puFv+rW99q7pHSoHPudyp5u/YsWNIO4XCevAZ37GnbNlG9wBtWS6RFvLnSNc4NcB3OeXBfiS94F6zlBNVe5dZi06j16xUy6x39mrrXElXydl+zkenF3bt2jVnPqmeT5xLbhnDOpL+cCqsdSCIW6GQbmhZBUm1PLnGrFu3rsrHPmb/eDC9FgUn1XOa65ZTa6SDOB57VkKcf0R+gScSicSEIhfwRCKRmFDkAp5IJBITigXlwJcsWTJwZs7bkd8jt+QB37du3TqkaWbUi8hG/tHNjMjpOT/OAOvM5xwm685IdR7VjWZGbH8v6hq5P+fU2cYWD+8gr/rAAw9U97gH4OZdbDPf67wd+4Emm87h8RBmys/5V173Dp2mnJh2D116enL8uLclOVzfKyCff8kllwxpN70kv8s+drMytpF9zH0XSbr22muHNM3yWvyov9fN1DgX2P6eJ2/vUAjCxyrHFs0jn3zyye5zrfe28vnYZx9zLPhhGa2y3WyQz/lhD5wz7FPfW+O60DrQelzkF3gikUhMKHIBTyQSiQnFglIoK1as0Pbt2yUdq85RvaEpmXvm0WOKKoebelH14Tl+bmbE57xOBNVKNx+imRXLcJX6/e9//5x1d7qCailVZVcjqdqyjOnp6Srf7t27hzTNA++7774qH1V+N4kjLcH2uxpJ8ymm/aAGXlPNdUqG7yVd4eOC72KwKDdD5dgiLUaPRak29fIDHageP/LII0P6m9/8ZpWPY4amc04Lsr9JQfnhCbxH+sPH4+rVq4c0zSjdZI9UQcv00K99rLK/2EYPDMcy2Pcu99YBGU4vsA96prGts2c9aBrpUq4x7gHKcedUKtcwvqsnT5opekA15vvc5z6nuZBf4IlEIjGhyAU8kUgkJhQLSqG8+uqrevjhh+e819qJ911uqlikSZ577rkqH1UuekJRVZJqldrV7ZYnmKtEVAPZDgY6kup2kXbxIFpUj2kNsWXLliofvQBJ3Xz1q1+t8pEqYZs8aBHl6YGUWoG4XBb0EKRHrVMozEcqyD3uWnG53dOPsqVa6lZHVPlpHeBWCawfPfikmsqhVQ89T6WaAmCdfFy0qAIPsMUxznHsVB37hM84vcCY2JSTx6dnP7qcSC9xnrkFDeVJKwyftxyfrTj2Ui1Ppn1MU9akzNw7suUd6tZJlJPTsbQGojVaz1OW8vM48W69MhfyCzyRSCQmFLmAJxKJxIQiF/BEIpGYUMSJeP+cKM4666xyzTXXzHnPTaZm4d6M5MzIe7r3GHkxmjR5dDHygs530USO5kjkBKVjTaFm8dhjj1XX5DTJzTkvT764ZW4n1fwwZeGefuxj8tzupdjbD6Dp22WXXTaknXNsRWN0L0py7OyTTZs2VfkoG7ardyAI79HjU2pHs3TunePJDwvhNevuZnocqxwLziNTZmyjj9XWe71+HNN8l3sVcj+AaTcV5P6Ht5HXnGc+Lrwts/D1h3Xv7VFwfJIr9yiDjPbHPnZemnOdPLfvG/QOC2GbGcmUab/mu9yjlibON99883dKKdtlyC/wRCKRmFDMu4BHxNsj4oGIeDQinoiIPx39fm5E3BsRu0f/nzNfWYlEIpE4dZiXQokZPXhlKeWViFgm6d8kfVrS70p6sZRya0TcIumcUsrN85RVZtVbV/todnTxxRcPafeYogpMVdlVO1IUVKPc7I2mO262RbWS6owHvaIqRarBVVHWl+qWe3vRxPDxxx8f0u4pSnMvtt8pFNaJ73JzNprmOb1CKoLqq3sBtkwC3cOSXmw04fJxwf7yQyEIqs70RHSqhaDK6kGV+C43ieO7aAbmtBPr3gtmxX5luneOKOkfp/7YB6TgvA84t2j25geCUOX3cUFTut4BK0Tr0AavO/M5xdU6IMLHD8sjzeZ0JGXTOq9Vqk0v3ZS1d5YvwT7ueX2yvLvvvvvEKJQyg1kyatnoX5F0g6TbR7/fLumj85WVSCQSiVOHsTjwiFgaEY9IOijp3lLK/ZIuLKUckKTR/xc0nr0pIr4dEd8+RXVOJBKJhMZcwEspb5RSrpR0kaSrI2LrPI/w2dtKKdvn+vxPJBKJxInjuFzpSykvRcTXJF0n6fmIWFVKORARqzTzdd7FihUrBndw5ybpgk5e2nnatWvXDmmaGD7xxBNVPpogkRfzKHY0b7riiiuqe+SxyFuSL5RqLpF1cg6T3Bc5uN6BDmy/B7F3c8ZZ+MHAdPcmP0xZSu2DhqX24c/O5zL6Hc0NHS3TRuccWQ/ylL4fQFlz78HDFDz66KND2t3sCbpae6RLghyw8+iUDfdJ3C2cPC3Ho3PRHMc9k0qCsnD+muObY8b3Ne6///5mnRhmgHyuc8CtA729Tq0Iie62zoiblCcPfJFqOdGU0w+MZpgKpj1MAd/l+4ecq5zTbk7MCJZc93xcjINxrFDOj4izR+kzJP2GpKck3SPpxlG2GyXdfdxvTyQSicQJY5wv8FWSbo+IpZpZ8O8spfx9RHxT0p0R8UlJ+yV97E2sZyKRSCQMC+qJGREvSNon6TxJ7UPpFhdSFkeRsjiKlMUMUg4zeF8p5Xz/cUEX8OGlEd/OTc0ZpCyOImVxFCmLGaQc+khX+kQikZhQ5AKeSCQSE4rTtYDfdpre+8uIlMVRpCyOImUxg5RDB6eFA08kEonEySMplEQikZhQ5AKeSCQSE4oFXcAj4rqIeDoi9oxC0C4aRMSaiPjniNg5iqv+6dHvizau+ihI2sMR8fej60Upi4g4OyLuioinRuPjg4tYFv99ND8ej4i/G51HsChlMQ4WbAEfeXL+laT/KGmLpI9HxJb+U28pHJb02VLKpZJ+RdIfjtp/i6T7SikbJd03ul4s+LSknbherLL4P5L+oZSyWdL7NSOTRSeLiFgt6b9J2l5K2SppqaTf1yKUxbhYyC/wqyXtKaXsLaW8JukOzcQUXxQopRwopTw0Sr+smUm6Wos0rnpEXCTptyX9DX5edLKIiLMk/QdJn5ekUsprpZSXtAhlMcKUpDMiYkrSCknPafHKYl4s5AK+WhLD5E2Pflt0iIi1krZJGjuu+lsQ/1vS/5TEY4sWoyzWS3pB0hdHdNLfRMRKLUJZlFK+L+nPNRNb6YCkn5RS/lGLUBbjYiEX8Jjjt0VnwxgRZ0r6kqTPlFJ+Ol/+tyIi4npJB0sp3znddfklwJSkqyT9dSllm6SfaZFSBCNu+wZJ6yS9R9LKiPiD01urX24s5AI+LWkNri/SjHq0aDA6U/RLkv62lPLl0c/Pj+Kpa9y46m8BXCvpdyLie5qh0n49Iv6/FqcspiVNj065kqS7NLOgL0ZZ/Iak75ZSXiilvC7py5J+VYtTFmNhIRfwByVtjIh1EbFcM5sT9yzg+08rRodDf17SzlLKX+DWoourXkr5X6WUi0opazUzDv6plPIHWpyy+IGkZyPiktFPH5H0pBahLDRDnfxKRKwYzZePaGavaDHKYiwsdDjZ/6QZ7nOppC+UUv5swV5+mhERH5L0r5J26Cjv+8ea4cHvlPRejeKql1JenLOQtyAi4tck/Y9SyvUR8S4tQllExJWa2cxdLmmvpP+iUex9LT5Z/Kmk39OM1dbDkj4l6UwtQlmMg3SlTyQSiQlFemImEonEhCIX8EQikZhQ5AKeSCQSE4pcwBOJRGJCkQt4IpFITChyAU8kEokJRS7giUQiMaH4d/xZtjRrFMhBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lst in captcha_generated:\n",
    "    if len(lst) > 0:\n",
    "        plt.imshow(lst[0][1], cmap=\"Greys\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "negative-underwear",
   "metadata": {
    "id": "negative-underwear"
   },
   "outputs": [],
   "source": [
    "def render_image(chars, fonts=\"fonts/FreeSans.ttf\", size=(captchaWidth, captchaHeight), \n",
    "                 margin=(captchaMarginX, captchaMarginY), resample=Image.BILINEAR, noise=0.3, use_cuda=False):\n",
    "    #noise = noise.data.item()\n",
    "    #print(chars, noise)\n",
    "    pad_spaces = MAX_N - len(chars)\n",
    "    space = \" \" * (pad_spaces // 2)\n",
    "    chars = space + chars + space\n",
    "    render = Claptcha(chars, fonts, size, margin, resample=resample, noise=noise)\n",
    "\n",
    "    \n",
    "    _ , rendered_image = render.image\n",
    "    rendered_image = np.array(rendered_image)[:,:,0] # the generator is gray scale, only keep one channel is enough\n",
    "    rendered_image = np.subtract(np.divide(rendered_image, 255), 0.5)\n",
    "    rendered_image = torch.from_numpy(rendered_image)\n",
    "    if use_cuda:\n",
    "        rendered_image = rendered_image.cuda()\n",
    "    return rendered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "contrary-lobby",
   "metadata": {
    "id": "contrary-lobby"
   },
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, raw_captchas, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.raw_captchas = raw_captchas\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_captchas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.raw_captchas[idx][0]\n",
    "        image = self.raw_captchas[idx][1]\n",
    "        noise = self.raw_captchas[idx][2]\n",
    "        \n",
    "        image = np.subtract(np.divide(image, 255), 0.5)\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return label, image, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "taken-spice",
   "metadata": {
    "id": "taken-spice"
   },
   "outputs": [],
   "source": [
    "def make_loarders(BATCH_SIZE, raw_samples):\n",
    "    dataloaders = [] # dataloaders for different num of char\n",
    "    for lst in raw_samples:\n",
    "        if lst:\n",
    "            ds = CaptchaDataset(lst)\n",
    "            dataloader = DataLoader(ds, batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True, num_workers=0, drop_last=True)\n",
    "            dataloaders.append(dataloader)\n",
    "    return dataloaders\n",
    "\n",
    "def make_batches(dataloaders):\n",
    "    all_batches = []\n",
    "    for dl in dataloaders:\n",
    "        for i_batch, sample in enumerate(dl):\n",
    "            all_batches.append(sample)\n",
    "    random.shuffle(all_batches)\n",
    "    random.shuffle(all_batches)\n",
    "    return all_batches\n",
    "\n",
    "TrainLoaders = make_loarders(BATCH_SIZE=batch_size, raw_samples=captcha_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arabic-rocket",
   "metadata": {
    "id": "arabic-rocket"
   },
   "outputs": [],
   "source": [
    "class NoiseNet(nn.Module):\n",
    "\n",
    "    def __init__(self, img_size, out_size = 1):\n",
    "        \"\"\"\n",
    "        Network for learning noise in a captcha\n",
    "        \"\"\"\n",
    "        super(NoiseNet, self).__init__()\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.fc0 = nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1])\n",
    "        self.fc1 = nn.Linear(img_size[0] * img_size[1], 1024)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc20 = nn.Linear(1024, img_size[0] * img_size[1])\n",
    "        self.fc21 = nn.Linear(img_size[0] * img_size[1], out_size)\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, img):\n",
    "        BS = img.shape[0]\n",
    "        img = img.reshape(-1, self.img_size[0] * self.img_size[1])\n",
    "        hidden = F.relu(self.fc0(img))\n",
    "        hidden = self.fc1(hidden)\n",
    "        # mean of noise, used in normal distribution\n",
    "        noise_map = self.fc20(F.relu(self.fc2(F.relu(hidden))))\n",
    "        mean =  self.fc21(F.relu(noise_map))\n",
    "        # std used in normal distribution\n",
    "        sigma = torch.tensor([[1e-8] for _ in range(BS)]).float()\n",
    "        if USE_CUDA:\n",
    "            sigma = sigma.cuda()\n",
    "        return mean, sigma, noise_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "patient-sunset",
   "metadata": {
    "id": "patient-sunset"
   },
   "outputs": [],
   "source": [
    "class NumNet(nn.Module):\n",
    "    def __init__(self, img_size, out_size = 3):\n",
    "        \"\"\"\n",
    "        Network for learning N, number of letters in a captcha\n",
    "        \"\"\"\n",
    "        super(NumNet, self).__init__()\n",
    "        self.neural_net = nn.Sequential(\n",
    "            nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1] * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(img_size[0] * img_size[1] * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, out_size),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "  \n",
    "    def forward(self, img):\n",
    "        img = torch.reshape(img, (img.shape[0], img.shape[1] * img.shape[2]))\n",
    "        prob = self.neural_net(img)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "authorized-sender",
   "metadata": {
    "id": "authorized-sender"
   },
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, img_size, output_size, MAX_N):\n",
    "        \"\"\"\n",
    "        Network for letters in a captcha, given the noise and number of letters\n",
    "        \"\"\"\n",
    "        super(InputEmbedding, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # observe layers\n",
    "        self.nnfc = nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1])\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.convBN1 = nn.BatchNorm2d(64)\n",
    "        self.convBN2 = nn.BatchNorm2d(64)\n",
    "        self.convBN3 = nn.BatchNorm2d(64)\n",
    "\n",
    "    def forward(self, img, noise_map):\n",
    "        \n",
    "        BATCH_SIZE = img.shape[0]\n",
    "        img = torch.reshape(img, (BATCH_SIZE, 1, self.img_size[0], self.img_size[1]))\n",
    "\n",
    "        img = self.pool(F.relu(self.convBN1(self.conv1(img))))\n",
    "        img = self.pool(F.relu(self.convBN2(self.conv2(img))))\n",
    "        img = self.pool(F.relu(self.convBN3(self.conv3(img))))\n",
    "        \n",
    "        img = torch.reshape(img, (BATCH_SIZE, 1280))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sensitive-greek",
   "metadata": {
    "id": "sensitive-greek"
   },
   "outputs": [],
   "source": [
    "class CharNetSingle(nn.Module):\n",
    "    def __init__(self, img_size, output_size, MAX_N):\n",
    "        \"\"\"\n",
    "        Network for letters in a captcha, given the noise and number of letters\n",
    "        \"\"\"\n",
    "        super(CharNetSingle, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # branches\n",
    "        self.pfc1 = nn.Linear(1280 + hidden_state_dim + 1, 2048)\n",
    "        self.pfc2 = nn.Linear(2048, 1024)\n",
    "        self.pfc3 = nn.Linear(1024, 1024)\n",
    "        self.pfc4 = nn.Linear(1024, output_size)\n",
    "\n",
    "    def forward(self, img_embedded, hid, noise_batch):\n",
    "        \n",
    "        BATCH_SIZE = img_embedded.shape[0]\n",
    "\n",
    "        img = torch.cat((img_embedded, hid, noise_batch), 1)\n",
    "        \n",
    "        out = F.relu(self.pfc1(img))\n",
    "        out = F.relu(self.pfc2(out))\n",
    "        out = F.relu(self.pfc3(out))\n",
    "        out = self.pfc4(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1244e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=32, out_size=1, t=\"normal\", out_non_linear=None):\n",
    "        super().__init__()\n",
    "        self.t = t\n",
    "        self.out_non_linear = out_non_linear\n",
    "        self.hiddeen_layer = nn.Linear(input_size, hidden)\n",
    "        if t == \"normal\":\n",
    "            self.loc_layer = nn.Linear(hidden, out_size)\n",
    "            self.std_layer = nn.Linear(hidden, out_size)\n",
    "            self.softplus = nn.Softplus()\n",
    "        elif t == \"bern\":\n",
    "            self.prob_layer = nn.Linear(hidden, out_size)\n",
    "        elif t == \"mlp\":\n",
    "            self.out_layer = nn.Linear(hidden, out_size)\n",
    "        \n",
    "    def forward(self, x_list):\n",
    "        for i in range(len(x_list)):\n",
    "            if x_list[i].dim() == 0:\n",
    "                x_list[i] = torch.unsqueeze(x_list[i], dim=0)\n",
    "        input_x = torch.cat(x_list, 1)\n",
    "        #print(input_x, input_x.shape)\n",
    "        hid = F.relu(self.hiddeen_layer(input_x))\n",
    "        # return loc, std\n",
    "        if self.t == \"normal\":\n",
    "            return self.loc_layer(hid), self.softplus(self.std_layer(hid))\n",
    "        elif self.t == \"bern\":\n",
    "            return torch.sigmoid(self.prob_layer(hid))\n",
    "        else:\n",
    "            if self.out_non_linear == \"tanh\":\n",
    "                return torch.tanh(self.out_layer(hid))\n",
    "            else:\n",
    "                return self.out_layer(hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "overhead-meditation",
   "metadata": {
    "id": "overhead-meditation"
   },
   "outputs": [],
   "source": [
    "def inference(t, use_cuda=False):\n",
    "    \"\"\"\n",
    "    one epoch of inference (iterate the training set once)\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    loss = 0\n",
    "    length = TrainingSample\n",
    "    loss_group = []\n",
    "    all_batches = make_batches(TrainLoaders)\n",
    "    for i_batch, sample_batched in enumerate(all_batches):\n",
    "        \n",
    "        img = sample_batched[1]\n",
    "        if use_cuda:\n",
    "            img = img.cuda()\n",
    "        IMG = {\"captcha\" : img}\n",
    "        imme_loss = csis.step(observations=IMG)\n",
    "        loss += imme_loss / length\n",
    "\n",
    "    print(\"loss at epoch {} is {}\".format(t, loss), end=\"; \")\n",
    "    print(\"Epoch takes\", round(time.time()- start), \"seconds\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "agreed-provincial",
   "metadata": {
    "id": "agreed-provincial"
   },
   "outputs": [],
   "source": [
    "test_accuracies = []\n",
    "test_char_accuracies = []\n",
    "test_noise_differences = []\n",
    "train_accuracies = []\n",
    "train_char_accuracies = []\n",
    "train_noise_differences = []\n",
    "\n",
    "def test(n = 0, use_train=False, verbose=False, use_cuda=False):\n",
    "    \"\"\"\n",
    "    benchmarking performance on customized or training set\n",
    "    \"\"\"\n",
    "    global test_accuracies, test_char_accuracies, train_accuracies, train_char_accuracies, train_noise_differences, test_noise_differences\n",
    "    if use_train:\n",
    "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=captcha_generated)\n",
    "    else:\n",
    "        test_captcha_generated = generate_random_captcha(n, save=False)\n",
    "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=test_captcha_generated)\n",
    "    \n",
    "    total_correct = 0\n",
    "    char_correct = 0\n",
    "    total_char = 0\n",
    "    all_batches = make_batches(TestLoaders)\n",
    "    noise_difference = 0\n",
    "    for i_batch, t in enumerate(all_batches):\n",
    "\n",
    "        label = t[0][0]\n",
    "        gt_noise = t[2][0]\n",
    "        img = t[1]\n",
    "\n",
    "        if use_cuda:\n",
    "            img = img.cuda()\n",
    "        \n",
    "        IMG = {\"captcha\" : img}\n",
    "        \n",
    "        posterior = csis.run(observations=IMG)\n",
    "        marginal_num = pyro.infer.EmpiricalMarginal(posterior, \"num_char\")\n",
    "        marginal_noise = pyro.infer.EmpiricalMarginal(posterior, \"noise\")\n",
    "        with torch.no_grad():\n",
    "\n",
    "            N_index = marginal_num()\n",
    "            N = N_index + captchaModel.num_char_domain[0]\n",
    "            noise = captchaModel._map_to_noise_range(marginal_noise()[0])\n",
    "            sampled_chars = []\n",
    "            \n",
    "            # sample characters one by one\n",
    "            for i in range(N):\n",
    "                marginal_char = pyro.infer.EmpiricalMarginal(posterior, \"char_{}\".format(i))()[0]\n",
    "                if use_cuda:\n",
    "                    marginal_char.cpu()\n",
    "                sampled_chars.append(marginal_char)\n",
    "        \n",
    "        chars = \"\"\n",
    "        for i in range(len(sampled_chars)):\n",
    "            c = sampled_chars[i]\n",
    "            chars +=  captchaModel.char_dict[c]\n",
    "        correct = 0\n",
    "        \n",
    "        for p_char, t_char in zip(chars, label):\n",
    "            if p_char == t_char:\n",
    "                correct += 1\n",
    "        noise_difference += abs(float(noise) - float(gt_noise))\n",
    "        if not verbose:\n",
    "            print(\"N_predicted:\", int(N), \"| Actual N:\", len(label), \"| Predicted Noise:\", round(float(noise), 3), \"| Actual Noise:\", round(float(gt_noise), 3), \"| Predicted Text:\", chars, \"| Actual Text:\", label, \"| Correct:\", correct)\n",
    "        if correct == len(label) and int(N) == len(label):\n",
    "            total_correct += 1\n",
    "        char_correct += correct\n",
    "        total_char += len(label)\n",
    "    num_test_samples = i_batch + 1\n",
    "    accuracy = total_correct / num_test_samples\n",
    "    char_accuracy = char_correct / total_char\n",
    " \n",
    "    \n",
    "    noise_difference = noise_difference / num_test_samples\n",
    "    if use_train:\n",
    "        train_accuracies.append(accuracy)\n",
    "        train_char_accuracies.append(char_accuracy)\n",
    "        train_noise_differences.append(noise_difference)\n",
    "    elif n > 10:\n",
    "        test_accuracies.append(accuracy)\n",
    "        test_char_accuracies.append(char_accuracy)\n",
    "        test_noise_differences.append(noise_difference)\n",
    "    print(\"use_train =\", use_train, \"AVG Noise Difference:\", noise_difference, \"Total correct:\", total_correct, \"accuracy:{}/{}=\".format(total_correct, num_test_samples), accuracy, \"char_accuracy:{}/{}=\".format(char_correct, total_char), char_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "occupied-invitation",
   "metadata": {
    "id": "occupied-invitation"
   },
   "outputs": [],
   "source": [
    "\n",
    "losses  = []\n",
    "def test_cycle(use_cuda):\n",
    "    \n",
    "    # disable dropout\n",
    "#     captchaModel.numNet.eval()\n",
    "#     captchaModel.charNetSingle.eval()\n",
    "    test(use_train=True, verbose=True, use_cuda=use_cuda)\n",
    "    test(1000, use_train=False, verbose=True, use_cuda=use_cuda)\n",
    "    #test(10, use_train=True, verbose=False, use_cuda=use_cuda)\n",
    "    test(10, use_train=False, verbose=False, use_cuda=use_cuda)\n",
    "    # enable dropout\n",
    "#     captchaModel.numNet.train()\n",
    "#     captchaModel.charNetSingle.train()\n",
    "\n",
    "def optimize(start_epoch=1, use_cuda=False):\n",
    "    \"\"\"\n",
    "    Training/Inferencing Stage\n",
    "    \"\"\"\n",
    "    loss_sequence = []\n",
    "    pause = 5\n",
    "    save_pause = 10\n",
    "    print(\"Optimizing...\")\n",
    "    for t in range(start_epoch, num_steps + 1):\n",
    "        L = inference(t, use_cuda)\n",
    "        loss_sequence.append(L)\n",
    "        losses.append(L)\n",
    "        if (t % pause == 0) and (t > 0):\n",
    "            test_cycle(use_cuda=use_cuda)\n",
    "        #if (t % save_pause == 0) and (t > 0):\n",
    "        #    save_and_download_checkpoints(\"branches-1-no-var-no-tanh_model.pt\", \"branches-1-no-var-no-tanh_optim.pt\", \"branches-1-no-var-no-tanh_param_store.pt\")\n",
    "    plt.plot(loss_sequence)\n",
    "    plt.title(\"loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "JtIuFFPvdzKk",
   "metadata": {
    "id": "JtIuFFPvdzKk"
   },
   "outputs": [],
   "source": [
    "# saves the model and optimizer states to disk\n",
    "def save_checkpoint(currentModel, currentOptimzier, save_model, save_opt, save_param_store):\n",
    "    print(\"saving model to %s...\" % save_model)\n",
    "    torch.save(currentModel.state_dict(), save_model)\n",
    "    print(\"saving optimizer states to %s...\" % save_opt)\n",
    "    currentOptimzier.save(save_opt)\n",
    "    print(\"saving pyro pram store states to %s...\" % save_param_store)\n",
    "    pyro.get_param_store().save(save_param_store)\n",
    "    print(\"done saving checkpoints to disk.\")\n",
    "\n",
    "# loads the model and optimizer states from disk\n",
    "def load_checkpoint(myModel, myOptimzer, load_model, load_opt, load_param_store):\n",
    "    pyro.clear_param_store()\n",
    "    print(\"loading model from %s...\" % load_model)\n",
    "    myModel.load_state_dict(torch.load(load_model))\n",
    "    print(\"loading optimizer states from %s...\" % load_opt)\n",
    "    myOptimzer.load(load_opt)\n",
    "    print(\"loading pyro pram store states from %s...\" % load_param_store)\n",
    "    pyro.get_param_store().load(load_param_store)\n",
    "    print(\"done loading states.\")\n",
    "    pyro.module(\"guide\", myModel, update_module_params=True)\n",
    "\n",
    "def save_and_download_checkpoints(save_model, save_opt, save_param_store):\n",
    "    save_checkpoint(captchaModel, optimiser, save_model, save_opt, save_param_store)\n",
    "def save_metric_to_disk(file_path):\n",
    "    import json\n",
    "    save_dict = {\n",
    "        \"test_accuracies\" : test_accuracies,\n",
    "        \"test_char_accuracies\" : test_char_accuracies,\n",
    "        \"test_noise_differences\" : test_noise_differences,\n",
    "        \"train_accuracies\"  : train_accuracies,\n",
    "        \"train_char_accuracies\"  : train_char_accuracies,\n",
    "        \"train_noise_differences\" : train_char_accuracies\n",
    "    }\n",
    "    with open(file_path, 'w') as fout:\n",
    "        json.dump(save_dict, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e723b63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "composite-secretary",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "composite-secretary",
    "outputId": "ba21847c-cace-42fd-c32b-3d6802c890ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_dependencies num_char ['img']\n",
      "all_dependencies noise ['img']\n",
      "all_sets [(0,)]\n",
      "input_ordering [0]\n",
      "out_sets [(0,), (0,)]\n",
      "out_orderings [0, 0]\n",
      "hid_orderings size 3200\n",
      "num hid layers: 3\n",
      "expanded_input_ordering size 3200\n",
      "expanded_output_ordering size 5\n",
      "number of levels: 1\n",
      "input_levels [['img']]\n",
      "out_levels [['num_char', 'noise']]\n",
      "all_dependencies char ['img_embedded']\n",
      "all_sets [(0,)]\n",
      "input_ordering [0]\n",
      "out_sets [(0,)]\n",
      "out_orderings [0]\n",
      "hid_orderings size 3840\n",
      "num hid layers: 3\n",
      "expanded_input_ordering size 1280\n",
      "expanded_output_ordering size 10\n",
      "number of levels: 1\n",
      "input_levels [['img_embedded']]\n",
      "out_levels [['char']]\n",
      "Optimizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\anaconda3\\envs\\pyro-env\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 1 is 7.136386923551561; Epoch takes 129 seconds\n",
      "loss at epoch 2 is 5.936099377393724; Epoch takes 127 seconds\n",
      "loss at epoch 3 is 5.339044213771819; Epoch takes 127 seconds\n",
      "loss at epoch 4 is 4.993703140735627; Epoch takes 127 seconds\n",
      "loss at epoch 5 is 4.620672351956366; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.11044831753530476 Total correct: 89 accuracy:89/2000= 0.0445 char_accuracy:1542/5992= 0.25734312416555405\n",
      "use_train = False AVG Noise Difference: 0.10318014010420895 Total correct: 30 accuracy:30/1000= 0.03 char_accuracy:699/2991= 0.2337011033099298\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.319 | Actual Noise: 0.391 | Predicted Text: 90 | Actual Text: 98 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.369 | Actual Noise: 0.373 | Predicted Text: 7605 | Actual Text: 2067 | Correct: 0\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.676 | Actual Noise: 0.785 | Predicted Text: 37 | Actual Text: 46 | Correct: 0\n",
      "N_predicted: 2 | Actual N: 3 | Predicted Noise: 0.538 | Actual Noise: 0.74 | Predicted Text: 11 | Actual Text: 034 | Correct: 0\n",
      "N_predicted: 2 | Actual N: 4 | Predicted Noise: 0.811 | Actual Noise: 0.852 | Predicted Text: 19 | Actual Text: 7510 | Correct: 0\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.766 | Actual Noise: 0.879 | Predicted Text: 91 | Actual Text: 99 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.278 | Actual Noise: 0.014 | Predicted Text: 146 | Actual Text: 196 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.783 | Actual Noise: 0.87 | Predicted Text: 2468 | Actual Text: 3322 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.246 | Actual Noise: 0.114 | Predicted Text: 444 | Actual Text: 494 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.549 | Actual Noise: 0.506 | Predicted Text: 77 | Actual Text: 18 | Correct: 0\n",
      "use_train = False AVG Noise Difference: 0.106558228966469 Total correct: 0 accuracy:0/10= 0.0 char_accuracy:6/29= 0.20689655172413793\n",
      "loss at epoch 6 is 4.537780559778213; Epoch takes 128 seconds\n",
      "loss at epoch 7 is 4.169031903505327; Epoch takes 127 seconds\n",
      "loss at epoch 8 is 4.013127912282944; Epoch takes 127 seconds\n",
      "loss at epoch 9 is 3.9652117762565604; Epoch takes 127 seconds\n",
      "loss at epoch 10 is 3.7713810734748847; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.10303358197632316 Total correct: 111 accuracy:111/2000= 0.0555 char_accuracy:1795/5992= 0.29956608811748997\n",
      "use_train = False AVG Noise Difference: 0.10785451765464625 Total correct: 55 accuracy:55/1000= 0.055 char_accuracy:871/2976= 0.2926747311827957\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.341 | Actual Noise: 0.097 | Predicted Text: 022 | Actual Text: 724 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.757 | Actual Noise: 0.887 | Predicted Text: 8294 | Actual Text: 1874 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.62 | Actual Noise: 0.613 | Predicted Text: 2992 | Actual Text: 2909 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.399 | Actual Noise: 0.321 | Predicted Text: 718 | Actual Text: 781 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.641 | Actual Noise: 0.652 | Predicted Text: 17 | Actual Text: 77 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.299 | Actual Noise: 0.125 | Predicted Text: 3689 | Actual Text: 8996 | Correct: 0\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.808 | Actual Noise: 0.795 | Predicted Text: 45 | Actual Text: 54 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.849 | Actual Noise: 0.804 | Predicted Text: 8604 | Actual Text: 4446 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.84 | Actual Noise: 0.897 | Predicted Text: 7635 | Actual Text: 8688 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.411 | Actual Noise: 0.307 | Predicted Text: 40 | Actual Text: 64 | Correct: 0\n",
      "use_train = False AVG Noise Difference: 0.08648611261062795 Total correct: 0 accuracy:0/10= 0.0 char_accuracy:7/32= 0.21875\n",
      "loss at epoch 11 is 3.6663300147652618; Epoch takes 127 seconds\n",
      "loss at epoch 12 is 3.6144987034201637; Epoch takes 127 seconds\n",
      "loss at epoch 13 is 3.528005717873572; Epoch takes 127 seconds\n",
      "loss at epoch 14 is 3.4107281899452206; Epoch takes 127 seconds\n",
      "loss at epoch 15 is 3.3616738905310632; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.08940042669659463 Total correct: 155 accuracy:155/2000= 0.0775 char_accuracy:2022/5992= 0.33744993324432576\n",
      "use_train = False AVG Noise Difference: 0.08496115139921132 Total correct: 89 accuracy:89/1000= 0.089 char_accuracy:993/3004= 0.3305592543275632\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.911 | Actual Noise: 0.982 | Predicted Text: 815 | Actual Text: 125 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.466 | Actual Noise: 0.367 | Predicted Text: 24 | Actual Text: 24 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.301 | Actual Noise: 0.015 | Predicted Text: 401 | Actual Text: 041 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.908 | Actual Noise: 0.972 | Predicted Text: 54 | Actual Text: 51 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.7 | Actual Noise: 0.853 | Predicted Text: 02 | Actual Text: 40 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.234 | Actual Noise: 0.084 | Predicted Text: 6034 | Actual Text: 0064 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.504 | Actual Noise: 0.417 | Predicted Text: 655 | Actual Text: 865 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.744 | Actual Noise: 0.825 | Predicted Text: 2729 | Actual Text: 2547 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.347 | Actual Noise: 0.228 | Predicted Text: 111 | Actual Text: 118 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.301 | Actual Noise: 0.047 | Predicted Text: 111 | Actual Text: 117 | Correct: 2\n",
      "use_train = False AVG Noise Difference: 0.13638911186290198 Total correct: 1 accuracy:1/10= 0.1 char_accuracy:13/29= 0.4482758620689655\n",
      "loss at epoch 16 is 3.237080321907996; Epoch takes 127 seconds\n",
      "loss at epoch 17 is 3.152264151155947; Epoch takes 127 seconds\n",
      "loss at epoch 18 is 3.179368360459804; Epoch takes 127 seconds\n",
      "loss at epoch 19 is 3.0463094943463793; Epoch takes 127 seconds\n",
      "loss at epoch 20 is 3.049898082226514; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.06190249256173754 Total correct: 173 accuracy:173/2000= 0.0865 char_accuracy:2092/5992= 0.34913217623498\n",
      "use_train = False AVG Noise Difference: 0.06099118358234803 Total correct: 99 accuracy:99/1000= 0.099 char_accuracy:1070/2961= 0.3613644039175954\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.198 | Actual Noise: 0.033 | Predicted Text: 1555 | Actual Text: 0551 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.8 | Actual Noise: 0.822 | Predicted Text: 80 | Actual Text: 80 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.341 | Actual Noise: 0.401 | Predicted Text: 098 | Actual Text: 259 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 2 | Predicted Noise: 0.875 | Actual Noise: 0.94 | Predicted Text: 5575 | Actual Text: 52 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 4 | Predicted Noise: 0.404 | Actual Noise: 0.398 | Predicted Text: 97 | Actual Text: 1070 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.205 | Actual Noise: 0.097 | Predicted Text: 633 | Actual Text: 633 | Correct: 3\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.336 | Actual Noise: 0.268 | Predicted Text: 49 | Actual Text: 49 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.317 | Actual Noise: 0.255 | Predicted Text: 7207 | Actual Text: 9227 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.822 | Actual Noise: 0.954 | Predicted Text: 77 | Actual Text: 73 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.399 | Actual Noise: 0.422 | Predicted Text: 59 | Actual Text: 59 | Correct: 2\n",
      "use_train = False AVG Noise Difference: 0.07112756131309834 Total correct: 4 accuracy:4/10= 0.4 char_accuracy:15/28= 0.5357142857142857\n",
      "loss at epoch 21 is 2.9133979442417632; Epoch takes 127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 22 is 2.8277779880166056; Epoch takes 127 seconds\n",
      "loss at epoch 23 is 2.758283671289682; Epoch takes 127 seconds\n",
      "loss at epoch 24 is 2.888226365566256; Epoch takes 127 seconds\n",
      "loss at epoch 25 is 2.6617206065952757; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.04959827611788717 Total correct: 204 accuracy:204/2000= 0.102 char_accuracy:2148/5992= 0.35847797062750336\n",
      "use_train = False AVG Noise Difference: 0.047376879809236376 Total correct: 91 accuracy:91/1000= 0.091 char_accuracy:1080/3008= 0.35904255319148937\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.298 | Actual Noise: 0.313 | Predicted Text: 844 | Actual Text: 048 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.559 | Actual Noise: 0.536 | Predicted Text: 6505 | Actual Text: 4655 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.371 | Actual Noise: 0.376 | Predicted Text: 21 | Actual Text: 29 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.72 | Actual Noise: 0.717 | Predicted Text: 88 | Actual Text: 85 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.434 | Actual Noise: 0.537 | Predicted Text: 0333 | Actual Text: 1036 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.899 | Actual Noise: 0.97 | Predicted Text: 22 | Actual Text: 02 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.204 | Actual Noise: 0.076 | Predicted Text: 11 | Actual Text: 11 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.795 | Actual Noise: 0.794 | Predicted Text: 9679 | Actual Text: 7396 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.804 | Actual Noise: 0.824 | Predicted Text: 5856 | Actual Text: 5380 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.426 | Actual Noise: 0.409 | Predicted Text: 00 | Actual Text: 50 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.038835444382350474 Total correct: 1 accuracy:1/10= 0.1 char_accuracy:10/29= 0.3448275862068966\n",
      "loss at epoch 26 is 2.5650503468513484; Epoch takes 127 seconds\n",
      "loss at epoch 27 is 2.5120857440605744; Epoch takes 127 seconds\n",
      "loss at epoch 28 is 2.4960391834676265; Epoch takes 127 seconds\n",
      "loss at epoch 29 is 2.4331487607657913; Epoch takes 127 seconds\n",
      "loss at epoch 30 is 2.4582167342305183; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.042907504713815055 Total correct: 222 accuracy:222/2000= 0.111 char_accuracy:2168/5992= 0.36181575433911883\n",
      "use_train = False AVG Noise Difference: 0.04296543636109866 Total correct: 105 accuracy:105/1000= 0.105 char_accuracy:1139/3034= 0.3754119973632169\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.686 | Actual Noise: 0.689 | Predicted Text: 919 | Actual Text: 191 | Correct: 0\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.195 | Actual Noise: 0.109 | Predicted Text: 33 | Actual Text: 35 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.305 | Actual Noise: 0.292 | Predicted Text: 98 | Actual Text: 98 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.644 | Actual Noise: 0.63 | Predicted Text: 444 | Actual Text: 493 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 2 | Predicted Noise: 0.208 | Actual Noise: 0.157 | Predicted Text: 290 | Actual Text: 22 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.23 | Actual Noise: 0.178 | Predicted Text: 77 | Actual Text: 77 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.394 | Actual Noise: 0.406 | Predicted Text: 7858 | Actual Text: 9851 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.586 | Actual Noise: 0.617 | Predicted Text: 208 | Actual Text: 530 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.383 | Actual Noise: 0.323 | Predicted Text: 865 | Actual Text: 865 | Correct: 3\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.757 | Actual Noise: 0.787 | Predicted Text: 55 | Actual Text: 25 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.035081051120225026 Total correct: 3 accuracy:3/10= 0.3 char_accuracy:13/26= 0.5\n",
      "loss at epoch 31 is 2.421692690372468; Epoch takes 127 seconds\n",
      "loss at epoch 32 is 2.3806925628483286; Epoch takes 127 seconds\n",
      "loss at epoch 33 is 2.275788016244769; Epoch takes 127 seconds\n",
      "loss at epoch 34 is 2.3014778825193636; Epoch takes 127 seconds\n",
      "loss at epoch 35 is 2.2760692076832054; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.03975071749190421 Total correct: 215 accuracy:215/2000= 0.1075 char_accuracy:2181/5992= 0.36398531375166887\n",
      "use_train = False AVG Noise Difference: 0.03874155853165179 Total correct: 98 accuracy:98/1000= 0.098 char_accuracy:1068/2984= 0.3579088471849866\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.839 | Actual Noise: 0.875 | Predicted Text: 055 | Actual Text: 995 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.195 | Actual Noise: 0.099 | Predicted Text: 449 | Actual Text: 449 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.476 | Actual Noise: 0.474 | Predicted Text: 0080 | Actual Text: 2085 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.408 | Actual Noise: 0.376 | Predicted Text: 455 | Actual Text: 542 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.6 | Actual Noise: 0.57 | Predicted Text: 664 | Actual Text: 446 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.889 | Actual Noise: 0.909 | Predicted Text: 525 | Actual Text: 205 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.685 | Actual Noise: 0.686 | Predicted Text: 333 | Actual Text: 332 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.589 | Actual Noise: 0.571 | Predicted Text: 646 | Actual Text: 641 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.856 | Actual Noise: 0.905 | Predicted Text: 26 | Actual Text: 76 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 3 | Predicted Noise: 0.218 | Actual Noise: 0.104 | Predicted Text: 11 | Actual Text: 918 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.03970318810253551 Total correct: 1 accuracy:1/10= 0.1 char_accuracy:13/30= 0.43333333333333335\n",
      "loss at epoch 36 is 2.3056036725938314; Epoch takes 127 seconds\n",
      "loss at epoch 37 is 2.2742914405912162; Epoch takes 127 seconds\n",
      "loss at epoch 38 is 2.2535975974053146; Epoch takes 127 seconds\n",
      "loss at epoch 39 is 2.2588034665286534; Epoch takes 127 seconds\n",
      "loss at epoch 40 is 2.2034080484360454; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.04525646202618275 Total correct: 215 accuracy:215/2000= 0.1075 char_accuracy:2210/5992= 0.36882510013351133\n",
      "use_train = False AVG Noise Difference: 0.04608464911301447 Total correct: 115 accuracy:115/1000= 0.115 char_accuracy:1140/3016= 0.3779840848806366\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.476 | Actual Noise: 0.455 | Predicted Text: 52 | Actual Text: 25 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.34 | Actual Noise: 0.325 | Predicted Text: 5595 | Actual Text: 7539 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.661 | Actual Noise: 0.609 | Predicted Text: 0055 | Actual Text: 7035 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.369 | Actual Noise: 0.339 | Predicted Text: 7884 | Actual Text: 4783 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.171 | Actual Noise: 0.046 | Predicted Text: 767 | Actual Text: 763 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.167 | Actual Noise: 0.034 | Predicted Text: 66 | Actual Text: 61 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.207 | Actual Noise: 0.139 | Predicted Text: 15 | Actual Text: 51 | Correct: 0\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.846 | Actual Noise: 0.894 | Predicted Text: 66 | Actual Text: 56 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.492 | Actual Noise: 0.452 | Predicted Text: 170 | Actual Text: 701 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.562 | Actual Noise: 0.541 | Predicted Text: 606 | Actual Text: 680 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.05534546443323949 Total correct: 0 accuracy:0/10= 0.0 char_accuracy:9/29= 0.3103448275862069\n",
      "loss at epoch 41 is 2.2069604077339173; Epoch takes 127 seconds\n",
      "loss at epoch 42 is 2.201588825255634; Epoch takes 127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 43 is 2.196020226716995; Epoch takes 127 seconds\n",
      "loss at epoch 44 is 2.1191545687392357; Epoch takes 127 seconds\n",
      "loss at epoch 45 is 2.1771881543230265; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.039375879276914785 Total correct: 227 accuracy:227/2000= 0.1135 char_accuracy:2215/5992= 0.3696595460614152\n",
      "use_train = False AVG Noise Difference: 0.03922824672148737 Total correct: 100 accuracy:100/1000= 0.1 char_accuracy:1106/3005= 0.36805324459234606\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.713 | Actual Noise: 0.691 | Predicted Text: 9889 | Actual Text: 8919 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.861 | Actual Noise: 0.916 | Predicted Text: 606 | Actual Text: 602 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.199 | Actual Noise: 0.132 | Predicted Text: 0005 | Actual Text: 7500 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.746 | Actual Noise: 0.779 | Predicted Text: 887 | Actual Text: 798 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.228 | Actual Noise: 0.233 | Predicted Text: 2220 | Actual Text: 9024 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.856 | Actual Noise: 0.973 | Predicted Text: 02 | Actual Text: 20 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 2 | Predicted Noise: 0.237 | Actual Noise: 0.233 | Predicted Text: 2422 | Actual Text: 42 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.447 | Actual Noise: 0.479 | Predicted Text: 9955 | Actual Text: 0395 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.474 | Actual Noise: 0.503 | Predicted Text: 1181 | Actual Text: 1718 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.341 | Actual Noise: 0.335 | Predicted Text: 5533 | Actual Text: 7358 | Correct: 0\n",
      "use_train = False AVG Noise Difference: 0.0370284303480975 Total correct: 0 accuracy:0/10= 0.0 char_accuracy:7/34= 0.20588235294117646\n",
      "loss at epoch 46 is 2.126223312094806; Epoch takes 127 seconds\n",
      "loss at epoch 47 is 2.099837329514324; Epoch takes 127 seconds\n",
      "loss at epoch 48 is 2.137665788307786; Epoch takes 127 seconds\n",
      "loss at epoch 49 is 2.086148668721319; Epoch takes 127 seconds\n",
      "loss at epoch 50 is 2.1119676257967948; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.035720131020067984 Total correct: 221 accuracy:221/2000= 0.1105 char_accuracy:2258/5992= 0.37683578104138854\n",
      "use_train = False AVG Noise Difference: 0.03613292605859187 Total correct: 123 accuracy:123/1000= 0.123 char_accuracy:1117/2961= 0.37723741979061126\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.918 | Actual Noise: 0.941 | Predicted Text: 827 | Actual Text: 827 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.512 | Actual Noise: 0.483 | Predicted Text: 090 | Actual Text: 909 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.336 | Actual Noise: 0.279 | Predicted Text: 177 | Actual Text: 671 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.218 | Actual Noise: 0.169 | Predicted Text: 88 | Actual Text: 08 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.312 | Actual Noise: 0.282 | Predicted Text: 12 | Actual Text: 21 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.578 | Actual Noise: 0.548 | Predicted Text: 2211 | Actual Text: 1214 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.199 | Actual Noise: 0.141 | Predicted Text: 191 | Actual Text: 913 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.609 | Actual Noise: 0.63 | Predicted Text: 2229 | Actual Text: 2952 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.16 | Actual Noise: 0.042 | Predicted Text: 2224 | Actual Text: 2343 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.187 | Actual Noise: 0.093 | Predicted Text: 22 | Actual Text: 20 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.05106672189733528 Total correct: 1 accuracy:1/10= 0.1 char_accuracy:10/30= 0.3333333333333333\n",
      "loss at epoch 51 is 2.0983171475231637; Epoch takes 127 seconds\n",
      "loss at epoch 52 is 2.089240691591055; Epoch takes 127 seconds\n",
      "loss at epoch 53 is 2.071590628666805; Epoch takes 127 seconds\n",
      "loss at epoch 54 is 2.0711997920498257; Epoch takes 127 seconds\n",
      "loss at epoch 55 is 2.0519530847407887; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.04437693999847761 Total correct: 235 accuracy:235/2000= 0.1175 char_accuracy:2282/5992= 0.3808411214953271\n",
      "use_train = False AVG Noise Difference: 0.045594468304810856 Total correct: 132 accuracy:132/1000= 0.132 char_accuracy:1142/2944= 0.38790760869565216\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.414 | Actual Noise: 0.374 | Predicted Text: 56 | Actual Text: 65 | Correct: 0\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.777 | Actual Noise: 0.785 | Predicted Text: 77 | Actual Text: 76 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.538 | Actual Noise: 0.506 | Predicted Text: 3311 | Actual Text: 3371 | Correct: 3\n",
      "N_predicted: 2 | Actual N: 4 | Predicted Noise: 0.674 | Actual Noise: 0.619 | Predicted Text: 00 | Actual Text: 0954 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.712 | Actual Noise: 0.732 | Predicted Text: 88 | Actual Text: 38 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.341 | Actual Noise: 0.295 | Predicted Text: 99 | Actual Text: 69 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.725 | Actual Noise: 0.708 | Predicted Text: 633 | Actual Text: 663 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.881 | Actual Noise: 0.884 | Predicted Text: 5528 | Actual Text: 5298 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.227 | Actual Noise: 0.187 | Predicted Text: 9552 | Actual Text: 5252 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.292 | Actual Noise: 0.262 | Predicted Text: 65 | Actual Text: 64 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.029321417192372367 Total correct: 0 accuracy:0/10= 0.0 char_accuracy:14/29= 0.4827586206896552\n",
      "loss at epoch 56 is 2.0526662006750698; Epoch takes 127 seconds\n",
      "loss at epoch 57 is 2.0597091622529553; Epoch takes 127 seconds\n",
      "loss at epoch 58 is 2.0816528478451084; Epoch takes 127 seconds\n",
      "loss at epoch 59 is 2.0410345245599752; Epoch takes 127 seconds\n",
      "loss at epoch 60 is 2.05908256970346; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.0402348339074896 Total correct: 217 accuracy:217/2000= 0.1085 char_accuracy:2190/5992= 0.36548731642189586\n",
      "use_train = False AVG Noise Difference: 0.03985655783601321 Total correct: 119 accuracy:119/1000= 0.119 char_accuracy:1137/3025= 0.37586776859504134\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.266 | Actual Noise: 0.26 | Predicted Text: 5999 | Actual Text: 6925 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.86 | Actual Noise: 0.92 | Predicted Text: 1194 | Actual Text: 1749 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.205 | Actual Noise: 0.125 | Predicted Text: 60 | Actual Text: 06 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.659 | Actual Noise: 0.658 | Predicted Text: 5888 | Actual Text: 5738 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.563 | Actual Noise: 0.591 | Predicted Text: 9029 | Actual Text: 0299 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.727 | Actual Noise: 0.723 | Predicted Text: 6635 | Actual Text: 6035 | Correct: 3\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.605 | Actual Noise: 0.625 | Predicted Text: 99 | Actual Text: 98 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.716 | Actual Noise: 0.726 | Predicted Text: 7887 | Actual Text: 1787 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.522 | Actual Noise: 0.511 | Predicted Text: 885 | Actual Text: 856 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.188 | Actual Noise: 0.104 | Predicted Text: 44 | Actual Text: 54 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.03047783051891458 Total correct: 0 accuracy:0/10= 0.0 char_accuracy:13/33= 0.3939393939393939\n",
      "loss at epoch 61 is 2.040373497597874; Epoch takes 127 seconds\n",
      "loss at epoch 62 is 2.008987303227185; Epoch takes 127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 63 is 2.0128323795301846; Epoch takes 127 seconds\n",
      "loss at epoch 64 is 2.0037132088243967; Epoch takes 127 seconds\n",
      "loss at epoch 65 is 2.033441957354545; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.03388374893794216 Total correct: 234 accuracy:234/2000= 0.117 char_accuracy:2264/5992= 0.37783711615487314\n",
      "use_train = False AVG Noise Difference: 0.03284953303961174 Total correct: 121 accuracy:121/1000= 0.121 char_accuracy:1102/2971= 0.3709188825311343\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.848 | Actual Noise: 0.882 | Predicted Text: 751 | Actual Text: 579 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.219 | Actual Noise: 0.172 | Predicted Text: 272 | Actual Text: 722 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.298 | Actual Noise: 0.278 | Predicted Text: 5757 | Actual Text: 5719 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.174 | Actual Noise: 0.078 | Predicted Text: 11 | Actual Text: 11 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.389 | Actual Noise: 0.384 | Predicted Text: 4445 | Actual Text: 2425 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.228 | Actual Noise: 0.184 | Predicted Text: 110 | Actual Text: 019 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.464 | Actual Noise: 0.487 | Predicted Text: 000 | Actual Text: 700 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.83 | Actual Noise: 0.887 | Predicted Text: 4777 | Actual Text: 3747 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.191 | Actual Noise: 0.104 | Predicted Text: 10 | Actual Text: 10 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.691 | Actual Noise: 0.716 | Predicted Text: 7337 | Actual Text: 4337 | Correct: 3\n",
      "use_train = False AVG Noise Difference: 0.043738915697454916 Total correct: 2 accuracy:2/10= 0.2 char_accuracy:17/32= 0.53125\n",
      "loss at epoch 66 is 1.9893913430236287; Epoch takes 127 seconds\n",
      "loss at epoch 67 is 1.986930269181729; Epoch takes 127 seconds\n",
      "loss at epoch 68 is 2.0000246515134354; Epoch takes 127 seconds\n",
      "loss at epoch 69 is 1.961221298539545; Epoch takes 127 seconds\n",
      "loss at epoch 70 is 1.995224016860127; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.036998182698172385 Total correct: 236 accuracy:236/2000= 0.118 char_accuracy:2223/5992= 0.3709946595460614\n",
      "use_train = False AVG Noise Difference: 0.037925342162665826 Total correct: 125 accuracy:125/1000= 0.125 char_accuracy:1142/2991= 0.3818121029755934\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.582 | Actual Noise: 0.583 | Predicted Text: 055 | Actual Text: 051 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.794 | Actual Noise: 0.851 | Predicted Text: 66 | Actual Text: 65 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.733 | Actual Noise: 0.729 | Predicted Text: 33 | Actual Text: 73 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.189 | Actual Noise: 0.077 | Predicted Text: 77 | Actual Text: 17 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.499 | Actual Noise: 0.482 | Predicted Text: 254 | Actual Text: 625 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.526 | Actual Noise: 0.487 | Predicted Text: 555 | Actual Text: 555 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.832 | Actual Noise: 0.841 | Predicted Text: 938 | Actual Text: 893 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.398 | Actual Noise: 0.366 | Predicted Text: 4491 | Actual Text: 4198 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.544 | Actual Noise: 0.552 | Predicted Text: 1219 | Actual Text: 9091 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.233 | Actual Noise: 0.196 | Predicted Text: 3119 | Actual Text: 8913 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.03170899718629346 Total correct: 1 accuracy:1/10= 0.1 char_accuracy:11/30= 0.36666666666666664\n",
      "loss at epoch 71 is 1.9742394923698159; Epoch takes 128 seconds\n",
      "loss at epoch 72 is 1.9597325632981961; Epoch takes 127 seconds\n",
      "loss at epoch 73 is 2.0017828232943997; Epoch takes 128 seconds\n",
      "loss at epoch 74 is 1.9286282050572336; Epoch takes 127 seconds\n",
      "loss at epoch 75 is 1.9511991701982905; Epoch takes 127 seconds\n",
      "use_train = True AVG Noise Difference: 0.033659406462578055 Total correct: 227 accuracy:227/2000= 0.1135 char_accuracy:2258/5992= 0.37683578104138854\n",
      "use_train = False AVG Noise Difference: 0.03364954678644263 Total correct: 106 accuracy:106/1000= 0.106 char_accuracy:1079/2995= 0.36026711185308846\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.701 | Actual Noise: 0.717 | Predicted Text: 8111 | Actual Text: 3810 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.876 | Actual Noise: 0.914 | Predicted Text: 68 | Actual Text: 68 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.803 | Actual Noise: 0.746 | Predicted Text: 9500 | Actual Text: 5409 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.185 | Actual Noise: 0.135 | Predicted Text: 90 | Actual Text: 90 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.812 | Actual Noise: 0.8 | Predicted Text: 171 | Actual Text: 137 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.568 | Actual Noise: 0.543 | Predicted Text: 884 | Actual Text: 884 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.185 | Actual Noise: 0.093 | Predicted Text: 772 | Actual Text: 527 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.725 | Actual Noise: 0.749 | Predicted Text: 080 | Actual Text: 038 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.205 | Actual Noise: 0.162 | Predicted Text: 922 | Actual Text: 912 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.184 | Actual Noise: 0.104 | Predicted Text: 66 | Actual Text: 60 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.043782938851404295 Total correct: 3 accuracy:3/10= 0.3 char_accuracy:14/29= 0.4827586206896552\n",
      "loss at epoch 76 is 1.9496644554659717; Epoch takes 127 seconds\n",
      "loss at epoch 77 is 1.9185979196280252; Epoch takes 138 seconds\n",
      "loss at epoch 78 is 1.9586150112524627; Epoch takes 170 seconds\n",
      "loss at epoch 79 is 1.953595596067607; Epoch takes 157 seconds\n",
      "loss at epoch 80 is 1.9061247066706426; Epoch takes 176 seconds\n",
      "use_train = True AVG Noise Difference: 0.03410349507712632 Total correct: 253 accuracy:253/2000= 0.1265 char_accuracy:2296/5992= 0.38317757009345793\n",
      "use_train = False AVG Noise Difference: 0.0329814669738456 Total correct: 129 accuracy:129/1000= 0.129 char_accuracy:1121/2962= 0.37846049966239026\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.897 | Actual Noise: 0.945 | Predicted Text: 171 | Actual Text: 781 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.883 | Actual Noise: 0.965 | Predicted Text: 192 | Actual Text: 129 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.262 | Actual Noise: 0.248 | Predicted Text: 12 | Actual Text: 21 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.613 | Actual Noise: 0.621 | Predicted Text: 677 | Actual Text: 766 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.596 | Actual Noise: 0.62 | Predicted Text: 6000 | Actual Text: 0946 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.882 | Actual Noise: 0.932 | Predicted Text: 358 | Actual Text: 385 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.168 | Actual Noise: 0.057 | Predicted Text: 668 | Actual Text: 716 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.429 | Actual Noise: 0.408 | Predicted Text: 424 | Actual Text: 424 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.697 | Actual Noise: 0.737 | Predicted Text: 6444 | Actual Text: 6246 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.21 | Actual Noise: 0.138 | Predicted Text: 44 | Actual Text: 44 | Correct: 2\n",
      "use_train = False AVG Noise Difference: 0.0469462597355942 Total correct: 2 accuracy:2/10= 0.2 char_accuracy:10/30= 0.3333333333333333\n",
      "loss at epoch 81 is 1.9060836294293404; Epoch takes 170 seconds\n",
      "loss at epoch 82 is 1.9113607380166648; Epoch takes 169 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 83 is 1.9211161451861265; Epoch takes 171 seconds\n",
      "loss at epoch 84 is 1.99418916625157; Epoch takes 176 seconds\n",
      "loss at epoch 85 is 1.916747657984495; Epoch takes 173 seconds\n",
      "use_train = True AVG Noise Difference: 0.035254285752197904 Total correct: 247 accuracy:247/2000= 0.1235 char_accuracy:2303/5992= 0.38434579439252337\n",
      "use_train = False AVG Noise Difference: 0.034932540952897995 Total correct: 126 accuracy:126/1000= 0.126 char_accuracy:1178/2975= 0.39596638655462185\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.286 | Actual Noise: 0.295 | Predicted Text: 555 | Actual Text: 415 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.36 | Actual Noise: 0.336 | Predicted Text: 3630 | Actual Text: 3600 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.904 | Actual Noise: 0.941 | Predicted Text: 9772 | Actual Text: 2973 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.454 | Actual Noise: 0.462 | Predicted Text: 88 | Actual Text: 78 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.479 | Actual Noise: 0.442 | Predicted Text: 4444 | Actual Text: 4176 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.577 | Actual Noise: 0.603 | Predicted Text: 46 | Actual Text: 64 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.209 | Actual Noise: 0.188 | Predicted Text: 272 | Actual Text: 072 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.578 | Actual Noise: 0.609 | Predicted Text: 6178 | Actual Text: 1786 | Correct: 0\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.3 | Actual Noise: 0.292 | Predicted Text: 77 | Actual Text: 77 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.796 | Actual Noise: 0.806 | Predicted Text: 585 | Actual Text: 581 | Correct: 2\n",
      "use_train = False AVG Noise Difference: 0.021128509273572953 Total correct: 1 accuracy:1/10= 0.1 char_accuracy:13/31= 0.41935483870967744\n",
      "loss at epoch 86 is 1.924055761411786; Epoch takes 175 seconds\n",
      "loss at epoch 87 is 1.8896625604107966; Epoch takes 173 seconds\n",
      "loss at epoch 88 is 1.9232130498308695; Epoch takes 171 seconds\n",
      "loss at epoch 89 is 1.900345913417637; Epoch takes 173 seconds\n",
      "loss at epoch 90 is 1.9281863896250733; Epoch takes 182 seconds\n",
      "use_train = True AVG Noise Difference: 0.03373509493486096 Total correct: 250 accuracy:250/2000= 0.125 char_accuracy:2319/5992= 0.38701602136181573\n",
      "use_train = False AVG Noise Difference: 0.0338644788205238 Total correct: 109 accuracy:109/1000= 0.109 char_accuracy:1128/3035= 0.37166392092257\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.869 | Actual Noise: 0.869 | Predicted Text: 206 | Actual Text: 620 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.641 | Actual Noise: 0.69 | Predicted Text: 9998 | Actual Text: 6895 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.574 | Actual Noise: 0.573 | Predicted Text: 09 | Actual Text: 09 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.733 | Actual Noise: 0.746 | Predicted Text: 78 | Actual Text: 87 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.694 | Actual Noise: 0.71 | Predicted Text: 433 | Actual Text: 473 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.884 | Actual Noise: 0.868 | Predicted Text: 474 | Actual Text: 471 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.16 | Actual Noise: 0.07 | Predicted Text: 9666 | Actual Text: 9162 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.46 | Actual Noise: 0.499 | Predicted Text: 8288 | Actual Text: 8029 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.449 | Actual Noise: 0.43 | Predicted Text: 66 | Actual Text: 68 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.171 | Actual Noise: 0.069 | Predicted Text: 6611 | Actual Text: 1116 | Correct: 1\n",
      "use_train = False AVG Noise Difference: 0.03430568717960936 Total correct: 1 accuracy:1/10= 0.1 char_accuracy:12/31= 0.3870967741935484\n",
      "loss at epoch 91 is 1.9568549931421875; Epoch takes 179 seconds\n",
      "loss at epoch 92 is 1.8899408748708666; Epoch takes 180 seconds\n",
      "loss at epoch 93 is 1.8916597655676313; Epoch takes 190 seconds\n",
      "loss at epoch 94 is 1.8898847967609758; Epoch takes 179 seconds\n",
      "loss at epoch 95 is 1.8621337032020087; Epoch takes 171 seconds\n",
      "use_train = True AVG Noise Difference: 0.03486888463231809 Total correct: 231 accuracy:231/2000= 0.1155 char_accuracy:2275/5992= 0.3796728971962617\n",
      "use_train = False AVG Noise Difference: 0.03706026941080548 Total correct: 129 accuracy:129/1000= 0.129 char_accuracy:1172/2962= 0.39567859554355167\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.843 | Actual Noise: 0.858 | Predicted Text: 19 | Actual Text: 19 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.204 | Actual Noise: 0.178 | Predicted Text: 5509 | Actual Text: 9530 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.411 | Actual Noise: 0.418 | Predicted Text: 0188 | Actual Text: 7018 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.436 | Actual Noise: 0.441 | Predicted Text: 0007 | Actual Text: 0571 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.377 | Actual Noise: 0.382 | Predicted Text: 833 | Actual Text: 834 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.907 | Actual Noise: 0.936 | Predicted Text: 99 | Actual Text: 98 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.28 | Actual Noise: 0.28 | Predicted Text: 997 | Actual Text: 709 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.797 | Actual Noise: 0.841 | Predicted Text: 1011 | Actual Text: 5010 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.866 | Actual Noise: 0.902 | Predicted Text: 44 | Actual Text: 04 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.753 | Actual Noise: 0.764 | Predicted Text: 5006 | Actual Text: 5066 | Correct: 3\n",
      "use_train = False AVG Noise Difference: 0.018082048247180633 Total correct: 1 accuracy:1/10= 0.1 char_accuracy:14/32= 0.4375\n",
      "loss at epoch 96 is 1.905130998782813; Epoch takes 179 seconds\n",
      "loss at epoch 97 is 1.8658374474123123; Epoch takes 181 seconds\n",
      "loss at epoch 98 is 1.8658597723843995; Epoch takes 175 seconds\n",
      "loss at epoch 99 is 1.8597983918637047; Epoch takes 172 seconds\n",
      "loss at epoch 100 is 1.8944685891345157; Epoch takes 176 seconds\n",
      "use_train = True AVG Noise Difference: 0.034919282053678745 Total correct: 238 accuracy:238/2000= 0.119 char_accuracy:2288/5992= 0.3818424566088118\n",
      "use_train = False AVG Noise Difference: 0.03656592613449919 Total correct: 127 accuracy:127/1000= 0.127 char_accuracy:1175/2981= 0.3941630325394163\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.229 | Actual Noise: 0.203 | Predicted Text: 753 | Actual Text: 537 | Correct: 0\n",
      "N_predicted: 4 | Actual N: 3 | Predicted Noise: 0.562 | Actual Noise: 0.556 | Predicted Text: 1118 | Actual Text: 148 | Correct: 1\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.627 | Actual Noise: 0.634 | Predicted Text: 699 | Actual Text: 906 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.399 | Actual Noise: 0.416 | Predicted Text: 433 | Actual Text: 324 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.555 | Actual Noise: 0.548 | Predicted Text: 411 | Actual Text: 614 | Correct: 1\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.492 | Actual Noise: 0.487 | Predicted Text: 6895 | Actual Text: 0859 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.88 | Actual Noise: 0.947 | Predicted Text: 42 | Actual Text: 42 | Correct: 2\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.194 | Actual Noise: 0.14 | Predicted Text: 26 | Actual Text: 62 | Correct: 0\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.171 | Actual Noise: 0.077 | Predicted Text: 760 | Actual Text: 706 | Correct: 1\n",
      "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.598 | Actual Noise: 0.59 | Predicted Text: 29 | Actual Text: 29 | Correct: 2\n",
      "use_train = False AVG Noise Difference: 0.029101883311322692 Total correct: 2 accuracy:2/10= 0.2 char_accuracy:8/28= 0.2857142857142857\n",
      "loss at epoch 101 is 1.8717169625014067; Epoch takes 178 seconds\n",
      "loss at epoch 102 is 1.8524706886410707; Epoch takes 177 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[0mcsis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSIS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptchaModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_rec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptchaModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguide_gmade_rec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_inference_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;31m# test_cycle(USE_CUDA)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[0msave_metric_to_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"captcha_metrics_noise_in_charnet_gmade_400_noise_128_rec.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/4203677847.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(start_epoch, use_cuda)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Optimizing...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mloss_sequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/3506795067.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(t, use_cuda)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mIMG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"captcha\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mimme_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mIMG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mimme_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyro-env\\lib\\site-packages\\pyro\\infer\\csis.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         params = set(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyro-env\\lib\\site-packages\\pyro\\infer\\csis.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(self, grads, batch, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparticle_param_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mguide_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_matched_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyro-env\\lib\\site-packages\\pyro\\infer\\csis.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             batch = (\n\u001b[1;32m--> 106\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_from_joint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyro-env\\lib\\site-packages\\pyro\\infer\\csis.py\u001b[0m in \u001b[0;36m_sample_from_joint\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m    200\u001b[0m         \u001b[0munconditioned_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muncondition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munconditioned_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pyro-env\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyro-env\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m             )\n\u001b[0;32m    173\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyro-env\\lib\\site-packages\\pyro\\poutine\\messenger.py\u001b[0m in \u001b[0;36m_context_wrap\u001b[1;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_context_wrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36mmodel_rec\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m    323\u001b[0m                     \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m             \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;31m#             for i in range(BS):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36m_render_imgs\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    321\u001b[0m                     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                     \u001b[0mrendered_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                     \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36m_render_imgs\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    321\u001b[0m                     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                     \u001b[0mrendered_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                     \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36m_render_imgs\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    321\u001b[0m                     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                     \u001b[0mrendered_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                     \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36m_render_imgs\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    321\u001b[0m                     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                     \u001b[0mrendered_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                     \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36m_render_imgs\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    321\u001b[0m                     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                     \u001b[0mrendered_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                     \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36m_render_imgs\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    321\u001b[0m                     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                     \u001b[0mrendered_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                     \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36m_render_imgs\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    321\u001b[0m                     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                     \u001b[0mrendered_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                     \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/1758833815.py\u001b[0m in \u001b[0;36m_render_imgs\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    319\u001b[0m                     \u001b[0mchars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_chars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                     \u001b[1;31m#print(\"chars\", chars)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m                     \u001b[0mrendered_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                     \u001b[0m_render_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_90512/2420432126.py\u001b[0m in \u001b[0;36mrender_image\u001b[1;34m(chars, fonts, size, margin, resample, noise, use_cuda)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# the generator is gray scale, only keep one channel is enough\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\URA\\Captchas\\claptchagen\\claptcha\\claptcha.py\u001b[0m in \u001b[0;36mimage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;31m# Resize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyro-env\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   1999\u001b[0m                 )\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2001\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2003\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def mask_operation(i, n):\n",
    "    return i < (n + MIN_N)\n",
    "    \n",
    "class CaptchaModel(nn.Module):\n",
    "    \"\"\"\n",
    "    network, model and guide wrapper class\n",
    "    \"\"\"\n",
    "    def __init__(self, use_cuda=False):\n",
    "        super().__init__()\n",
    "        self.num_char_domain = torch.arange(MIN_N, MAX_N + 1)\n",
    "        if use_cuda:\n",
    "            self.num_char_domain = self.num_char_domain.cuda()\n",
    "\n",
    "        self.numNet = NumNet((captchaHeight, captchaWidth), len(self.num_char_domain))\n",
    "        self.noiseNet = NoiseNet((captchaHeight, captchaWidth), 1)\n",
    "        self.char_dict = char_dict # letter dictionary\n",
    "        self.charNet = CharNetSingle((captchaHeight, captchaWidth), len(self.char_dict), max(self.num_char_domain)) # with noise\n",
    "        self.inputEmbedding = InputEmbedding((captchaHeight, captchaWidth), len(self.char_dict), max(self.num_char_domain))\n",
    "        self.noise_constraint = torch.distributions.constraints.interval(MIN_NOISE, MAX_NOISE)\n",
    "        self.hid_net = simpleNN(hidden_state_dim + len(char_dict) + MAX_N + 1, hidden=128, out_size = hidden_state_dim, t = \"mlp\")\n",
    "        self.h0 = nn.Parameter(torch.zeros(hidden_state_dim))\n",
    "        \n",
    "        input_dim_dict = {\n",
    "            \"img\" : captchaHeight * captchaWidth,\n",
    "        }\n",
    "        var_dim_dict = {\n",
    "            \"num_char\" : 1,\n",
    "            \"noise\" : 1,\n",
    "        }\n",
    "        \n",
    "        dependency_dict = {\n",
    "            \"num_char\" : [\"img\"],\n",
    "            \"noise\" : [\"img\"],\n",
    "        }\n",
    "        \n",
    "        to_event_dict = {\n",
    "            \"num_char\" : 0,\n",
    "            \"noise\" : 1,\n",
    "        }\n",
    "        \n",
    "        dist_type_dict = {\n",
    "            \"num_char\" : (\"cate\", len(self.num_char_domain)),\n",
    "            \"noise\" : \"norm\"\n",
    "        }\n",
    "        \n",
    "        self.gmade_n = GMADE(input_dim_dict, dependency_dict, var_dim_dict, \n",
    "           dist_type_dict, to_event_dict, use_cuda=use_cuda, hidden_layers=3, hidden_sizes=1)\n",
    "        \n",
    "        self.noise_dim = 128\n",
    "        \n",
    "        input_dim_dict = {\n",
    "            \"img_embedded\" : 1280,\n",
    "        }\n",
    "        \n",
    "        var_dim_dict = {\n",
    "            \"char\" : 1, \n",
    "        }\n",
    "        \n",
    "        dependency_dict = {\n",
    "            \"char\" : [\"img_embedded\"]\n",
    "        }\n",
    "        \n",
    "        to_event_dict = {\n",
    "            \"char\" : 0\n",
    "        }\n",
    "        \n",
    "        dist_type_dict = {\n",
    "           \"char\" : (\"cate\", len(self.char_dict))\n",
    "        }\n",
    "        \n",
    "        self.gmade_char = GMADE(input_dim_dict, dependency_dict, var_dim_dict, \n",
    "           dist_type_dict, to_event_dict, use_cuda=use_cuda, hidden_layers=3, hidden_sizes=3)\n",
    "            \n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "    \n",
    "    def _map_to_noise_range(self, input):\n",
    "        \"\"\"\n",
    "        map input number to the valid noise range\n",
    "        \"\"\"\n",
    "        input = torch.distributions.transform_to(self.noise_constraint)(input)\n",
    "        return input\n",
    "\n",
    "    def guide_gmade_rec(self, observations={\"captcha\": torch.rand(1, captchaHeight, captchaWidth)}):\n",
    "        pyro.module(\"guide\", self)\n",
    "        \n",
    "        img = observations[\"captcha\"].float()\n",
    "        BS = img.shape[0]\n",
    "        # flatten representation of img\n",
    "        img_raw = torch.reshape(img, (img.shape[0], img.shape[1] * img.shape[2]))\n",
    "                \n",
    "        with pyro.plate(\"data\", img.shape[0]):\n",
    "            \n",
    "            input_dict = {\n",
    "                \"img\" : img_raw\n",
    "            }\n",
    "            out_1 = self.gmade_n(input_dict, suffix=\"\")\n",
    "            N_index = out_1[\"num_char\"]\n",
    "            N_index = torch.add(N_index, self.num_char_domain[0])\n",
    "            noise_batch = out_1[\"noise\"]\n",
    "            noise_batch = self._map_to_noise_range(noise_batch)\n",
    "            input_emb = self.inputEmbedding(img, None)\n",
    "            noise_batch = noise_batch.repeat(1, self.noise_dim)\n",
    "            rnn_input = torch.cat()\n",
    "            \n",
    "            def _rec(i, h):\n",
    "                if i < MAX_N:\n",
    "                    i_input = torch.tensor(i)\n",
    "                    if USE_CUDA:\n",
    "                        i_input = i_input.cuda()\n",
    "                    i_input = F.one_hot(i_input, num_classes=MAX_N).float()\n",
    "                    i_input = i_input.repeat(BS, 1)\n",
    "                    sample_mask = i < N_index\n",
    "                    input_dict_char = {\n",
    "                        \"img_embedded\" : input_emb,\n",
    "                    }\n",
    "                    out_2 = self.gmade_char(input_dict_char, suffix=\"_\"+str(i), mask_dict={\"char\" : sample_mask})\n",
    "                    c_i = out_2[\"char\"]\n",
    "                    c_i = F.one_hot(c_i, num_classes=len(self.char_dict)).float()\n",
    "                    _rec(i + 1, h)\n",
    "            _rec(0, None)\n",
    "    \n",
    "    def model_rec(self, observations={\"captcha\": torch.rand(1, captchaHeight, captchaWidth)}):\n",
    "        \n",
    "        BS = observations[\"captcha\"].shape[0]\n",
    "        \n",
    "        with pyro.plate(\"data\", BS):\n",
    "            \n",
    "            \n",
    "            num_p = torch.tensor(1 / len(self.num_char_domain)).repeat(len(self.num_char_domain)).unsqueeze(0).repeat(BS, 1)\n",
    "        \n",
    "            if self.use_cuda:\n",
    "                num_p = num_p.cuda()\n",
    "\n",
    "            # sample the number of characters\n",
    "            N_index = pyro.sample(\"num_char\", dist.Categorical(num_p).to_event(0))\n",
    "            \n",
    "            N_index = torch.add(N_index,  self.num_char_domain[0])\n",
    "            \n",
    "            noise_mean = torch.tensor((MAX_NOISE - MIN_NOISE) / 2).repeat((BS, 1))\n",
    "            noise_sig = torch.tensor(0.5).repeat((BS, 1))\n",
    "\n",
    "            if self.use_cuda:\n",
    "                noise_mean = noise_mean.cuda()\n",
    "                noise_sig = noise_sig.cuda()\n",
    "\n",
    "            # sample the noise\n",
    "            noise_batch = pyro.sample(\"noise\", dist.Normal(noise_mean, noise_sig).to_event(1))\n",
    "            noise_batch = self._map_to_noise_range(noise_batch)\n",
    "            \n",
    "            sampled_c = []\n",
    "            \n",
    "            def _rec(i):\n",
    "                if i < MAX_N:\n",
    "                    sample_mask = i < N_index\n",
    "                    num_c_i = torch.tensor(1 / len(self.char_dict)).repeat((BS, len(self.char_dict)))\n",
    "                    if self.use_cuda:\n",
    "                        num_c_i = num_c_i.cuda()\n",
    "                    c_i = pyro.sample(\"char_{}\".format(i), dist.Categorical(num_c_i).mask(sample_mask).to_event(0))\n",
    "                    sampled_c.append((sample_mask, c_i))\n",
    "                    _rec(i + 1)\n",
    "            _rec(0)\n",
    "                \n",
    "            # sample characters\n",
    "            rendered_images = []\n",
    "            \n",
    "            # does not contain any sample statements\n",
    "            def _render_imgs(i):\n",
    "                \n",
    "                def _get_chars(j, chars, i):\n",
    "                    if j < MAX_N:\n",
    "                        if sampled_c[j][0][i]:\n",
    "                            chars += self.char_dict[sampled_c[j][1][i]]\n",
    "                            return _get_chars(j + 1, chars, i)\n",
    "                    return chars\n",
    "                if i < BS:\n",
    "                    chars = \"\"\n",
    "                    chars = _get_chars(0, \"\", i)\n",
    "                    #print(\"chars\", chars)\n",
    "                    rendered_image = render_image(chars, noise=float(noise_batch[i]), use_cuda=self.use_cuda)\n",
    "                    rendered_images.append(rendered_image)\n",
    "                    _render_imgs(i + 1)\n",
    "                    \n",
    "            _render_imgs(0)\n",
    "                \n",
    "        rendered_images = torch.stack(rendered_images)\n",
    "        sigma = torch.tensor(0.000001)\n",
    "        if self.use_cuda:\n",
    "                sigma = sigma.cuda()\n",
    "\n",
    "        pyro.sample(\"captcha\", dist.Normal(rendered_images, sigma).to_event(2), obs=observations[\"captcha\"])\n",
    "\n",
    "captchaModel = CaptchaModel(USE_CUDA)\n",
    "\n",
    "optimiser = pyro.optim.Adam({'lr': 5e-5})\n",
    "csis = pyro.infer.CSIS(captchaModel.model_rec, captchaModel.guide_gmade_rec, optimiser, num_inference_samples=1)\n",
    "\n",
    "optimize(1, USE_CUDA)\n",
    "# test_cycle(USE_CUDA)\n",
    "save_metric_to_disk(\"captcha_metrics_noise_in_charnet_gmade_400_noise_128_rec.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66dc2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metric_to_disk(\"captcha_metrics_noise_in_charnet_gmade_100_rec_mean_field.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bbde90",
   "metadata": {},
   "source": [
    "Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2e1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db93859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7faf922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-sister",
   "metadata": {
    "id": "swiss-sister"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-difficulty",
   "metadata": {
    "id": "genetic-difficulty"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Captcha_CSIS_CUDA-noCor_single_FNN-Branches-1-no-var-no-tanh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
